<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.51" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="icon" href="/espnet_draft_home_page/assets/image/espnet.png"><title>espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder</title><meta name="description" content="A documentation for ESPnet">
    <link rel="preload" href="/espnet_draft_home_page/assets/style-CiXYLHjk.css" as="style"><link rel="stylesheet" href="/espnet_draft_home_page/assets/style-CiXYLHjk.css">
    <link rel="modulepreload" href="/espnet_draft_home_page/assets/app-DtMTUqbx.js">
    
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container external-link-icon"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/espnet_draft_home_page/"><img class="vp-nav-logo" src="/espnet_draft_home_page/assets/image/espnet_logo1.png" alt><!----><!----></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Demos"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon>Demos<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/notebook/" aria-label="Roadmap"><!---->Roadmap<!----></a></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/notebook/ESPnet2/Demo/" aria-label="Demo"><!---->Demo<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/notebook/ESPnet2/Course/" aria-label="Course"><!---->Course<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet-EZ</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/notebook/ESPnetEZ/" aria-label="ESPnet EZ"><!---->ESPnet EZ<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ESPnet1 (Legacy)</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/notebook/ESPnet1/" aria-label="ESPnet1"><!---->ESPnet1<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Recipes"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon>Recipes<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/" aria-label="What is a recipe template?"><!---->What is a recipe template?<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Python API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon>Python API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/distributed/" aria-label="distributed"><!---->distributed<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/nets/" aria-label="nets"><!---->nets<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/optimizer/" aria-label="optimizer"><!---->optimizer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/scheduler/" aria-label="scheduler"><!---->scheduler<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/transform/" aria-label="transform"><!---->transform<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet/vc/" aria-label="vc"><!---->vc<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnet2</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/asr/" aria-label="asr"><!---->asr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/" aria-label="asr_transducer"><!---->asr_transducer<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/asvspoof/" aria-label="asvspoof"><!---->asvspoof<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/diar/" aria-label="diar"><!---->diar<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/enh/" aria-label="enh"><!---->enh<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/fileio/" aria-label="fileio"><!---->fileio<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/fst/" aria-label="fst"><!---->fst<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/gan_codec/" aria-label="gan_codec"><!---->gan_codec<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/gan_svs/" aria-label="gan_svs"><!---->gan_svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/gan_tts/" aria-label="gan_tts"><!---->gan_tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/hubert/" aria-label="hubert"><!---->hubert<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/iterators/" aria-label="iterators"><!---->iterators<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/layers/" aria-label="layers"><!---->layers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/lm/" aria-label="lm"><!---->lm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/main_funcs/" aria-label="main_funcs"><!---->main_funcs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/mt/" aria-label="mt"><!---->mt<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/optimizers/" aria-label="optimizers"><!---->optimizers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/s2st/" aria-label="s2st"><!---->s2st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/s2t/" aria-label="s2t"><!---->s2t<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/samplers/" aria-label="samplers"><!---->samplers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/schedulers/" aria-label="schedulers"><!---->schedulers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/slu/" aria-label="slu"><!---->slu<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/speechlm/" aria-label="speechlm"><!---->speechlm<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/spk/" aria-label="spk"><!---->spk<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/st/" aria-label="st"><!---->st<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/svs/" aria-label="svs"><!---->svs<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/tasks/" aria-label="tasks"><!---->tasks<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/text/" aria-label="text"><!---->text<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/torch_utils/" aria-label="torch_utils"><!---->torch_utils<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/train/" aria-label="train"><!---->train<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/tts/" aria-label="tts"><!---->tts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/tts2/" aria-label="tts2"><!---->tts2<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/uasr/" aria-label="uasr"><!---->uasr<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnet2/utils/" aria-label="utils"><!---->utils<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">espnetez</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnetez/config/" aria-label="config"><!---->config<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnetez/data/" aria-label="data"><!---->data<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnetez/dataloader/" aria-label="dataloader"><!---->dataloader<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnetez/dataset/" aria-label="dataset"><!---->dataset<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnetez/preprocess/" aria-label="preprocess"><!---->preprocess<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnetez/task/" aria-label="task"><!---->task<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/espnet_draft_home_page/guide/espnetez/trainer/" aria-label="trainer"><!---->trainer<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Shell API"><!--[--><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon>Shell API<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/tools/espnet2_bin/" aria-label="espnet2_bin"><!---->espnet2_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/tools/espnet_bin/" aria-label="espnet_bin"><!---->espnet_bin<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/tools/spm/" aria-label="spm"><!---->spm<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/tools/utils/" aria-label="utils"><!---->utils<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/espnet_draft_home_page/tools/utils_py/" aria-label="utils_py"><!---->utils_py<!----></a></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/espnet/espnet" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:laptop-code" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Demos</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/notebook/" aria-label="ESPnet Notebooks"><!---->ESPnet Notebooks<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet EZ</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet1</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">ESPnet2</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:mug-hot" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Recipes</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/" aria-label="Recipe Template"><!---->Recipe Template<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/asr1.html" aria-label="Automatic Speech Recognition (Multi-tasking)"><!---->Automatic Speech Recognition (Multi-tasking)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/asr2.html" aria-label="Automatic Speech Recognition with Discrete Units"><!---->Automatic Speech Recognition with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/lm1.html" aria-label="Language Modeling"><!---->Language Modeling<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/mt1.html" aria-label="Machine Translation"><!---->Machine Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/ssl1.html" aria-label="Self-supervised Learning"><!---->Self-supervised Learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/svs1.html" aria-label="Singing Voice Synthesis"><!---->Singing Voice Synthesis<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/diar1.html" aria-label="Speaker Diarisation"><!---->Speaker Diarisation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/enh_diar1.html" aria-label="Speaker Diarisation with Speech Enhancement"><!---->Speaker Diarisation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/spk1.html" aria-label="Speaker Representation"><!---->Speaker Representation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/asvspoof1.html" aria-label="Speaker Verification Spoofing and Countermeasures"><!---->Speaker Verification Spoofing and Countermeasures<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/codec1.html" aria-label="Speech Codec"><!---->Speech Codec<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/enh1.html" aria-label="Speech Enhancement"><!---->Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/speechlm1.html" aria-label="Speech Language Model"><!---->Speech Language Model<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/enh_asr1.html" aria-label="Speech Recognition with Speech Enhancement"><!---->Speech Recognition with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/s2st1.html" aria-label="Speech-to-Speech Translation"><!---->Speech-to-Speech Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/st1.html" aria-label="Speech-to-Text Translation"><!---->Speech-to-Text Translation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/enh_st1.html" aria-label="Speech-to-Text Translation with Speech Enhancement"><!---->Speech-to-Text Translation with Speech Enhancement<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/slu1.html" aria-label="Spoken Language Understanding"><!---->Spoken Language Understanding<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/tts1.html" aria-label="Text-to-Speech"><!---->Text-to-Speech<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/tts2.html" aria-label="Text-to-Speech with Discrete Units"><!---->Text-to-Speech with Discrete Units<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/uasr1.html" aria-label="Unsupervised Automatic Speech Recognition"><!---->Unsupervised Automatic Speech Recognition<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/recipe/s2t1.html" aria-label="Weakly-supervised Learning (Speech-to-Text)"><!---->Weakly-supervised Learning (Speech-to-Text)<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:book" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Python API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Espnet2</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Asr</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Asr Transducer</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/FTSwish.html" aria-label="espnet2.asr_transducer.activation.FTSwish"><!---->espnet2.asr_transducer.activation.FTSwish<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/get_activation.html" aria-label="espnet2.asr_transducer.activation.get_activation"><!---->espnet2.asr_transducer.activation.get_activation<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/Mish.html" aria-label="espnet2.asr_transducer.activation.Mish"><!---->espnet2.asr_transducer.activation.Mish<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/Smish.html" aria-label="espnet2.asr_transducer.activation.Smish"><!---->espnet2.asr_transducer.activation.Smish<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/Swish.html" aria-label="espnet2.asr_transducer.activation.Swish"><!---->espnet2.asr_transducer.activation.Swish<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/BeamSearchTransducer.html" aria-label="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer"><!---->espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/ExtendedHypothesis.html" aria-label="espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis"><!---->espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/Hypothesis.html" aria-label="espnet2.asr_transducer.beam_search_transducer.Hypothesis"><!---->espnet2.asr_transducer.beam_search_transducer.Hypothesis<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/AbsDecoder.html" aria-label="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder"><!---->espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/MEGA.html" aria-label="espnet2.asr_transducer.decoder.blocks.mega.MEGA"><!---->espnet2.asr_transducer.decoder.blocks.mega.MEGA<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/RWKV.html" aria-label="espnet2.asr_transducer.decoder.blocks.rwkv.RWKV"><!---->espnet2.asr_transducer.decoder.blocks.rwkv.RWKV<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/MEGADecoder.html" aria-label="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder"><!---->espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/NormalizedPositionwiseFeedForward.html" aria-label="espnet2.asr_transducer.decoder.modules.mega.feed_forward.NormalizedPositionwiseFeedForward"><!---->espnet2.asr_transducer.decoder.modules.mega.feed_forward.NormalizedPositionwiseFeedForward<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/MultiHeadDampedEMA.html" aria-label="espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA"><!---->espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/RelativePositionBias.html" aria-label="espnet2.asr_transducer.decoder.modules.mega.positional_bias.RelativePositionBias"><!---->espnet2.asr_transducer.decoder.modules.mega.positional_bias.RelativePositionBias<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/RotaryRelativePositionBias.html" aria-label="espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias"><!---->espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/load_wkv_kernel.html" aria-label="espnet2.asr_transducer.decoder.modules.rwkv.attention.load_wkv_kernel"><!---->espnet2.asr_transducer.decoder.modules.rwkv.attention.load_wkv_kernel<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/SelfAttention.html" aria-label="espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention"><!---->espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/WKVLinearAttention.html" aria-label="espnet2.asr_transducer.decoder.modules.rwkv.attention.WKVLinearAttention"><!---->espnet2.asr_transducer.decoder.modules.rwkv.attention.WKVLinearAttention<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/FeedForward.html" aria-label="espnet2.asr_transducer.decoder.modules.rwkv.feed_forward.FeedForward"><!---->espnet2.asr_transducer.decoder.modules.rwkv.feed_forward.FeedForward<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/RNNDecoder.html" aria-label="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder"><!---->espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/RWKVDecoder.html" aria-label="espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder"><!---->espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/StatelessDecoder.html" aria-label="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder"><!---->espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/Branchformer.html" aria-label="espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer"><!---->espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/Conformer.html" aria-label="espnet2.asr_transducer.encoder.blocks.conformer.Conformer"><!---->espnet2.asr_transducer.encoder.blocks.conformer.Conformer<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/ConvInput.html" aria-label="espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput"><!---->espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/Conv1d.html" aria-label="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d"><!---->espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/EBranchformer.html" aria-label="espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer"><!---->espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/build_body_blocks.html" aria-label="espnet2.asr_transducer.encoder.building.build_body_blocks"><!---->espnet2.asr_transducer.encoder.building.build_body_blocks<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/build_branchformer_block.html" aria-label="espnet2.asr_transducer.encoder.building.build_branchformer_block"><!---->espnet2.asr_transducer.encoder.building.build_branchformer_block<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/build_conformer_block.html" aria-label="espnet2.asr_transducer.encoder.building.build_conformer_block"><!---->espnet2.asr_transducer.encoder.building.build_conformer_block<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/build_conv1d_block.html" aria-label="espnet2.asr_transducer.encoder.building.build_conv1d_block"><!---->espnet2.asr_transducer.encoder.building.build_conv1d_block<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/build_ebranchformer_block.html" aria-label="espnet2.asr_transducer.encoder.building.build_ebranchformer_block"><!---->espnet2.asr_transducer.encoder.building.build_ebranchformer_block<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/build_input_block.html" aria-label="espnet2.asr_transducer.encoder.building.build_input_block"><!---->espnet2.asr_transducer.encoder.building.build_input_block<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/build_main_parameters.html" aria-label="espnet2.asr_transducer.encoder.building.build_main_parameters"><!---->espnet2.asr_transducer.encoder.building.build_main_parameters<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/build_positional_encoding.html" aria-label="espnet2.asr_transducer.encoder.building.build_positional_encoding"><!---->espnet2.asr_transducer.encoder.building.build_positional_encoding<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/Encoder.html" aria-label="espnet2.asr_transducer.encoder.encoder.Encoder"><!---->espnet2.asr_transducer.encoder.encoder.Encoder<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/RelPositionMultiHeadedAttention.html" aria-label="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention"><!---->espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/ConformerConvolution.html" aria-label="espnet2.asr_transducer.encoder.modules.convolution.ConformerConvolution"><!---->espnet2.asr_transducer.encoder.modules.convolution.ConformerConvolution<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/ConvolutionalSpatialGatingUnit.html" aria-label="espnet2.asr_transducer.encoder.modules.convolution.ConvolutionalSpatialGatingUnit"><!---->espnet2.asr_transducer.encoder.modules.convolution.ConvolutionalSpatialGatingUnit<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/DepthwiseConvolution.html" aria-label="espnet2.asr_transducer.encoder.modules.convolution.DepthwiseConvolution"><!---->espnet2.asr_transducer.encoder.modules.convolution.DepthwiseConvolution<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/MultiBlocks.html" aria-label="espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks"><!---->espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/RelPositionalEncoding.html" aria-label="espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding"><!---->espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/validate_architecture.html" aria-label="espnet2.asr_transducer.encoder.validation.validate_architecture"><!---->espnet2.asr_transducer.encoder.validation.validate_architecture<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/validate_block_arguments.html" aria-label="espnet2.asr_transducer.encoder.validation.validate_block_arguments"><!---->espnet2.asr_transducer.encoder.validation.validate_block_arguments<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/validate_input_block.html" aria-label="espnet2.asr_transducer.encoder.validation.validate_input_block"><!---->espnet2.asr_transducer.encoder.validation.validate_input_block<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/ErrorCalculator.html" aria-label="espnet2.asr_transducer.error_calculator.ErrorCalculator"><!---->espnet2.asr_transducer.error_calculator.ErrorCalculator<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/ESPnetASRTransducerModel.html" aria-label="espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel"><!---->espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/OnlineAudioProcessor.html" aria-label="espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor"><!---->espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/JointNetwork.html" aria-label="espnet2.asr_transducer.joint_network.JointNetwork"><!---->espnet2.asr_transducer.joint_network.JointNetwork<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/BasicNorm.html" aria-label="espnet2.asr_transducer.normalization.BasicNorm"><!---->espnet2.asr_transducer.normalization.BasicNorm<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/get_normalization.html" aria-label="espnet2.asr_transducer.normalization.get_normalization"><!---->espnet2.asr_transducer.normalization.get_normalization<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/RMSNorm.html" aria-label="espnet2.asr_transducer.normalization.RMSNorm"><!---->espnet2.asr_transducer.normalization.RMSNorm<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/ScaleNorm.html" aria-label="espnet2.asr_transducer.normalization.ScaleNorm"><!---->espnet2.asr_transducer.normalization.ScaleNorm<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/check_short_utt.html" aria-label="espnet2.asr_transducer.utils.check_short_utt"><!---->espnet2.asr_transducer.utils.check_short_utt<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/get_convinput_module_parameters.html" aria-label="espnet2.asr_transducer.utils.get_convinput_module_parameters"><!---->espnet2.asr_transducer.utils.get_convinput_module_parameters<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/get_transducer_task_io.html" aria-label="espnet2.asr_transducer.utils.get_transducer_task_io"><!---->espnet2.asr_transducer.utils.get_transducer_task_io<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/make_chunk_mask.html" aria-label="espnet2.asr_transducer.utils.make_chunk_mask"><!---->espnet2.asr_transducer.utils.make_chunk_mask<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/make_source_mask.html" aria-label="espnet2.asr_transducer.utils.make_source_mask"><!---->espnet2.asr_transducer.utils.make_source_mask<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/TooShortUttError.html" aria-label="espnet2.asr_transducer.utils.TooShortUttError"><!---->espnet2.asr_transducer.utils.TooShortUttError<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Asvspoof</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Diar</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Enh</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Fileio</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Fst</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Gan Codec</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Gan Svs</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Gan Tts</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Hubert</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Iterators</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Layers</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Lm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Main Funcs</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Mt</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Optimizers</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">S2st</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">S2t</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Samplers</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Schedulers</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Slu</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Speechlm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Spk</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">St</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Svs</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Tasks</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Text</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Torch Utils</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Train</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Tts</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Tts2</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Uasr</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnetez</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="fa-solid:wrench" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">Shell API</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Espnet2 Bin</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Spm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Utils Py</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder</h1><div class="page-info"><!----><!----><!----><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 10 min</span><meta property="timeRequired" content="PT10M"></span><!----><!----></div><hr></div><!----><!----><div class="theme-hope-content"><!-- _espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder --><h1 id="espnet2-asr-transducer-decoder-mega-decoder-megadecoder" tabindex="-1"><a class="header-anchor" href="#espnet2-asr-transducer-decoder-mega-decoder-megadecoder"><span>espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder</span></a></h1><p><a href="https://github.com/espnet/espnet/blob/e1fdf91cf400cbcb5f3fe4cf3a4c85cbd0f8bedb/espnet2/asr_transducer/decoder/mega_decoder.py#L19" target="_blank" rel="noopener noreferrer">source</a></p><div class="custom-h3"><p><em>class</em> espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder<span class="small-bracket">(vocab_size: int, block_size: int = 512, linear_size: int = 1024, qk_size: int = 128, v_size: int = 1024, num_heads: int = 4, rel_pos_bias_type: str = &#39;simple&#39;, max_positions: int = 2048, truncation_length: int | <a href="../asr/AbsDecoder.md#espnet2.asr.decoder.abs_decoder.AbsDecoder.None">None</a> = None, normalization_type: str = &#39;layer_norm&#39;, normalization_args: Dict = {}, activation_type: str = &#39;swish&#39;, activation_args: Dict = {}, chunk_size: int = -1, num_blocks: int = 4, dropout_rate: float = 0.0, embed_dropout_rate: float = 0.0, att_dropout_rate: float = 0.0, ema_dropout_rate: float = 0.0, ffn_dropout_rate: float = 0.0, embed_pad: int = 0)</span></p></div><p>Bases: <a class="route-link" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/AbsDecoder.html#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder"><code>AbsDecoder</code></a></p><p>MEGA decoder module for Transducer models.</p><p>This class implements the MEGA (Memory-Enhanced Generative Attention) decoder for sequence-to-sequence tasks, inspired by the paper: <a href="https://arxiv.org/pdf/2209.10655.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2209.10655.pdf</a>.</p><div class="custom-h4"><p>vocab_size</p></div><p>Vocabulary size for the decoder.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>output_size</p></div><p>Size of the decoder output.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>chunk_size</p></div><p>Chunk size for attention computation.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>mega_num_heads</p></div><p>Number of attention heads in MEGA.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>mega_att_k_size</p></div><p>Size of the keys in the attention mechanism.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>mega_att_v_size</p></div><p>Size of the values in the attention mechanism.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>mega_ema_size</p></div><p>Size of the EMA module.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>mega_ema_num_heads</p></div><p>Number of heads in the EMA.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>pad_idx</p></div><p>Padding symbol ID for embeddings.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>num_blocks</p></div><p>Number of MEGA blocks.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>score_cache</p></div><p>Cache for storing computed scores.</p><ul><li><strong>Type:</strong> dict</li></ul><div class="custom-h4"><p>device</p></div><p>Device (CPU or GPU) used for computation.</p><ul><li><p><strong>Type:</strong> torch.device</p></li><li><p><strong>Parameters:</strong></p><ul><li><strong>vocab_size</strong> (<em>int</em>) – Vocabulary size.</li><li><strong>block_size</strong> (<em>int</em> <em>,</em> <em>optional</em>) – Input/Output size. Defaults to 512.</li><li><strong>linear_size</strong> (<em>int</em> <em>,</em> <em>optional</em>) – NormalizedPositionwiseFeedForward hidden size. Defaults to 1024.</li><li><strong>qk_size</strong> (<em>int</em> <em>,</em> <em>optional</em>) – Shared query and key size for attention module. Defaults to 128.</li><li><strong>v_size</strong> (<em>int</em> <em>,</em> <em>optional</em>) – Value size for attention module. Defaults to 1024.</li><li><strong>num_heads</strong> (<em>int</em> <em>,</em> <em>optional</em>) – Number of EMA heads. Defaults to 4.</li><li><strong>rel_pos_bias_type</strong> (<em>str</em> <em>,</em> <em>optional</em>) – Type of relative position bias in attention module. Defaults to “simple”.</li><li><strong>max_positions</strong> (<em>int</em> <em>,</em> <em>optional</em>) – Maximum number of position for RelativePositionBias. Defaults to 2048.</li><li><strong>truncation_length</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em> <em>,</em> <em>optional</em>) – Maximum length for truncation in EMA module. Defaults to None.</li><li><strong>normalization_type</strong> (<em>str</em> <em>,</em> <em>optional</em>) – Normalization layer type. Defaults to “layer_norm”.</li><li><strong>normalization_args</strong> (<em>Dict</em> <em>,</em> <em>optional</em>) – Normalization layer arguments. Defaults to an empty dictionary.</li><li><strong>activation_type</strong> (<em>str</em> <em>,</em> <em>optional</em>) – Activation function type. Defaults to “swish”.</li><li><strong>activation_args</strong> (<em>Dict</em> <em>,</em> <em>optional</em>) – Activation function arguments. Defaults to an empty dictionary.</li><li><strong>chunk_size</strong> (<em>int</em> <em>,</em> <em>optional</em>) – Chunk size for attention computation (-1 = full context). Defaults to -1.</li><li><strong>num_blocks</strong> (<em>int</em> <em>,</em> <em>optional</em>) – Number of MEGA blocks. Defaults to 4.</li><li><strong>dropout_rate</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Dropout rate for MEGA internal modules. Defaults to 0.0.</li><li><strong>embed_dropout_rate</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Dropout rate for embedding layer. Defaults to 0.0.</li><li><strong>att_dropout_rate</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Dropout rate for the attention module. Defaults to 0.0.</li><li><strong>ema_dropout_rate</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Dropout rate for the EMA module. Defaults to 0.0.</li><li><strong>ffn_dropout_rate</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Dropout rate for the feed-forward module. Defaults to 0.0.</li><li><strong>embed_pad</strong> (<em>int</em> <em>,</em> <em>optional</em>) – Embedding padding symbol ID. Defaults to 0.</li></ul></li></ul><p>####################### Examples</p><p>Initialize a MEGADecoder: : decoder = MEGADecoder( : vocab_size=10000, block_size=512, num_blocks=4, activation_type=”relu” &lt;br/&gt; )</p><p>Forward pass through the decoder: : labels = torch.randint(0, 10000, (32, 20)) # Batch of 32, length 20 outputs = decoder(labels)</p><p>Inference with states: : states = decoder.init_state(batch_size=32) output, new_states = decoder.inference(labels, states)</p><ul><li><strong>Raises:</strong><strong>ValueError</strong> – If any of the arguments are out of expected range or format.</li></ul><p>Construct a MEGADecoder object.</p><div class="custom-h4"><p>batch_score<span class="small-bracket">(hyps: List[<a href="Hypothesis.md#espnet2.asr_transducer.beam_search_transducer.Hypothesis">Hypothesis</a>])</span> → Tuple[Tensor, List[Dict[str, Tensor]]]</p></div><p>One-step forward hypotheses.</p><p>This method processes a batch of hypotheses and computes the decoder output for each hypothesis in the batch. It retrieves the last label from each hypothesis and creates a corresponding batch of states.</p><ul><li><p><strong>Parameters:</strong><strong>hyps</strong> – A list of Hypothesis objects, each containing the current label sequence and decoder state.</p></li><li><p><strong>Returns:</strong> A tensor containing the decoder output sequence for each : hypothesis in the batch, shape (B, D_dec).</p><p>states: A list of dictionaries containing the updated decoder : hidden states for each hypothesis.</p></li><li><p><strong>Return type:</strong> out</p></li></ul><p>####################### Examples</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;"> from</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> espnet2.asr_transducer.decoder.blocks.mega </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> Hypothesis</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> hyps </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">Hypothesis</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">yseq</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">dec_state</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">{</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}),</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">         Hypothesis</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">yseq</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">dec_state</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">{</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">})]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> decoder </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> MEGADecoder</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> output, updated_states </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> decoder.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">batch_score</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(hyps)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="custom-h4"><p>create_batch_states<span class="small-bracket">(new_states: List[List[Dict[str, Tensor]]])</span> → List[Dict[str, Tensor]]</p></div><p>Create batch of decoder hidden states given a list of new states.</p><p>This method constructs a new batch of decoder hidden states from a list of individual states for each block. It aggregates the states across the batch dimension, allowing for efficient processing of hypotheses during inference.</p><ul><li><strong>Parameters:</strong><strong>new_states</strong> – A list containing decoder hidden states, where each element is a list of dictionaries representing the states for each block in the decoder. The structure is [B x [N x Dict]], where B is the batch size and N is the number of blocks.</li><li><strong>Returns:</strong> A list of dictionaries representing the aggregated decoder hidden states for each block. The structure is [N x Dict], where N is the number of blocks.</li></ul><p>####################### Examples</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> new_states </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">     [{</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&#39;ema_state&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]]),</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       &#39;prev_key&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.3</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]]),</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       &#39;prev_value&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]])}],</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">     [{</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&#39;ema_state&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.6</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]]),</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       &#39;prev_key&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.7</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]]),</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">       &#39;prev_value&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.8</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]])}]</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> ]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> batch_states </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> decoder.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">create_batch_states</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(new_states)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> print</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(batch_states)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">[{</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&#39;ema_state&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">], [</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.6</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]]),</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">  &#39;prev_key&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.3</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">], [</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.7</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]]),</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">  &#39;prev_value&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">], [</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.8</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]])}]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="custom-h4"><p>forward<span class="small-bracket">(labels: Tensor)</span> → Tensor</p></div><p>MEGA decoder module.</p><p>This class implements the MEGA decoder as described in the paper “MEGA: A New Decoder for ASR” (<a href="https://arxiv.org/pdf/2209.10655.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2209.10655.pdf</a>).</p><div class="custom-h4"><p>embed</p></div><p>Embedding layer for input sequences.</p><div class="custom-h4"><p>dropout_embed</p></div><p>Dropout layer applied to the embedding output.</p><div class="custom-h4"><p>mega_blocks</p></div><p>A list of MEGA blocks, each containing a MEGA module and a Normalized Positionwise Feed Forward module.</p><div class="custom-h4"><p>final_norm</p></div><p>Final normalization layer applied to the output.</p><div class="custom-h4"><p>vocab_size</p></div><p>Size of the vocabulary.</p><div class="custom-h4"><p>output_size</p></div><p>Output size of the decoder.</p><div class="custom-h4"><p>chunk_size</p></div><p>Chunk size for attention computation.</p><div class="custom-h4"><p>mega_num_heads</p></div><p>Number of heads in the MEGA attention.</p><div class="custom-h4"><p>mega_att_k_size</p></div><p>Size of the query and key in attention.</p><div class="custom-h4"><p>mega_att_v_size</p></div><p>Size of the value in attention.</p><div class="custom-h4"><p>mega_ema_size</p></div><p>Size of the EMA module.</p><div class="custom-h4"><p>mega_ema_num_heads</p></div><p>Number of heads in the EMA module.</p><div class="custom-h4"><p>pad_idx</p></div><p>Padding index for the embedding layer.</p><div class="custom-h4"><p>num_blocks</p></div><p>Number of MEGA blocks.</p><div class="custom-h4"><p>score_cache</p></div><p>Cache for previously computed scores.</p><div class="custom-h4"><p>device</p></div><p>Device to which the model is allocated.</p><ul><li><strong>Parameters:</strong><ul><li><strong>vocab_size</strong> – Vocabulary size.</li><li><strong>block_size</strong> – Input/Output size.</li><li><strong>linear_size</strong> – NormalizedPositionwiseFeedForward hidden size.</li><li><strong>qk_size</strong> – Shared query and key size for attention module.</li><li><strong>v_size</strong> – Value size for attention module.</li><li><strong>num_heads</strong> – Number of EMA heads.</li><li><strong>rel_pos_bias_type</strong> – Type of relative position bias in attention module.</li><li><strong>max_positions</strong> – Maximum number of positions for RelativePositionBias.</li><li><strong>truncation_length</strong> – Maximum length for truncation in EMA module.</li><li><strong>normalization_type</strong> – Normalization layer type.</li><li><strong>normalization_args</strong> – Normalization layer arguments.</li><li><strong>activation_type</strong> – Activation function type.</li><li><strong>activation_args</strong> – Activation function arguments.</li><li><strong>chunk_size</strong> – Chunk size for attention computation (-1 = full context).</li><li><strong>num_blocks</strong> – Number of MEGA blocks.</li><li><strong>dropout_rate</strong> – Dropout rate for MEGA internal modules.</li><li><strong>embed_dropout_rate</strong> – Dropout rate for embedding layer.</li><li><strong>att_dropout_rate</strong> – Dropout rate for the attention module.</li><li><strong>ema_dropout_rate</strong> – Dropout rate for the EMA module.</li><li><strong>ffn_dropout_rate</strong> – Dropout rate for the feed-forward module.</li><li><strong>embed_pad</strong> – Embedding padding symbol ID.</li></ul></li></ul><p>####################### Examples</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> decoder </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> MEGADecoder</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">vocab_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> input_tensor </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">randint</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, (</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">50</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">))  </span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># (B, L)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> output </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> decoder</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(input_tensor)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> output.shape</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">Size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">50</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, block_size])</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="custom-h4"><p>inference<span class="small-bracket">(labels: Tensor, states: List[Dict[str, Tensor]])</span> → Tuple[Tensor, List[Dict[str, Tensor]]]</p></div><p>MEGA decoder module for Transducer models.</p><p>This class implements the MEGA decoder as described in the paper “MEGA: A Multiscale Encoder-Decoder Architecture for Speech Recognition” (<a href="https://arxiv.org/pdf/2209.10655.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2209.10655.pdf</a>).</p><div class="custom-h4"><p>vocab_size</p></div><p>Size of the vocabulary.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>output_size</p></div><p>Size of the output block.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>chunk_size</p></div><p>Size of the chunks for attention computation.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>mega_num_heads</p></div><p>Number of heads in the MEGA attention.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>mega_att_k_size</p></div><p>Size of the key in MEGA attention.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>mega_att_v_size</p></div><p>Size of the value in MEGA attention.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>mega_ema_size</p></div><p>Size of the EMA in MEGA.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>mega_ema_num_heads</p></div><p>Number of heads in EMA.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>pad_idx</p></div><p>Padding index for the embedding.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>num_blocks</p></div><p>Number of MEGA blocks.</p><ul><li><strong>Type:</strong> int</li></ul><div class="custom-h4"><p>score_cache</p></div><p>Cache for score computations.</p><ul><li><strong>Type:</strong> dict</li></ul><div class="custom-h4"><p>device</p></div><p>Device on which the model is located.</p><ul><li><p><strong>Type:</strong> torch.device</p></li><li><p><strong>Parameters:</strong></p><ul><li><strong>vocab_size</strong> (<em>int</em>) – Vocabulary size.</li><li><strong>block_size</strong> (<em>int</em>) – Input/Output size.</li><li><strong>linear_size</strong> (<em>int</em>) – NormalizedPositionwiseFeedForward hidden size.</li><li><strong>qk_size</strong> (<em>int</em>) – Shared query and key size for attention module.</li><li><strong>v_size</strong> (<em>int</em>) – Value size for attention module.</li><li><strong>num_heads</strong> (<em>int</em>) – Number of EMA heads.</li><li><strong>rel_pos_bias_type</strong> (<em>str</em>) – Type of relative position bias in attention module.</li><li><strong>max_positions</strong> (<em>int</em>) – Maximum number of position for RelativePositionBias.</li><li><strong>truncation_length</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Maximum length for truncation in EMA.</li><li><strong>normalization_type</strong> (<em>str</em>) – Normalization layer type.</li><li><strong>normalization_args</strong> (<em>Dict</em>) – Normalization layer arguments.</li><li><strong>activation_type</strong> (<em>str</em>) – Activation function type.</li><li><strong>activation_args</strong> (<em>Dict</em>) – Activation function arguments.</li><li><strong>chunk_size</strong> (<em>int</em>) – Chunk size for attention computation (-1 = full context).</li><li><strong>num_blocks</strong> (<em>int</em>) – Number of MEGA blocks.</li><li><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate for MEGA internal modules.</li><li><strong>embed_dropout_rate</strong> (<em>float</em>) – Dropout rate for embedding layer.</li><li><strong>att_dropout_rate</strong> (<em>float</em>) – Dropout rate for the attention module.</li><li><strong>ema_dropout_rate</strong> (<em>float</em>) – Dropout rate for the EMA module.</li><li><strong>ffn_dropout_rate</strong> (<em>float</em>) – Dropout rate for the feed-forward module.</li><li><strong>embed_pad</strong> (<em>int</em>) – Embedding padding symbol ID.</li></ul></li></ul><p>####################### Examples</p><h1 id="initialize-a-megadecoder-instance" tabindex="-1"><a class="header-anchor" href="#initialize-a-megadecoder-instance"><span>Initialize a MEGADecoder instance</span></a></h1><p>decoder = MEGADecoder(</p><blockquote><p>vocab_size=10000, block_size=512, linear_size=1024, num_heads=4, num_blocks=4,</p></blockquote><p>)</p><h1 id="forward-pass-with-labels" tabindex="-1"><a class="header-anchor" href="#forward-pass-with-labels"><span>Forward pass with labels</span></a></h1><p>labels = torch.tensor([[1, 2, 3], [4, 5, 0]]) output = decoder(labels)</p><h1 id="inference-with-previous-states" tabindex="-1"><a class="header-anchor" href="#inference-with-previous-states"><span>Inference with previous states</span></a></h1><p>states = decoder.init_state(batch_size=2) out, new_states = decoder.inference(labels, states)</p><ul><li><strong>Raises:</strong><strong>ValueError</strong> – If the input tensor shapes do not match the expected dimensions.</li></ul><div class="custom-h4"><p>init_state<span class="small-bracket">(batch_size: int = 0)</span> → List[Dict[str, Tensor]]</p></div><p>Initialize MEGADecoder states.</p><p>This method creates the initial hidden states for the MEGADecoder, which are necessary for processing input sequences. The states are initialized to zero tensors based on the output size and the number of MEGA blocks.</p><ul><li><strong>Parameters:</strong><strong>batch_size</strong> – Batch size. This parameter is not used in the current implementation but can be useful for future enhancements.</li><li><strong>Returns:</strong> Decoder hidden states. A list of dictionaries where each : dictionary corresponds to a block in the decoder. Each dictionary contains: <blockquote><ul><li>”ema_state”: A tensor of shape (output_size, num_heads) representing the Exponential Moving Average state.</li><li>”prev_key”: A tensor of shape (1, 1, qk_size) representing the previous key state.</li><li>”prev_value”: A tensor of shape (1, 1, v_size) representing the previous value state.</li></ul></blockquote></li><li><strong>Return type:</strong> states</li></ul><p>####################### Examples</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> decoder </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> MEGADecoder</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">vocab_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> states </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> decoder.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">init_state</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">batch_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(states)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # Assuming num_blocks is set to 4</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="custom-h4"><p>score<span class="small-bracket">(label_sequence: List[int], states: List[Dict[str, Tensor]])</span> → Tuple[Tensor, List[Dict[str, Tensor]]]</p></div><p>MEGA decoder module.</p><p>Based on <a href="https://arxiv.org/pdf/2209.10655.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2209.10655.pdf</a>.</p><p>This class implements the MEGA decoder, which is designed for transducer models in automatic speech recognition (ASR). The decoder uses a combination of attention mechanisms and feed-forward networks to process input sequences and generate output sequences.</p><div class="custom-h4"><p>vocab_size</p></div><p>Vocabulary size.</p><div class="custom-h4"><p>output_size</p></div><p>Size of the output block.</p><div class="custom-h4"><p>chunk_size</p></div><p>Size of chunks for attention computation.</p><div class="custom-h4"><p>mega_num_heads</p></div><p>Number of heads in the MEGA attention.</p><div class="custom-h4"><p>mega_att_k_size</p></div><p>Shared query and key size for the attention module.</p><div class="custom-h4"><p>mega_att_v_size</p></div><p>Value size for the attention module.</p><div class="custom-h4"><p>mega_ema_size</p></div><p>Size of the EMA (Exponential Moving Average).</p><div class="custom-h4"><p>mega_ema_num_heads</p></div><p>Number of EMA heads.</p><div class="custom-h4"><p>pad_idx</p></div><p>Padding index for the embedding layer.</p><div class="custom-h4"><p>num_blocks</p></div><p>Number of MEGA blocks.</p><div class="custom-h4"><p>score_cache</p></div><p>Cache for previously computed scores.</p><div class="custom-h4"><p>device</p></div><p>The device (CPU or GPU) the model is currently using.</p><ul><li><strong>Parameters:</strong><ul><li><strong>vocab_size</strong> – Vocabulary size.</li><li><strong>block_size</strong> – Input/Output size.</li><li><strong>linear_size</strong> – NormalizedPositionwiseFeedForward hidden size.</li><li><strong>qk_size</strong> – Shared query and key size for attention module.</li><li><strong>v_size</strong> – Value size for attention module.</li><li><strong>num_heads</strong> – Number of EMA heads.</li><li><strong>rel_pos_bias_type</strong> – Type of relative position bias in attention module.</li><li><strong>max_positions</strong> – Maximum number of position for RelativePositionBias.</li><li><strong>truncation_length</strong> – Maximum length for truncation in EMA module.</li><li><strong>normalization_type</strong> – Normalization layer type.</li><li><strong>normalization_args</strong> – Normalization layer arguments.</li><li><strong>activation_type</strong> – Activation function type.</li><li><strong>activation_args</strong> – Activation function arguments.</li><li><strong>chunk_size</strong> – Chunk size for attention computation (-1 = full context).</li><li><strong>num_blocks</strong> – Number of MEGA blocks.</li><li><strong>dropout_rate</strong> – Dropout rate for MEGA internal modules.</li><li><strong>embed_dropout_rate</strong> – Dropout rate for embedding layer.</li><li><strong>att_dropout_rate</strong> – Dropout rate for the attention module.</li><li><strong>ema_dropout_rate</strong> – Dropout rate for the EMA module.</li><li><strong>ffn_dropout_rate</strong> – Dropout rate for the feed-forward module.</li><li><strong>embed_pad</strong> – Embedding padding symbol ID.</li></ul></li></ul><p>####################### Examples</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> decoder </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> MEGADecoder</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">vocab_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">block_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">512</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> labels </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">], [</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]])</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> output </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> decoder</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(labels)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> print</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(output.shape)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Output shape will be (B, U, D_dec)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="custom-h4"><p>select_state<span class="small-bracket">(states: List[Dict[str, Tensor]], idx: int)</span> → List[Dict[str, Tensor]]</p></div><p>Select ID state from batch of decoder hidden states.</p><p>This method retrieves the hidden states for a specific index from a batch of decoder states. It extracts the ema_state, prev_key, and prev_value for each block in the decoder.</p><ul><li><strong>Parameters:</strong><ul><li><strong>states</strong> – Decoder hidden states. A list of dictionaries, where each dictionary contains the states for a specific block. Each dictionary should have the keys: <ul><li>“ema_state”: Tensor containing the EMA state for the block.</li><li>“prev_key”: Tensor containing the previous key for the block.</li><li>“prev_value”: Tensor containing the previous value for the block.</li></ul></li><li><strong>idx</strong> – The index of the state to select from each block’s hidden states.</li></ul></li><li><strong>Returns:</strong> A list of dictionaries, where each dictionary contains the selected hidden states for the given index. The structure is the same as the input states but only contains the states corresponding to the specified index.</li></ul><p>####################### Examples</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> states </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">     {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;ema_state&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">randn</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;prev_key&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">randn</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">),</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">      &quot;prev_value&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">randn</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)},</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">     {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;ema_state&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">randn</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;prev_key&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">randn</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">),</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">      &quot;prev_value&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">: torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">randn</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)},</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> ]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> idx </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> selected </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> select_state</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(states, idx)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(selected)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">  # Two blocks were selected from the states.</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="custom-h4"><p>set_device<span class="small-bracket">(device: device) → <a href="../asr/AbsDecoder.md#espnet2.asr.decoder.abs_decoder.AbsDecoder.None">None</a></span></p></div><p>Set GPU device to use.</p><p>This method allows the user to specify the GPU device on which the MEGADecoder will run. It is important for managing the device placement of tensors and operations in PyTorch.</p><ul><li><strong>Parameters:</strong><strong>device</strong> – The device to set for the decoder. This should be a torch.device object representing the desired GPU or CPU device.</li></ul><p>####################### Examples</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> decoder </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> MEGADecoder</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">vocab_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> decoder.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">set_device</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">device</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&#39;cuda:0&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">))  </span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Use GPU 0</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> decoder.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">set_device</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">device</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&#39;cpu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">))      </span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Use CPU</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h5 id="note" tabindex="-1"><a class="header-anchor" href="#note"><span>NOTE</span></a></h5><p>Ensure that the specified device is available and valid in your PyTorch installation. You can check available devices using torch.cuda.is_available() and torch.cuda.device_count().</p><div class="custom-h4"><p>stack_qk_states<span class="small-bracket">(state_list: List[Tensor], dim: int)</span> → List[Tensor]</p></div><p>Stack query or key states with different lengths.</p><p>This method takes a list of query or key states, which may have different lengths, and stacks them into a tensor of shape (num_states, max_len, dim). The shorter states are padded with zeros to match the length of the longest state in the list.</p><ul><li><strong>Parameters:</strong><ul><li><strong>state_list</strong> – List of query or key states, where each state is a tensor of shape (length, dim).</li><li><strong>dim</strong> – The size of the last dimension of each state tensor.</li></ul></li><li><strong>Returns:</strong> A tensor containing stacked query/key states with shape (num_states, max_len, dim), where num_states is the number of states in the input list and max_len is the length of the longest state.</li><li><strong>Return type:</strong> new_state</li></ul><p>####################### Examples</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> states </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">], [</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]]), torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]])]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> stacked </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> stack_qk_states</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(states, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&gt;&gt;&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> print</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(stacked.shape)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">Size</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">])  </span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># 2 states, max length 2, dimension 2</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/RWKV.html" aria-label="espnet2.asr_transducer.decoder.blocks.rwkv.RWKV"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><!---->espnet2.asr_transducer.decoder.blocks.rwkv.RWKV</div></a><a class="route-link auto-link next" href="/espnet_draft_home_page/guide/espnet2/asr_transducer/NormalizedPositionwiseFeedForward.html" aria-label="espnet2.asr_transducer.decoder.modules.mega.feed_forward.NormalizedPositionwiseFeedForward"><div class="hint">Next<span class="arrow end"></span></div><div class="link">espnet2.asr_transducer.decoder.modules.mega.feed_forward.NormalizedPositionwiseFeedForward<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">Copyright © 2024 ESPnet Community. All rights reserved.</div><!----></footer></div><!--]--><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/espnet_draft_home_page/assets/app-DtMTUqbx.js" defer></script>
  </body>
</html>
