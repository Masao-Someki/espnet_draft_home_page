import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,f as t,a as o,o as r}from"./app-KOUU_Wij.js";const s={},i=o('<h1 id="espnet-nets-pytorch-backend-transformer-encoder-mix-encodermix" tabindex="-1"><a class="header-anchor" href="#espnet-nets-pytorch-backend-transformer-encoder-mix-encodermix"><span>espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix</span></a></h1><div class="custom-h3"><p><em>class</em> espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix<span class="small-bracket">(idim, attention_dim=256, attention_heads=4, linear_units=2048, num_blocks_sd=4, num_blocks_rec=8, dropout_rate=0.1, positional_dropout_rate=0.1, attention_dropout_rate=0.0, input_layer=&#39;conv2d&#39;, pos_enc_class=&lt;class &#39;espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding&#39;&gt;, normalize_before=True, concat_after=False, positionwise_layer_type=&#39;linear&#39;, positionwise_conv_kernel_size=1, padding_idx=-1, num_spkrs=2)</span></p></div><p>Bases: <code>Encoder</code>, <code>Module</code></p><p>Transformer encoder module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>idim</strong> (<em>int</em>) – input dim</li><li><strong>attention_dim</strong> (<em>int</em>) – dimension of attention</li><li><strong>attention_heads</strong> (<em>int</em>) – the number of heads of multi head attention</li><li><strong>linear_units</strong> (<em>int</em>) – the number of units of position-wise feed forward</li><li><strong>num_blocks</strong> (<em>int</em>) – the number of decoder blocks</li><li><strong>dropout_rate</strong> (<em>float</em>) – dropout rate</li><li><strong>attention_dropout_rate</strong> (<em>float</em>) – dropout rate in attention</li><li><strong>positional_dropout_rate</strong> (<em>float</em>) – dropout rate after adding positional encoding</li><li><strong>input_layer</strong> (<em>str</em> <em>or</em> <em>torch.nn.Module</em>) – input layer type</li><li><strong>pos_enc_class</strong> (<em>class</em>) – PositionalEncoding or ScaledPositionalEncoding</li><li><strong>normalize_before</strong> (<em>bool</em>) – whether to use layer_norm before the first block</li><li><strong>concat_after</strong> (<em>bool</em>) – whether to concat attention layer’s input and output if True, additional linear will be applied. i.e. x -&gt; x + linear(concat(x, att(x))) if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</li><li><strong>positionwise_layer_type</strong> (<em>str</em>) – linear of conv1d</li><li><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – kernel size of positionwise conv1d layer</li><li><strong>padding_idx</strong> (<em>int</em>) – padding_idx for input_layer=embed</li></ul></li></ul><p>Construct an Encoder object.</p><div class="custom-h4"><p>forward<span class="small-bracket">(xs, masks)</span></p></div><p>Encode input sequence.</p><ul><li><strong>Parameters:</strong><ul><li><strong>xs</strong> (<em>torch.Tensor</em>) – input tensor</li><li><strong>masks</strong> (<em>torch.Tensor</em>) – input mask</li></ul></li><li><strong>Returns:</strong> position embedded tensor and mask</li><li><strong>Rtype Tuple[torch.Tensor, torch.Tensor]:</strong></li></ul><div class="custom-h4"><p>forward_one_step<span class="small-bracket">(xs, masks, *, cache=None)</span></p></div><p>Encode input frame.</p><ul><li><strong>Parameters:</strong><ul><li><strong>xs</strong> (<em>torch.Tensor</em>) – input tensor</li><li><strong>masks</strong> (<em>torch.Tensor</em>) – input mask</li><li><strong>cache</strong> (<em>List</em> *[*<em>torch.Tensor</em> <em>]</em>) – cache tensors</li></ul></li><li><strong>Returns:</strong> position embedded tensor, mask and new cache</li><li><strong>Rtype Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]:</strong></li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',13);function a(l,c){return r(),n("div",null,[t(" _espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix "),i])}const p=e(s,[["render",a],["__file","EncoderMix.html.vue"]]),_=JSON.parse(`{"path":"/guide/espnet/nets/EncoderMix.html","title":"espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.99,"words":296},"filePathRelative":"guide/espnet/nets/EncoderMix.md","excerpt":"<!-- _espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix -->\\n<h1>espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix<span class=\\"small-bracket\\">(idim, attention_dim=256, attention_heads=4, linear_units=2048, num_blocks_sd=4, num_blocks_rec=8, dropout_rate=0.1, positional_dropout_rate=0.1, attention_dropout_rate=0.0, input_layer='conv2d', pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;, normalize_before=True, concat_after=False, positionwise_layer_type='linear', positionwise_conv_kernel_size=1, padding_idx=-1, num_spkrs=2)</span></p></div>"}`);export{p as comp,_ as data};
