import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,f as n,a as s,o as i}from"./app-KOUU_Wij.js";const o={},r=s('<h1 id="espnet2-asr-transducer-decoder-modules-rwkv-attention-selfattention" tabindex="-1"><a class="header-anchor" href="#espnet2-asr-transducer-decoder-modules-rwkv-attention-selfattention"><span>espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention</span></a></h1><div class="custom-h3"><p><em>class</em> espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention<span class="small-bracket">(size: int, attention_size: int, context_size: int, block_id: int, num_blocks: int)</span></p></div><p>Bases: <code>Module</code></p><p>SelfAttention module definition.</p><ul><li><strong>Parameters:</strong><ul><li><strong>size</strong> – Input/Output size.</li><li><strong>attention_size</strong> – Attention hidden size.</li><li><strong>context_size</strong> – Context size for WKV kernel.</li><li><strong>block_id</strong> – Block index.</li><li><strong>num_blocks</strong> – Number of blocks in the architecture.</li></ul></li></ul><p>Construct a SelfAttention object.</p><div class="custom-h4"><p>forward<span class="small-bracket">(x: Tensor, state: List[Tensor] | None = None)</span></p></div><p>Compute time mixing.</p><ul><li><strong>Parameters:</strong><ul><li><strong>x</strong> – SelfAttention input sequences. (B, U, size)</li><li><strong>state</strong> – Decoder hidden states. [5 x (B, 1, D_att, N)]</li></ul></li><li><strong>Returns:</strong> SelfAttention output sequences. (B, U, size)</li><li><strong>Return type:</strong> x</li></ul><div class="custom-h4"><p>reset_parameters<span class="small-bracket">(size: int, attention_size: int, block_id: int, num_blocks: int)</span></p></div><p>Reset module parameters.</p><ul><li><strong>Parameters:</strong><ul><li><strong>size</strong> – Block size.</li><li><strong>attention_size</strong> – Attention hidden size.</li><li><strong>block_id</strong> – Block index.</li><li><strong>num_blocks</strong> – Number of blocks in the architecture.</li></ul></li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div><div class="custom-h4"><p>wkv_linear_attention<span class="small-bracket">(time_decay: Tensor, time_first: Tensor, key: Tensor, value: Tensor, state: Tuple[Tensor, Tensor, Tensor])</span></p></div><p>Compute WKV with state (i.e.: for inference).</p><ul><li><strong>Parameters:</strong><ul><li><strong>time_decay</strong> – Channel-wise time decay vector. (D_att)</li><li><strong>time_first</strong> – Channel-wise time first vector. (D_att)</li><li><strong>key</strong> – Key tensor. (B, 1, D_att)</li><li><strong>value</strong> – Value tensor. (B, 1, D_att)</li><li><strong>state</strong> – Decoder hidden states. [3 x (B, D_att)]</li></ul></li><li><strong>Returns:</strong> Weighted Key-Value. (B, 1, D_att) state: Decoder hidden states. [3 x (B, 1, D_att)]</li><li><strong>Return type:</strong> output</li></ul>',16);function l(a,c){return i(),e("div",null,[n(" _espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention "),r])}const m=t(o,[["render",l],["__file","SelfAttention.html.vue"]]),p=JSON.parse('{"path":"/guide/espnet2/asr_transducer/SelfAttention.html","title":"espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.84,"words":253},"filePathRelative":"guide/espnet2/asr_transducer/SelfAttention.md","excerpt":"<!-- _espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention -->\\n<h1>espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention<span class=\\"small-bracket\\">(size: int, attention_size: int, context_size: int, block_id: int, num_blocks: int)</span></p></div>"}');export{m as comp,p as data};
