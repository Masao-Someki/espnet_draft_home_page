import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as l,c as h,b as i,d as s,e as t,w as n,a as r,o as d}from"./app-KOUU_Wij.js";const p={},o=i("h1",{id:"common-usages",tabindex:"-1"},[i("a",{class:"header-anchor",href:"#common-usages"},[i("span",null,"Common usages")])],-1),c=i("h2",{id:"espnet1",tabindex:"-1"},[i("a",{class:"header-anchor",href:"#espnet1"},[i("span",null,"ESPnet1")])],-1),k=i("h2",{id:"espnet2",tabindex:"-1"},[i("a",{class:"header-anchor",href:"#espnet2"},[i("span",null,"ESPnet2")])],-1),u=r(`<h2 id="multiple-gpu-tips" tabindex="-1"><a class="header-anchor" href="#multiple-gpu-tips"><span>Multiple GPU TIPs</span></a></h2><ul><li>Note that if you want to use multiple GPUs, the installation of <a href="https://developer.nvidia.com/nccl" target="_blank" rel="noopener noreferrer">nccl</a> is required before setup.</li><li>Currently, espnet1 only supports multiple GPU training within a single node. The distributed setup across multiple nodes is only supported in <a href="https://espnet.github.io/espnet/espnet2_distributed.html" target="_blank" rel="noopener noreferrer">espnet2</a>.</li><li>We don&#39;t support multiple GPU inference. Instead, please split the recognition task for multiple jobs and distribute these split jobs to multiple GPUs.</li><li>If you cannot get enough speed improvement with multiple GPUs, you should first check the GPU usage by <code>nvidia-smi</code>. If the GPU-Util percentage is low, the bottleneck will come from disk access. You can apply data prefetching by <code>--n-iter-processes 2</code> in your <code>run.sh</code> to mitigate the problem. Note that this data prefetching consumes a lot of CPU memory, so please be careful when you increase the number of processes.</li><li>The behavior of batch size in ESPnet2 during multi-GPU training is different from that in ESPnet1. <strong>In ESPnet2, the total batch size is not changed regardless of the number of GPUs.</strong> Therefore, you need to manually increase the batch size if you increase the number of GPUs. Please refer to this <a href="https://espnet.github.io/espnet/espnet2_training_option.html#the-relation-between-mini-batch-size-and-number-of-gpus" target="_blank" rel="noopener noreferrer">doc</a> for more information.</li></ul><h2 id="start-from-the-middle-stage-or-stop-at-the-specified-stage" tabindex="-1"><a class="header-anchor" href="#start-from-the-middle-stage-or-stop-at-the-specified-stage"><span>Start from the middle stage or stop at the specified stage</span></a></h2><p><code>run.sh</code> has multiple stages, including data preparation, training, etc., so you may likely want to start from the specified stage if some stages failed for some reason, for example.</p><p>You can start from the specified stage as follows and stop the process at the specified stage:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Start from 3rd stage and stop at 5th stage</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> ./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 3</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --stop-stage</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 5</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="ctc-attention-and-hybrid-ctc-attention" tabindex="-1"><a class="header-anchor" href="#ctc-attention-and-hybrid-ctc-attention"><span>CTC, attention, and hybrid CTC/attention</span></a></h2><p>ESPnet can easily switch the model&#39;s training/decoding mode from CTC, attention, and hybrid CTC/attention.</p><p>Each mode can be trained by specifying <code>mtlalpha</code> (espnet1) <code>ctc_weight</code> (espnet2):</p><ul><li><p>espnet1</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># hybrid CTC/attention (default)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">mtlalpha:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.3</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># CTC</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">mtlalpha:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1.0</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># attention</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">mtlalpha:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.0</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>espnet2</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># hybrid CTC/attention (default)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">model_conf:</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    ctc_weight:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.3</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># CTC</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">model_conf:</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    ctc_weight:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1.0</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># attention</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">model_conf:</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    ctc_weight:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.0</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><p>Decoding for each mode can be done using the following decoding configurations:</p><ul><li><p>espnet1</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># hybrid CTC/attention (default)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">ctc-weight:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.3</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">beam-size:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 10</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># CTC</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">ctc-weight:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1.0</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">## for best path decoding</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">api:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> v1</span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> # default setting (can be omitted)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">## for prefix search decoding w/ beam search</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">api:</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> v2</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">beam-size:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 10</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># attention</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">ctc-weight:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.0</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">beam-size:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 10</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">maxlenratio:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.8</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">minlenratio:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.3</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>espnet2</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># hybrid CTC/attention (default)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">ctc_weight:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.3</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">beam_size:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 10</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># CTC</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">ctc_weight:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 1.0</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">beam_size:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 10</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># attention</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">ctc_weight:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.0</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">beam_size:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 10</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">maxlenratio:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.8</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">minlenratio:</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.3</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>The CTC mode does not compute the validation accuracy, and the optimum model is selected with its loss value, e.g.,</p><ul><li><p>espnet1</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">best_model_criterion:</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">-</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">   -</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> valid</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    -</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> cer_ctc</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">    -</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> min</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>espnet2</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">./run.sh</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> --recog_model</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> model.loss.best</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul></li><li><p>The pure attention mode requires setting the maximum and minimum hypothesis length (<code>--maxlenratio</code> and <code>--minlenratio</code>) appropriately. In general, if you have more insertion errors, you can decrease the <code>maxlenratio</code> value, while if you have more deletion errors, you can increase the <code>minlenratio</code> value. Note that the optimum values depend on the ratio of the input frame and output label lengths, which are changed for each language and each BPE unit.</p></li><li><p>Negative <code>maxlenratio</code> can be used to set the constant maximum hypothesis length independently from the number of input frames. If <code>maxlenratio</code> is set to <code>-1</code>, the decoding will always stop after the first output, which can be used to emulate the utterance classification tasks. This is suitable for some spoken language understanding and speaker identification tasks.</p></li><li><p>About the effectiveness of hybrid CTC/attention during training and recognition, see [2] and [3]. For example, hybrid CTC/attention is not sensitive to the above maximum and minimum hypothesis heuristics.</p></li></ul>`,12);function g(m,b){const e=l("RouteLink");return d(),h("div",null,[o,c,i("p",null,[s("Please first check "),t(e,{to:"/espnet1_tutorial.html"},{default:n(()=>[s("ESPnet1 tutorial")]),_:1})]),k,i("p",null,[s("Please first check "),t(e,{to:"/espnet2_tutorial.html"},{default:n(()=>[s("ESPnet2 tutorial")]),_:1})]),u])}const v=a(p,[["render",g],["__file","tutorial.html.vue"]]),C=JSON.parse(`{"path":"/tutorial.html","title":"Common usages","lang":"en-US","frontmatter":{},"headers":[{"level":2,"title":"ESPnet1","slug":"espnet1","link":"#espnet1","children":[]},{"level":2,"title":"ESPnet2","slug":"espnet2","link":"#espnet2","children":[]},{"level":2,"title":"Multiple GPU TIPs","slug":"multiple-gpu-tips","link":"#multiple-gpu-tips","children":[]},{"level":2,"title":"Start from the middle stage or stop at the specified stage","slug":"start-from-the-middle-stage-or-stop-at-the-specified-stage","link":"#start-from-the-middle-stage-or-stop-at-the-specified-stage","children":[]},{"level":2,"title":"CTC, attention, and hybrid CTC/attention","slug":"ctc-attention-and-hybrid-ctc-attention","link":"#ctc-attention-and-hybrid-ctc-attention","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":2.11,"words":633},"filePathRelative":"tutorial.md","excerpt":"\\n<h2>ESPnet1</h2>\\n<p>Please first check <a href=\\"/espnet1_tutorial.html\\" target=\\"_blank\\">ESPnet1 tutorial</a></p>\\n<h2>ESPnet2</h2>\\n<p>Please first check <a href=\\"/espnet2_tutorial.html\\" target=\\"_blank\\">ESPnet2 tutorial</a></p>\\n<h2>Multiple GPU TIPs</h2>\\n<ul>\\n<li>Note that if you want to use multiple GPUs, the installation of <a href=\\"https://developer.nvidia.com/nccl\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">nccl</a> is required before setup.</li>\\n<li>Currently, espnet1 only supports multiple GPU training within a single node. The distributed setup across multiple nodes is only supported in <a href=\\"https://espnet.github.io/espnet/espnet2_distributed.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">espnet2</a>.</li>\\n<li>We don't support multiple GPU inference. Instead, please split the recognition task for multiple jobs and distribute these split jobs to multiple GPUs.</li>\\n<li>If you cannot get enough speed improvement with multiple GPUs, you should first check the GPU usage by <code>nvidia-smi</code>. If the GPU-Util percentage is low, the bottleneck will come from disk access. You can apply data prefetching by <code>--n-iter-processes 2</code> in your <code>run.sh</code> to mitigate the problem. Note that this data prefetching consumes a lot of CPU memory, so please be careful when you increase the number of processes.</li>\\n<li>The behavior of batch size in ESPnet2 during multi-GPU training is different from that in ESPnet1. <strong>In ESPnet2, the total batch size is not changed regardless of the number of GPUs.</strong> Therefore, you need to manually increase the batch size if you increase the number of GPUs. Please refer to this <a href=\\"https://espnet.github.io/espnet/espnet2_training_option.html#the-relation-between-mini-batch-size-and-number-of-gpus\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">doc</a> for more information.</li>\\n</ul>"}`);export{v as comp,C as data};
