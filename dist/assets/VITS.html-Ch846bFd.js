import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as n,c as r,b as e,d as s,e as a,w as i,a as l,o as _}from"./app-KOUU_Wij.js";const m={},d=e("p",null,"<!-- _espnet2.gan_svs.vits.vits.VITS -->",-1),c=e("h1",{id:"espnet2-gan-svs-vits-vits-vits",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-gan-svs-vits-vits-vits"},[e("span",null,"espnet2.gan_svs.vits.vits.VITS")])],-1),g=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),s(" espnet2.gan_svs.vits.vits.VITS"),e("span",{class:"small-bracket"},"(idim: int, odim: int, sampling_rate: int = 22050, generator_type: str = 'visinger', vocoder_generator_type: str = 'hifigan', generator_params: Dict[str, Any] = {'decoder_channels': 512, 'decoder_kernel_size': 7, 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_upsample_scales': [8, 8, 2, 2], 'expand_f0_method': 'repeat', 'flow_base_dilation': 1, 'flow_dropout_rate': 0.0, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_layers': 4, 'global_channels': -1, 'hidden_channels': 192, 'hubert_channels': 0, 'langs': None, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'projection_filters': [0, 1, 1, 1], 'projection_kernels': [0, 5, 7, 11], 'segment_size': 32, 'spk_embed_dim': None, 'spks': None, 'text_encoder_activation_type': 'swish', 'text_encoder_attention_dropout_rate': 0.0, 'text_encoder_attention_heads': 2, 'text_encoder_blocks': 6, 'text_encoder_conformer_kernel_size': 7, 'text_encoder_dropout_rate': 0.1, 'text_encoder_ffn_expand': 4, 'text_encoder_normalize_before': True, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_positionwise_conv_kernel_size': 1, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'use_conformer_conv_in_text_encoder': True, 'use_macaron_style_in_text_encoder': True, 'use_only_mean_in_flow': True, 'use_phoneme_predictor': False, 'use_weight_norm_in_decoder': True, 'use_weight_norm_in_flow': True, 'use_weight_norm_in_posterior_encoder': True}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'avocodo': {'combd': {'combd_d_d': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'combd_d_g': [[1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1]], 'combd_d_k': [[7, 11, 11, 11, 11, 5], [11, 21, 21, 21, 21, 5], [15, 41, 41, 41, 41, 5]], 'combd_d_p': [[3, 5, 5, 5, 5, 2], [5, 10, 10, 10, 10, 2], [7, 20, 20, 20, 20, 2]], 'combd_d_s': [[1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1]], 'combd_h_u': [[16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024]], 'combd_op_f': [1, 1, 1], 'combd_op_g': [1, 1, 1], 'combd_op_k': [3, 3, 3]}, 'pqmf_config': {'lv1': [2, 256, 0.25, 10.0], 'lv2': [4, 192, 0.13, 10.0]}, 'sbd': {'pqmf_config': {'fsbd': [64, 256, 0.1, 9.0], 'sbd': [16, 256, 0.03, 10.0]}, 'sbd_band_ranges': [[0, 6], [0, 11], [0, 16], [0, 64]], 'sbd_dilations': [[[5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11]], [[3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [2, 3, 5], [2, 3, 5]]], 'sbd_filters': [[64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [32, 64, 128, 128, 128]], 'sbd_kernel_sizes': [[[7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]], [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]]], 'sbd_strides': [[1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1]], 'sbd_transpose': [False, False, False, True], 'use_sbd': True}}, 'hifigan_multi_scale_multi_period_discriminator': {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_adv: float = 1.0, lambda_mel: float = 45.0, lambda_feat_match: float = 2.0, lambda_dur: float = 0.1, lambda_kl: float = 1.0, lambda_pitch: float = 10.0, lambda_phoneme: float = 1.0, lambda_c_yin: float = 45.0, cache_generator_outputs: bool = True)")])],-1),p=e("code",null,"AbsGANSVS",-1),f=l('<p>VITS module (generator + discriminator).</p><p>This is a module of VITS described in <a href="https://arxiv.org/abs/2006.04558" target="_blank" rel="noopener noreferrer">Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</a>.</p><p>Initialize VITS module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</li><li><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will be 1 since VITS is the end-to-end text-to-wave model but for the compatibility odim is used to indicate the acoustic feature dimension.</li><li><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will be referred in saving waveform during the inference.</li><li><strong>generator_type</strong> (<em>str</em>) – Generator type.</li><li><strong>vocoder_generator_type</strong> (<em>str</em>) – Type of vocoder generator to use in the model.</li><li><strong>generator_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for generator.</li><li><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</li><li><strong>discriminator_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for discriminator.</li><li><strong>generator_adv_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for generator adversarial loss.</li><li><strong>discriminator_adv_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for discriminator adversarial loss.</li><li><strong>feat_match_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for feat match loss.</li><li><strong>mel_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for mel loss.</li><li><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</li><li><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel spectrogram loss.</li><li><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</li><li><strong>lambda_dur</strong> (<em>float</em>) – Loss scaling coefficient for duration loss.</li><li><strong>lambda_kl</strong> (<em>float</em>) – Loss scaling coefficient for KL divergence loss.</li><li><strong>lambda_pitch</strong> (<em>float</em>) – Loss scaling coefficient for pitch loss.</li><li><strong>lambda_phoneme</strong> (<em>float</em>) – Loss scaling coefficient for phoneme loss.</li><li><strong>lambda_c_yin</strong> (<em>float</em>) – Loss scaling coefficient for yin loss.</li><li><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(text: Tensor, text_lengths: Tensor, feats: Tensor, feats_lengths: Tensor, singing: Tensor, singing_lengths: Tensor, ssl_feats: Tensor | None = None, ssl_feats_lengths: Tensor | None = None, label: Dict[str, Tensor] | None = None, label_lengths: Dict[str, Tensor] | None = None, melody: Dict[str, Tensor] | None = None, pitch: LongTensor | None = None, ying: Tensor | None = None, duration: Dict[str, Tensor] | None = None, slur: LongTensor | None = None, spembs: Tensor | None = None, sids: Tensor | None = None, lids: Tensor | None = None, forward_generator: bool = True)</span></p></div><p>Perform generator forward.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>LongTensor</em>) – Batch of padded character ids (B, T_text).</li><li><strong>text_lengths</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Batch of padded target features (B, T_feats, odim).</li><li><strong>feats_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</li><li><strong>singing</strong> (<em>Tensor</em>) – Singing waveform tensor (B, T_wav).</li><li><strong>singing_lengths</strong> (<em>Tensor</em>) – Singing length tensor (B,).</li><li><strong>ssl_feats</strong> (<em>Tensor</em>) – SSL feature tensor (B, T_feats, hubert_channels).</li><li><strong>ssl_feats_lengths</strong> (<em>Tensor</em>) – SSL feature length tensor (B,).</li><li><strong>label</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded label ids (B, T_text).</li><li><strong>label_lengths</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of the lengths of padded label ids (B, ).</li><li><strong>melody</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded melody (B, T_text).</li><li><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, T_feats).</li><li><strong>ying</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of padded ying (B, T_feats).</li><li><strong>duration</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab”, “score_phn” or “score_syb”; value (LongTensor): Batch of padded duration (B, T_text).</li><li><strong>slur</strong> (<em>FloatTensor</em>) – Batch of padded slur (B, T_text).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker embeddings (B, spk_embed_dim).</li><li><strong>sids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker IDs (B, 1).</li><li><strong>lids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of language IDs (B, 1).</li><li><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</li></ul></li><li><strong>Returns:</strong><ul><li>loss (Tensor): Loss scalar tensor.</li><li>stats (Dict[str, float]): Statistics to be monitored.</li><li>weight (Tensor): Weight tensor to summarize losses.</li><li>optim_idx (int): Optimizer index (0 for G and 1 for D).</li></ul></li><li><strong>Return type:</strong> Dict[str, Any]</li></ul><div class="custom-h4"><p>inference<span class="small-bracket">(text: Tensor, feats: Tensor | None = None, ssl_feats: Tensor | None = None, label: Dict[str, Tensor] | None = None, melody: Dict[str, Tensor] | None = None, pitch: Tensor | None = None, duration: Dict[str, Tensor] | None = None, slur: Dict[str, Tensor] | None = None, spembs: Tensor | None = None, sids: Tensor | None = None, lids: Tensor | None = None, noise_scale: float = 0.667, noise_scale_dur: float = 0.8, alpha: float = 1.0, max_len: int | None = None, use_teacher_forcing: bool = False)</span></p></div><p>Run inference.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (T_feats, aux_channels).</li><li><strong>ssl_feats</strong> (<em>Tensor</em>) – SSL Feature tensor (T_feats, hubert_channels).</li><li><strong>label</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded label ids (B, T_text).</li><li><strong>melody</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded melody (B, T_text).</li><li><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, T_feats).</li><li><strong>slur</strong> (<em>LongTensor</em>) – Batch of padded slur (B, T_text).</li><li><strong>sids</strong> (<em>Tensor</em>) – Speaker index tensor (1,).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker embedding tensor (spk_embed_dim,).</li><li><strong>lids</strong> (<em>Tensor</em>) – Language index tensor (1,).</li><li><strong>noise_scale</strong> (<em>float</em>) – Noise scale value for flow.</li><li><strong>noise_scale_dur</strong> (<em>float</em>) – Noise scale value for duration predictor.</li><li><strong>alpha</strong> (<em>float</em>) – Alpha parameter to control the speed of generated singing.</li><li><strong>max_len</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Maximum length.</li><li><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</li><li><strong>duration</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab”, “score_phn” or “score_syb”; value (LongTensor): Batch of padded duration (B, T_text).</li></ul></li><li><strong>Returns:</strong><ul><li>wav (Tensor): Generated waveform tensor (T_wav,).</li></ul></li><li><strong>Return type:</strong> Dict[str, Tensor]</li></ul><div class="custom-h4"><p><em>property</em> require_raw_singing</p></div><p>Return whether or not singing is required.</p><div class="custom-h4"><p><em>property</em> require_vocoder</p></div><p>Return whether or not vocoder is required.</p><div class="custom-h4"><p>training <em>: bool</em></p></div>',15);function u(h,b){const o=n("RouteLink");return _(),r("div",null,[d,c,g,e("p",null,[s("Bases: "),a(o,{to:"/guide/espnet2/gan_svs/AbsGANSVS.html#espnet2.gan_svs.abs_gan_svs.AbsGANSVS"},{default:i(()=>[p]),_:1})]),f])}const y=t(m,[["render",u],["__file","VITS.html.vue"]]),x=JSON.parse(`{"path":"/guide/espnet2/gan_svs/VITS.html","title":"espnet2.gan_svs.vits.vits.VITS","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":5.09,"words":1526},"filePathRelative":"guide/espnet2/gan_svs/VITS.md","excerpt":"<p>&lt;!-- _espnet2.gan_svs.vits.vits.VITS --&gt;</p>\\n<h1>espnet2.gan_svs.vits.vits.VITS</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.gan_svs.vits.vits.VITS<span class=\\"small-bracket\\">(idim: int, odim: int, sampling_rate: int = 22050, generator_type: str = 'visinger', vocoder_generator_type: str = 'hifigan', generator_params: Dict[str, Any] = {'decoder_channels': 512, 'decoder_kernel_size': 7, 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_upsample_scales': [8, 8, 2, 2], 'expand_f0_method': 'repeat', 'flow_base_dilation': 1, 'flow_dropout_rate': 0.0, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_layers': 4, 'global_channels': -1, 'hidden_channels': 192, 'hubert_channels': 0, 'langs': None, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'projection_filters': [0, 1, 1, 1], 'projection_kernels': [0, 5, 7, 11], 'segment_size': 32, 'spk_embed_dim': None, 'spks': None, 'text_encoder_activation_type': 'swish', 'text_encoder_attention_dropout_rate': 0.0, 'text_encoder_attention_heads': 2, 'text_encoder_blocks': 6, 'text_encoder_conformer_kernel_size': 7, 'text_encoder_dropout_rate': 0.1, 'text_encoder_ffn_expand': 4, 'text_encoder_normalize_before': True, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_positionwise_conv_kernel_size': 1, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'use_conformer_conv_in_text_encoder': True, 'use_macaron_style_in_text_encoder': True, 'use_only_mean_in_flow': True, 'use_phoneme_predictor': False, 'use_weight_norm_in_decoder': True, 'use_weight_norm_in_flow': True, 'use_weight_norm_in_posterior_encoder': True}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'avocodo': {'combd': {'combd_d_d': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'combd_d_g': [[1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1], [1, 4, 16, 64, 256, 1]], 'combd_d_k': [[7, 11, 11, 11, 11, 5], [11, 21, 21, 21, 21, 5], [15, 41, 41, 41, 41, 5]], 'combd_d_p': [[3, 5, 5, 5, 5, 2], [5, 10, 10, 10, 10, 2], [7, 20, 20, 20, 20, 2]], 'combd_d_s': [[1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1], [1, 1, 4, 4, 4, 1]], 'combd_h_u': [[16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024], [16, 64, 256, 1024, 1024, 1024]], 'combd_op_f': [1, 1, 1], 'combd_op_g': [1, 1, 1], 'combd_op_k': [3, 3, 3]}, 'pqmf_config': {'lv1': [2, 256, 0.25, 10.0], 'lv2': [4, 192, 0.13, 10.0]}, 'sbd': {'pqmf_config': {'fsbd': [64, 256, 0.1, 9.0], 'sbd': [16, 256, 0.03, 10.0]}, 'sbd_band_ranges': [[0, 6], [0, 11], [0, 16], [0, 64]], 'sbd_dilations': [[[5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11], [5, 7, 11]], [[3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7], [3, 5, 7]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3], [1, 2, 3], [2, 3, 5], [2, 3, 5]]], 'sbd_filters': [[64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [64, 128, 256, 256, 256], [32, 64, 128, 128, 128]], 'sbd_kernel_sizes': [[[7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7], [7, 7, 7]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]], [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], [[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5]]], 'sbd_strides': [[1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1], [1, 1, 3, 3, 1]], 'sbd_transpose': [False, False, False, True], 'use_sbd': True}}, 'hifigan_multi_scale_multi_period_discriminator': {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_adv: float = 1.0, lambda_mel: float = 45.0, lambda_feat_match: float = 2.0, lambda_dur: float = 0.1, lambda_kl: float = 1.0, lambda_pitch: float = 10.0, lambda_phoneme: float = 1.0, lambda_c_yin: float = 45.0, cache_generator_outputs: bool = True)</span></p></div>"}`);export{y as comp,x as data};
