import{_ as r}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as o,c as n,f as a,b as e,d as t,e as i,w as _,a as l,o as m}from"./app-KOUU_Wij.js";const c={},d=e("h1",{id:"espnet2-gan-tts-joint-joint-text2wav-jointtext2wav",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-gan-tts-joint-joint-text2wav-jointtext2wav"},[e("span",null,"espnet2.gan_tts.joint.joint_text2wav.JointText2Wav")])],-1),p=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet2.gan_tts.joint.joint_text2wav.JointText2Wav"),e("span",{class:"small-bracket"},"(idim: int, odim: int, segment_size: int = 32, sampling_rate: int = 22050, text2mel_type: str = 'fastspeech2', text2mel_params: Dict[str, Any] = {'adim': 384, 'aheads': 2, 'conformer_activation_type': 'swish', 'conformer_dec_kernel_size': 31, 'conformer_enc_kernel_size': 7, 'conformer_pos_enc_layer_type': 'rel_pos', 'conformer_rel_pos_type': 'latest', 'conformer_self_attn_layer_type': 'rel_selfattn', 'decoder_concat_after': False, 'decoder_normalize_before': True, 'decoder_type': 'conformer', 'dlayers': 4, 'dunits': 1536, 'duration_predictor_chans': 384, 'duration_predictor_dropout_rate': 0.1, 'duration_predictor_kernel_size': 3, 'duration_predictor_layers': 2, 'elayers': 4, 'encoder_concat_after': False, 'encoder_normalize_before': True, 'encoder_type': 'conformer', 'energy_embed_dropout': 0.5, 'energy_embed_kernel_size': 1, 'energy_predictor_chans': 384, 'energy_predictor_dropout': 0.5, 'energy_predictor_kernel_size': 3, 'energy_predictor_layers': 2, 'eunits': 1536, 'gst_conv_chans_list': [32, 32, 64, 64, 128, 128], 'gst_conv_kernel_size': 3, 'gst_conv_layers': 6, 'gst_conv_stride': 2, 'gst_gru_layers': 1, 'gst_gru_units': 128, 'gst_heads': 4, 'gst_tokens': 10, 'init_dec_alpha': 1.0, 'init_enc_alpha': 1.0, 'init_type': 'xavier_uniform', 'langs': -1, 'pitch_embed_dropout': 0.5, 'pitch_embed_kernel_size': 1, 'pitch_predictor_chans': 384, 'pitch_predictor_dropout': 0.5, 'pitch_predictor_kernel_size': 5, 'pitch_predictor_layers': 5, 'positionwise_conv_kernel_size': 1, 'positionwise_layer_type': 'conv1d', 'postnet_chans': 512, 'postnet_dropout_rate': 0.5, 'postnet_filts': 5, 'postnet_layers': 5, 'reduction_factor': 1, 'spk_embed_dim': None, 'spk_embed_integration_type': 'add', 'spks': -1, 'stop_gradient_from_energy_predictor': False, 'stop_gradient_from_pitch_predictor': True, 'transformer_dec_attn_dropout_rate': 0.1, 'transformer_dec_dropout_rate': 0.1, 'transformer_dec_positional_dropout_rate': 0.1, 'transformer_enc_attn_dropout_rate': 0.1, 'transformer_enc_dropout_rate': 0.1, 'transformer_enc_positional_dropout_rate': 0.1, 'use_batch_norm': True, 'use_cnn_in_conformer': True, 'use_gst': False, 'use_macaron_style_in_conformer': True, 'use_masking': False, 'use_scaled_pos_enc': True, 'use_weighted_masking': False, 'zero_triu': False}, vocoder_type: str = 'hifigan_generator', vocoder_params: Dict[str, Any] = {'bias': True, 'channels': 512, 'global_channels': -1, 'kernel_size': 7, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'upsample_kernel_sizes': [16, 16, 4, 4], 'upsample_scales': [8, 8, 2, 2], 'use_additional_convs': True, 'use_weight_norm': True}, use_pqmf: bool = False, pqmf_params: Dict[str, Any] = {'beta': 9.0, 'cutoff_ratio': 0.142, 'subbands': 4, 'taps': 62}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, use_feat_match_loss: bool = True, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, use_mel_loss: bool = True, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_text2mel: float = 1.0, lambda_adv: float = 1.0, lambda_feat_match: float = 2.0, lambda_mel: float = 45.0, cache_generator_outputs: bool = False)")])],-1),g=e("code",null,"AbsGANTTS",-1),u=l('<p>General class to jointly train text2mel and vocoder parts.</p><p>Initialize JointText2Wav module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</li><li><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will be 1 since the model is the end-to-end text-to-wave model but for the compatibility odim is used to indicate the acoustic feature dimension.</li><li><strong>segment_size</strong> (<em>int</em>) – Segment size for random windowed inputs.</li><li><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will be referred in saving waveform during the inference.</li><li><strong>text2mel_type</strong> (<em>str</em>) – The text2mel model type.</li><li><strong>text2mel_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for text2mel model.</li><li><strong>use_pqmf</strong> (<em>bool</em>) – Whether to use PQMF for multi-band vocoder.</li><li><strong>pqmf_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for PQMF module.</li><li><strong>vocoder_type</strong> (<em>str</em>) – The vocoder model type.</li><li><strong>vocoder_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for vocoder model.</li><li><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</li><li><strong>discriminator_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for discriminator.</li><li><strong>generator_adv_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for generator adversarial loss.</li><li><strong>discriminator_adv_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for discriminator adversarial loss.</li><li><strong>use_feat_match_loss</strong> (<em>bool</em>) – Whether to use feat match loss.</li><li><strong>feat_match_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for feat match loss.</li><li><strong>use_mel_loss</strong> (<em>bool</em>) – Whether to use mel loss.</li><li><strong>mel_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for mel loss.</li><li><strong>lambda_text2mel</strong> (<em>float</em>) – Loss scaling coefficient for text2mel model loss.</li><li><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</li><li><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</li><li><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel loss.</li><li><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(text: Tensor, text_lengths: Tensor, feats: Tensor, feats_lengths: Tensor, speech: Tensor, speech_lengths: Tensor, forward_generator: bool = True, **kwargs)</span></p></div><p>Perform generator forward.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</li><li><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, T_feats, aux_channels).</li><li><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</li><li><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</li><li><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B,).</li><li><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</li></ul></li><li><strong>Returns:</strong><ul><li>loss (Tensor): Loss scalar tensor.</li><li>stats (Dict[str, float]): Statistics to be monitored.</li><li>weight (Tensor): Weight tensor to summarize losses.</li><li>optim_idx (int): Optimizer index (0 for G and 1 for D).</li></ul></li><li><strong>Return type:</strong> Dict[str, Any]</li></ul><div class="custom-h4"><p>inference<span class="small-bracket">(text: Tensor, **kwargs)</span></p></div><p>Run inference.</p><ul><li><strong>Parameters:</strong><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</li><li><strong>Returns:</strong><ul><li>wav (Tensor): Generated waveform tensor (T_wav,).</li><li>feat_gan (Tensor): Generated feature tensor (T_text, C).</li></ul></li><li><strong>Return type:</strong> Dict[str, Tensor]</li></ul><div class="custom-h4"><p><em>property</em> require_raw_speech</p></div><p>Return whether or not speech is required.</p><div class="custom-h4"><p><em>property</em> require_vocoder</p></div><p>Return whether or not vocoder is required.</p><div class="custom-h4"><p>training <em>: bool</em></p></div>',14);function f(h,y){const s=o("RouteLink");return m(),n("div",null,[a(" _espnet2.gan_tts.joint.joint_text2wav.JointText2Wav "),d,p,e("p",null,[t("Bases: "),i(s,{to:"/guide/espnet2/gan_tts/AbsGANTTS.html#espnet2.gan_tts.abs_gan_tts.AbsGANTTS"},{default:_(()=>[g]),_:1})]),u])}const T=r(c,[["render",f],["__file","JointText2Wav.html.vue"]]),x=JSON.parse(`{"path":"/guide/espnet2/gan_tts/JointText2Wav.html","title":"espnet2.gan_tts.joint.joint_text2wav.JointText2Wav","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":2.89,"words":866},"filePathRelative":"guide/espnet2/gan_tts/JointText2Wav.md","excerpt":"<!-- _espnet2.gan_tts.joint.joint_text2wav.JointText2Wav -->\\n<h1>espnet2.gan_tts.joint.joint_text2wav.JointText2Wav</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.gan_tts.joint.joint_text2wav.JointText2Wav<span class=\\"small-bracket\\">(idim: int, odim: int, segment_size: int = 32, sampling_rate: int = 22050, text2mel_type: str = 'fastspeech2', text2mel_params: Dict[str, Any] = {'adim': 384, 'aheads': 2, 'conformer_activation_type': 'swish', 'conformer_dec_kernel_size': 31, 'conformer_enc_kernel_size': 7, 'conformer_pos_enc_layer_type': 'rel_pos', 'conformer_rel_pos_type': 'latest', 'conformer_self_attn_layer_type': 'rel_selfattn', 'decoder_concat_after': False, 'decoder_normalize_before': True, 'decoder_type': 'conformer', 'dlayers': 4, 'dunits': 1536, 'duration_predictor_chans': 384, 'duration_predictor_dropout_rate': 0.1, 'duration_predictor_kernel_size': 3, 'duration_predictor_layers': 2, 'elayers': 4, 'encoder_concat_after': False, 'encoder_normalize_before': True, 'encoder_type': 'conformer', 'energy_embed_dropout': 0.5, 'energy_embed_kernel_size': 1, 'energy_predictor_chans': 384, 'energy_predictor_dropout': 0.5, 'energy_predictor_kernel_size': 3, 'energy_predictor_layers': 2, 'eunits': 1536, 'gst_conv_chans_list': [32, 32, 64, 64, 128, 128], 'gst_conv_kernel_size': 3, 'gst_conv_layers': 6, 'gst_conv_stride': 2, 'gst_gru_layers': 1, 'gst_gru_units': 128, 'gst_heads': 4, 'gst_tokens': 10, 'init_dec_alpha': 1.0, 'init_enc_alpha': 1.0, 'init_type': 'xavier_uniform', 'langs': -1, 'pitch_embed_dropout': 0.5, 'pitch_embed_kernel_size': 1, 'pitch_predictor_chans': 384, 'pitch_predictor_dropout': 0.5, 'pitch_predictor_kernel_size': 5, 'pitch_predictor_layers': 5, 'positionwise_conv_kernel_size': 1, 'positionwise_layer_type': 'conv1d', 'postnet_chans': 512, 'postnet_dropout_rate': 0.5, 'postnet_filts': 5, 'postnet_layers': 5, 'reduction_factor': 1, 'spk_embed_dim': None, 'spk_embed_integration_type': 'add', 'spks': -1, 'stop_gradient_from_energy_predictor': False, 'stop_gradient_from_pitch_predictor': True, 'transformer_dec_attn_dropout_rate': 0.1, 'transformer_dec_dropout_rate': 0.1, 'transformer_dec_positional_dropout_rate': 0.1, 'transformer_enc_attn_dropout_rate': 0.1, 'transformer_enc_dropout_rate': 0.1, 'transformer_enc_positional_dropout_rate': 0.1, 'use_batch_norm': True, 'use_cnn_in_conformer': True, 'use_gst': False, 'use_macaron_style_in_conformer': True, 'use_masking': False, 'use_scaled_pos_enc': True, 'use_weighted_masking': False, 'zero_triu': False}, vocoder_type: str = 'hifigan_generator', vocoder_params: Dict[str, Any] = {'bias': True, 'channels': 512, 'global_channels': -1, 'kernel_size': 7, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'upsample_kernel_sizes': [16, 16, 4, 4], 'upsample_scales': [8, 8, 2, 2], 'use_additional_convs': True, 'use_weight_norm': True}, use_pqmf: bool = False, pqmf_params: Dict[str, Any] = {'beta': 9.0, 'cutoff_ratio': 0.142, 'subbands': 4, 'taps': 62}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, use_feat_match_loss: bool = True, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, use_mel_loss: bool = True, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_text2mel: float = 1.0, lambda_adv: float = 1.0, lambda_feat_match: float = 2.0, lambda_mel: float = 45.0, cache_generator_outputs: bool = False)</span></p></div>"}`);export{T as comp,x as data};
