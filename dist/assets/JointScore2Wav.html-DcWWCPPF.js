import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as n,c as r,f as a,b as e,d as o,e as i,w as l,a as m,o as _}from"./app-KOUU_Wij.js";const c={},d=e("h1",{id:"espnet2-gan-svs-joint-joint-score2wav-jointscore2wav",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-gan-svs-joint-joint-score2wav-jointscore2wav"},[e("span",null,"espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav")])],-1),p=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),o(" espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav"),e("span",{class:"small-bracket"},"(idim: int, odim: int, segment_size: int = 32, sampling_rate: int = 22050, score2mel_type: str = 'xiaoice', score2mel_params: Dict[str, Any] = {'adim': 384, 'aheads': 4, 'conformer_activation_type': 'swish', 'conformer_dec_kernel_size': 31, 'conformer_enc_kernel_size': 7, 'conformer_pos_enc_layer_type': 'rel_pos', 'conformer_rel_pos_type': 'latest', 'conformer_self_attn_layer_type': 'rel_selfattn', 'decoder_concat_after': False, 'decoder_normalize_before': True, 'decoder_type': 'transformer', 'dlayers': 6, 'dunits': 1536, 'duration_predictor_chans': 384, 'duration_predictor_dropout_rate': 0.1, 'duration_predictor_kernel_size': 3, 'duration_predictor_layers': 2, 'elayers': 6, 'encoder_concat_after': False, 'encoder_normalize_before': True, 'encoder_type': 'transformer', 'eunits': 1536, 'init_dec_alpha': 1.0, 'init_enc_alpha': 1.0, 'init_type': 'xavier_uniform', 'lambda_dur': 0.1, 'lambda_mel': 1, 'lambda_pitch': 0.01, 'lambda_vuv': 0.01, 'langs': None, 'loss_function': 'XiaoiceSing2', 'loss_type': 'L1', 'midi_dim': 129, 'positionwise_conv_kernel_size': 1, 'positionwise_layer_type': 'conv1d', 'postnet_chans': 512, 'postnet_dropout_rate': 0.5, 'postnet_filts': 5, 'postnet_layers': 5, 'reduction_factor': 1, 'spk_embed_dim': None, 'spk_embed_integration_type': 'add', 'spks': None, 'tempo_dim': 500, 'transformer_dec_attn_dropout_rate': 0.1, 'transformer_dec_dropout_rate': 0.1, 'transformer_dec_positional_dropout_rate': 0.1, 'transformer_enc_attn_dropout_rate': 0.1, 'transformer_enc_dropout_rate': 0.1, 'transformer_enc_positional_dropout_rate': 0.1, 'use_batch_norm': True, 'use_cnn_in_conformer': True, 'use_macaron_style_in_conformer': True, 'use_masking': False, 'use_scaled_pos_enc': True, 'use_weighted_masking': False, 'zero_triu': False}, vocoder_type: str = 'hifigan_generator', vocoder_params: Dict[str, Any] = {'bias': True, 'channels': 512, 'global_channels': -1, 'kernel_size': 7, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'upsample_kernel_sizes': [16, 16, 4, 4], 'upsample_scales': [8, 8, 2, 2], 'use_additional_convs': True, 'use_weight_norm': True}, use_pqmf: bool = False, pqmf_params: Dict[str, Any] = {'beta': 9.0, 'cutoff_ratio': 0.142, 'subbands': 4, 'taps': 62}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, use_feat_match_loss: bool = True, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, use_mel_loss: bool = True, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_score2mel: float = 1.0, lambda_adv: float = 1.0, lambda_feat_match: float = 2.0, lambda_mel: float = 45.0, cache_generator_outputs: bool = False)")])],-1),g=e("code",null,"AbsGANSVS",-1),u=m('<p>General class to jointly train score2mel and vocoder parts.</p><p>Initialize JointScore2Wav module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</li><li><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will be 1 since the model is the end-to-end text-to-wave model but for the compatibility odim is used to indicate the acoustic feature dimension.</li><li><strong>segment_size</strong> (<em>int</em>) – Segment size for random windowed inputs.</li><li><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will be referred in saving waveform during the inference.</li><li><strong>text2mel_type</strong> (<em>str</em>) – The text2mel model type.</li><li><strong>text2mel_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for text2mel model.</li><li><strong>use_pqmf</strong> (<em>bool</em>) – Whether to use PQMF for multi-band vocoder.</li><li><strong>pqmf_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for PQMF module.</li><li><strong>vocoder_type</strong> (<em>str</em>) – The vocoder model type.</li><li><strong>vocoder_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for vocoder model.</li><li><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</li><li><strong>discriminator_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for discriminator.</li><li><strong>generator_adv_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for generator adversarial loss.</li><li><strong>discriminator_adv_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for discriminator adversarial loss.</li><li><strong>use_feat_match_loss</strong> (<em>bool</em>) – Whether to use feat match loss.</li><li><strong>feat_match_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for feat match loss.</li><li><strong>use_mel_loss</strong> (<em>bool</em>) – Whether to use mel loss.</li><li><strong>mel_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for mel loss.</li><li><strong>lambda_text2mel</strong> (<em>float</em>) – Loss scaling coefficient for text2mel model loss.</li><li><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</li><li><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</li><li><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel loss.</li><li><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(text: Tensor, text_lengths: Tensor, feats: Tensor, feats_lengths: Tensor, singing: Tensor, singing_lengths: Tensor, label: Dict[str, Tensor] | None = None, label_lengths: Dict[str, Tensor] | None = None, melody: Dict[str, Tensor] | None = None, pitch: LongTensor | None = None, duration: Dict[str, Tensor] | None = None, slur: LongTensor | None = None, spembs: Tensor | None = None, sids: Tensor | None = None, lids: Tensor | None = None, forward_generator: bool = True)</span></p></div><p>Perform generator forward.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>LongTensor</em>) – Batch of padded character ids (B, Tmax).</li><li><strong>text_lengths</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</li><li><strong>feats_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</li><li><strong>singing</strong> (<em>Tensor</em>) – Singing waveform tensor (B, T_wav).</li><li><strong>singing_lengths</strong> (<em>Tensor</em>) – Singing length tensor (B,).</li><li><strong>label</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded label ids (B, Tmax).</li><li><strong>label_lengths</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of the lengths of padded label ids (B, ).</li><li><strong>melody</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded melody (B, Tmax).</li><li><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, Tmax).</li><li><strong>duration</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab”, “score_phn” or “score_syb”; value (LongTensor): Batch of padded duration (B, Tmax).</li><li><strong>slur</strong> (<em>FloatTensor</em>) – Batch of padded slur (B, Tmax).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker embeddings (B, spk_embed_dim).</li><li><strong>sids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker IDs (B, 1).</li><li><strong>lids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of language IDs (B, 1).</li><li><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</li></ul></li><li><strong>Returns:</strong><ul><li>loss (Tensor): Loss scalar tensor.</li><li>stats (Dict[str, float]): Statistics to be monitored.</li><li>weight (Tensor): Weight tensor to summarize losses.</li><li>optim_idx (int): Optimizer index (0 for G and 1 for D).</li></ul></li><li><strong>Return type:</strong> Dict[str, Any]</li></ul><div class="custom-h4"><p>inference<span class="small-bracket">(text: Tensor, feats: Tensor | None = None, label: Dict[str, Tensor] | None = None, melody: Dict[str, Tensor] | None = None, pitch: Tensor | None = None, duration: Dict[str, Tensor] | None = None, slur: Dict[str, Tensor] | None = None, spembs: Tensor | None = None, sids: Tensor | None = None, lids: Tensor | None = None, noise_scale: float = 0.667, noise_scale_dur: float = 0.8, alpha: float = 1.0, max_len: int | None = None, use_teacher_forcing: bool = False)</span></p></div><p>Run inference.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (T_feats, aux_channels).</li><li><strong>label</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded label ids (B, Tmax).</li><li><strong>melody</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded melody (B, Tmax).</li><li><strong>duration</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab”, “score_phn” or “score_syb”; value (LongTensor): Batch of padded duration (B, Tmax).</li><li><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, Tmax).</li><li><strong>slur</strong> (<em>LongTensor</em>) – Batch of padded slur (B, Tmax).</li><li><strong>sids</strong> (<em>Tensor</em>) – Speaker index tensor (1,).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker embedding tensor (spk_embed_dim,).</li><li><strong>lids</strong> (<em>Tensor</em>) – Language index tensor (1,).</li><li><strong>noise_scale</strong> (<em>float</em>) – Noise scale value for flow.</li><li><strong>noise_scale_dur</strong> (<em>float</em>) – Noise scale value for duration predictor.</li><li><strong>alpha</strong> (<em>float</em>) – Alpha parameter to control the speed of generated singing.</li><li><strong>max_len</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Maximum length.</li><li><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</li></ul></li><li><strong>Returns:</strong><ul><li>wav (Tensor): Generated waveform tensor (T_wav,).</li><li>feat_gan (Tensor): Generated feature tensor (T_text, C).</li></ul></li><li><strong>Return type:</strong> Dict[str, Tensor]</li></ul><div class="custom-h4"><p><em>property</em> require_raw_singing</p></div><p>Return whether or not singing is required.</p><div class="custom-h4"><p><em>property</em> require_vocoder</p></div><p>Return whether or not vocoder is required.</p><div class="custom-h4"><p>training <em>: bool</em></p></div>',14);function f(h,v){const s=n("RouteLink");return _(),r("div",null,[a(" _espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav "),d,p,e("p",null,[o("Bases: "),i(s,{to:"/guide/espnet2/gan_svs/AbsGANSVS.html#espnet2.gan_svs.abs_gan_svs.AbsGANSVS"},{default:l(()=>[g]),_:1})]),u])}const T=t(c,[["render",f],["__file","JointScore2Wav.html.vue"]]),w=JSON.parse(`{"path":"/guide/espnet2/gan_svs/JointScore2Wav.html","title":"espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":4.02,"words":1205},"filePathRelative":"guide/espnet2/gan_svs/JointScore2Wav.md","excerpt":"<!-- _espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav -->\\n<h1>espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.gan_svs.joint.joint_score2wav.JointScore2Wav<span class=\\"small-bracket\\">(idim: int, odim: int, segment_size: int = 32, sampling_rate: int = 22050, score2mel_type: str = 'xiaoice', score2mel_params: Dict[str, Any] = {'adim': 384, 'aheads': 4, 'conformer_activation_type': 'swish', 'conformer_dec_kernel_size': 31, 'conformer_enc_kernel_size': 7, 'conformer_pos_enc_layer_type': 'rel_pos', 'conformer_rel_pos_type': 'latest', 'conformer_self_attn_layer_type': 'rel_selfattn', 'decoder_concat_after': False, 'decoder_normalize_before': True, 'decoder_type': 'transformer', 'dlayers': 6, 'dunits': 1536, 'duration_predictor_chans': 384, 'duration_predictor_dropout_rate': 0.1, 'duration_predictor_kernel_size': 3, 'duration_predictor_layers': 2, 'elayers': 6, 'encoder_concat_after': False, 'encoder_normalize_before': True, 'encoder_type': 'transformer', 'eunits': 1536, 'init_dec_alpha': 1.0, 'init_enc_alpha': 1.0, 'init_type': 'xavier_uniform', 'lambda_dur': 0.1, 'lambda_mel': 1, 'lambda_pitch': 0.01, 'lambda_vuv': 0.01, 'langs': None, 'loss_function': 'XiaoiceSing2', 'loss_type': 'L1', 'midi_dim': 129, 'positionwise_conv_kernel_size': 1, 'positionwise_layer_type': 'conv1d', 'postnet_chans': 512, 'postnet_dropout_rate': 0.5, 'postnet_filts': 5, 'postnet_layers': 5, 'reduction_factor': 1, 'spk_embed_dim': None, 'spk_embed_integration_type': 'add', 'spks': None, 'tempo_dim': 500, 'transformer_dec_attn_dropout_rate': 0.1, 'transformer_dec_dropout_rate': 0.1, 'transformer_dec_positional_dropout_rate': 0.1, 'transformer_enc_attn_dropout_rate': 0.1, 'transformer_enc_dropout_rate': 0.1, 'transformer_enc_positional_dropout_rate': 0.1, 'use_batch_norm': True, 'use_cnn_in_conformer': True, 'use_macaron_style_in_conformer': True, 'use_masking': False, 'use_scaled_pos_enc': True, 'use_weighted_masking': False, 'zero_triu': False}, vocoder_type: str = 'hifigan_generator', vocoder_params: Dict[str, Any] = {'bias': True, 'channels': 512, 'global_channels': -1, 'kernel_size': 7, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'upsample_kernel_sizes': [16, 16, 4, 4], 'upsample_scales': [8, 8, 2, 2], 'use_additional_convs': True, 'use_weight_norm': True}, use_pqmf: bool = False, pqmf_params: Dict[str, Any] = {'beta': 9.0, 'cutoff_ratio': 0.142, 'subbands': 4, 'taps': 62}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, use_feat_match_loss: bool = True, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, use_mel_loss: bool = True, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_score2mel: float = 1.0, lambda_adv: float = 1.0, lambda_feat_match: float = 2.0, lambda_mel: float = 45.0, cache_generator_outputs: bool = False)</span></p></div>"}`);export{T as comp,w as data};
