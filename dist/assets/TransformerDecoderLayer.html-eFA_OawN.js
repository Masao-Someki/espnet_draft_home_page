import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as r,f as t,a as n,o as s}from"./app-KOUU_Wij.js";const o={},a=n('<h1 id="espnet-nets-pytorch-backend-transducer-transformer-decoder-layer-transformerdecoderlayer" tabindex="-1"><a class="header-anchor" href="#espnet-nets-pytorch-backend-transducer-transformer-decoder-layer-transformerdecoderlayer"><span>espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer</span></a></h1><div class="custom-h3"><p><em>class</em> espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer<span class="small-bracket">(hdim: int, self_attention: <a href="MultiHeadedAttention.md#espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention">MultiHeadedAttention</a></span>, feed_forward: PositionwiseFeedForward, dropout_rate: float)</p></div><p>Bases: <code>Module</code></p><p>Transformer decoder layer module for custom Transducer model.</p><ul><li><strong>Parameters:</strong><ul><li><strong>hdim</strong> – Hidden dimension.</li><li><strong>self_attention</strong> – Self-attention module.</li><li><strong>feed_forward</strong> – Feed forward module.</li><li><strong>dropout_rate</strong> – Dropout rate.</li></ul></li></ul><p>Construct an DecoderLayer object.</p><div class="custom-h4"><p>forward<span class="small-bracket">(sequence: Tensor, mask: Tensor, cache: Tensor | None = None)</span></p></div><p>Compute previous decoder output sequences.</p><ul><li><strong>Parameters:</strong><ul><li><strong>sequence</strong> – Transformer input sequences. (B, U, D_dec)</li><li><strong>mask</strong> – Transformer intput mask sequences. (B, U)</li><li><strong>cache</strong> – Cached decoder output sequences. (B, (U - 1), D_dec)</li></ul></li><li><strong>Returns:</strong> Transformer output sequences. (B, U, D_dec) mask: Transformer output mask sequences. (B, U)</li><li><strong>Return type:</strong> sequence</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',10);function d(c,l){return s(),r("div",null,[t(" _espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer "),a])}const u=e(o,[["render",d],["__file","TransformerDecoderLayer.html.vue"]]),p=JSON.parse('{"path":"/guide/espnet/nets/TransformerDecoderLayer.html","title":"espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.46,"words":138},"filePathRelative":"guide/espnet/nets/TransformerDecoderLayer.md","excerpt":"<!-- _espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer -->\\n<h1>espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer<span class=\\"small-bracket\\">(hdim: int, self_attention: <a href=\\"MultiHeadedAttention.md#espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention\\">MultiHeadedAttention</a></span>, feed_forward: PositionwiseFeedForward, dropout_rate: float)</p></div>"}');export{u as comp,p as data};
