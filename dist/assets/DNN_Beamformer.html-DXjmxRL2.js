import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,f as r,a as s,o as n}from"./app-KOUU_Wij.js";const t={},a=s('<h1 id="espnet2-enh-layers-dnn-beamformer-dnn-beamformer" tabindex="-1"><a class="header-anchor" href="#espnet2-enh-layers-dnn-beamformer-dnn-beamformer"><span>espnet2.enh.layers.dnn_beamformer.DNN_Beamformer</span></a></h1><div class="custom-h3"><p><em>class</em> espnet2.enh.layers.dnn_beamformer.DNN_Beamformer<span class="small-bracket">(bidim, btype: str = &#39;blstmp&#39;, blayers: int = 3, bunits: int = 300, bprojs: int = 320, num_spk: int = 1, use_noise_mask: bool = True, nonlinear: str = &#39;sigmoid&#39;, dropout_rate: float = 0.0, badim: int = 320, ref_channel: int = -1, beamformer_type: str = &#39;mvdr_souden&#39;, rtf_iterations: int = 2, mwf_mu: float = 1.0, eps: float = 1e-06, diagonal_loading: bool = True, diag_eps: float = 1e-07, mask_flooring: bool = False, flooring_thres: float = 1e-06, use_torch_solver: bool = True, use_torchaudio_api: bool = False, btaps: int = 5, bdelay: int = 3)</span></p></div><p>Bases: <code>Module</code></p><p>DNN mask based Beamformer.</p><p>Citation: : Multichannel End-to-end Speech Recognition; T. Ochiai et al., 2017; <a href="http://proceedings.mlr.press/v70/ochiai17a/ochiai17a.pdf" target="_blank" rel="noopener noreferrer">http://proceedings.mlr.press/v70/ochiai17a/ochiai17a.pdf</a></p><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p><div class="custom-h4"><p>apply_beamforming<span class="small-bracket">(data, ilens, psd_n, psd_speech, psd_distortion=None, rtf_mat=None, spk=0)</span></p></div><p>Beamforming with the provided statistics.</p><ul><li><strong>Parameters:</strong><ul><li><strong>data</strong> (<em>torch.complex64/ComplexTensor</em>) – (B, F, C, T)</li><li><strong>ilens</strong> (<em>torch.Tensor</em>) – (B,)</li><li><strong>psd_n</strong> (<em>torch.complex64/ComplexTensor</em>) – Noise covariance matrix for MVDR (B, F, C, C) Observation covariance matrix for MPDR/wMPDR (B, F, C, C) Stacked observation covariance for WPD (B,F,(btaps+1)*C,(btaps+1)*C)</li><li><strong>psd_speech</strong> (<em>torch.complex64/ComplexTensor</em>) – Speech covariance matrix (B, F, C, C)</li><li><strong>psd_distortion</strong> (<em>torch.complex64/ComplexTensor</em>) – Noise covariance matrix (B, F, C, C)</li><li><strong>rtf_mat</strong> (<em>torch.complex64/ComplexTensor</em>) – RTF matrix (B, F, C, num_spk)</li><li><strong>spk</strong> (<em>int</em>) – speaker index</li></ul></li><li><strong>Returns:</strong> (B, F, T) ws (torch.complex64/ComplexTensor): (B, F) or (B, F, (btaps+1)*C)</li><li><strong>Return type:</strong> enhanced (torch.complex64/ComplexTensor)</li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(data: Tensor | ComplexTensor, ilens: LongTensor, powers: List[Tensor] | None = None, oracle_masks: List[Tensor] | None = None)</span></p></div><p>DNN_Beamformer forward function.</p><p>Notation: : B: Batch C: Channel T: Time or Sequence length F: Freq</p><ul><li><strong>Parameters:</strong><ul><li><strong>data</strong> (<em>torch.complex64/ComplexTensor</em>) – (B, T, C, F)</li><li><strong>ilens</strong> (<em>torch.Tensor</em>) – (B,)</li><li><strong>powers</strong> (<em>List</em> *[*<em>torch.Tensor</em> <em>] or</em> <em>None</em>) – used for wMPDR or WPD (B, F, T)</li><li><strong>oracle_masks</strong> (<em>List</em> *[*<em>torch.Tensor</em> <em>] or</em> <em>None</em>) – oracle masks (B, F, C, T) if not None, oracle_masks will be used instead of self.mask</li></ul></li><li><strong>Returns:</strong> (B, T, F) ilens (torch.Tensor): (B,) masks (torch.Tensor): (B, T, C, F)</li><li><strong>Return type:</strong> enhanced (torch.complex64/ComplexTensor)</li></ul><div class="custom-h4"><p>predict_mask<span class="small-bracket">(data: Tensor | ComplexTensor, ilens: LongTensor)</span></p></div><p>Predict masks for beamforming.</p><ul><li><strong>Parameters:</strong><ul><li><strong>data</strong> (<em>torch.complex64/ComplexTensor</em>) – (B, T, C, F), double precision</li><li><strong>ilens</strong> (<em>torch.Tensor</em>) – (B,)</li></ul></li><li><strong>Returns:</strong> (B, T, C, F) ilens (torch.Tensor): (B,)</li><li><strong>Return type:</strong> masks (torch.Tensor)</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',17);function l(i,m){return n(),o("div",null,[r(" _espnet2.enh.layers.dnn_beamformer.DNN_Beamformer "),a])}const d=e(t,[["render",l],["__file","DNN_Beamformer.html.vue"]]),_=JSON.parse(`{"path":"/guide/espnet2/enh/DNN_Beamformer.html","title":"espnet2.enh.layers.dnn_beamformer.DNN_Beamformer","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.33,"words":400},"filePathRelative":"guide/espnet2/enh/DNN_Beamformer.md","excerpt":"<!-- _espnet2.enh.layers.dnn_beamformer.DNN_Beamformer -->\\n<h1>espnet2.enh.layers.dnn_beamformer.DNN_Beamformer</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.enh.layers.dnn_beamformer.DNN_Beamformer<span class=\\"small-bracket\\">(bidim, btype: str = 'blstmp', blayers: int = 3, bunits: int = 300, bprojs: int = 320, num_spk: int = 1, use_noise_mask: bool = True, nonlinear: str = 'sigmoid', dropout_rate: float = 0.0, badim: int = 320, ref_channel: int = -1, beamformer_type: str = 'mvdr_souden', rtf_iterations: int = 2, mwf_mu: float = 1.0, eps: float = 1e-06, diagonal_loading: bool = True, diag_eps: float = 1e-07, mask_flooring: bool = False, flooring_thres: float = 1e-06, use_torch_solver: bool = True, use_torchaudio_api: bool = False, btaps: int = 5, bdelay: int = 3)</span></p></div>"}`);export{d as comp,_ as data};
