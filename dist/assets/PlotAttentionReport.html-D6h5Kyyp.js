import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,f as s,a as n,o}from"./app-KOUU_Wij.js";const r={},a=n('<h1 id="espnet-asr-asr-mix-utils-plotattentionreport" tabindex="-1"><a class="header-anchor" href="#espnet-asr-asr-mix-utils-plotattentionreport"><span>espnet.asr.asr_mix_utils.PlotAttentionReport</span></a></h1><div class="custom-h3"><p><em>class</em> espnet.asr.asr_mix_utils.PlotAttentionReport<span class="small-bracket">(att_vis_fn, data, outdir, converter, device, reverse=False)</span></p></div><p>Bases: <code>Extension</code></p><p>Plot attention reporter.</p><ul><li><strong>Parameters:</strong><ul><li><strong>att_vis_fn</strong> (<em>espnet.nets.*_backend.e2e_asr.calculate_all_attentions</em>) – Function of attention visualization.</li><li><strong>data</strong> (<em>list</em> *[*<em>tuple</em> *(*<em>str</em> <em>,</em> <em>dict</em> *[*<em>str</em> <em>,</em> <em>dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em> <em>]</em> <em>)</em> <em>]</em>) – List json utt key items.</li><li><strong>outdir</strong> (<em>str</em>) – Directory to save figures.</li><li><strong>converter</strong> (<em>espnet.asr.*_backend.asr.CustomConverter</em>) – CustomConverter object. Function to convert data.</li><li><strong>device</strong> (<em>torch.device</em>) – The destination device to send tensor.</li><li><strong>reverse</strong> (<em>bool</em>) – If True, input and output length are reversed.</li></ul></li></ul><p>Initialize PlotAttentionReport.</p><div class="custom-h4"><p>draw_attention_plot<span class="small-bracket">(att_w)</span></p></div><p>Visualize attention weights matrix.</p><ul><li><strong>Parameters:</strong><strong>att_w</strong> (<em>Tensor</em>) – Attention weight matrix.</li><li><strong>Returns:</strong> pyplot object with attention matrix image.</li><li><strong>Return type:</strong> matplotlib.pyplot</li></ul><div class="custom-h4"><p>get_attention_weight<span class="small-bracket">(idx, att_w, spkr_idx)</span></p></div><p>Transform attention weight in regard to self.reverse.</p><div class="custom-h4"><p>get_attention_weights()</p></div><p>Return attention weights.</p><ul><li><strong>Returns:</strong> attention weights. It’s shape would be : differ from bachend.dtype=float * pytorch-&gt; 1) multi-head case =&gt; (B, H, Lmax, Tmax). 2) <blockquote><p>other case =&gt; (B, Lmax, Tmax).</p></blockquote><ul><li>chainer-&gt; attention weights (B, Lmax, Tmax).</li></ul></li><li><strong>Return type:</strong> arr_ws_sd (numpy.ndarray)</li></ul><div class="custom-h4"><p>log_attentions<span class="small-bracket">(logger, step)</span></p></div><p>Add image files of attention matrix to tensorboard.</p>',16);function i(l,m){return o(),e("div",null,[s(" _espnet.asr.asr_mix_utils.PlotAttentionReport "),a])}const d=t(r,[["render",i],["__file","PlotAttentionReport.html.vue"]]),u=JSON.parse('{"path":"/guide/espnet/asr/PlotAttentionReport.html","title":"espnet.asr.asr_mix_utils.PlotAttentionReport","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.73,"words":218},"filePathRelative":"guide/espnet/asr/PlotAttentionReport.md","excerpt":"<!-- _espnet.asr.asr_mix_utils.PlotAttentionReport -->\\n<h1>espnet.asr.asr_mix_utils.PlotAttentionReport</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.asr.asr_mix_utils.PlotAttentionReport<span class=\\"small-bracket\\">(att_vis_fn, data, outdir, converter, device, reverse=False)</span></p></div>\\n"}');export{d as comp,u as data};
