import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,f as n,a as o,o as s}from"./app-KOUU_Wij.js";const r={},a=o('<h1 id="espnet-nets-pytorch-backend-rnn-attentions-attforwardta" tabindex="-1"><a class="header-anchor" href="#espnet-nets-pytorch-backend-rnn-attentions-attforwardta"><span>espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA</span></a></h1><div class="custom-h3"><p><em>class</em> espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA<span class="small-bracket">(eunits, dunits, att_dim, aconv_chans, aconv_filts, odim)</span></p></div><p>Bases: <code>Module</code></p><p>Forward attention with transition agent module.</p><p>Reference: Forward attention in sequence-to-sequence acoustic modeling for speech synthesis</p><blockquote><p>(<a href="https://arxiv.org/pdf/1807.06736.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1807.06736.pdf</a>)</p></blockquote><ul><li><strong>Parameters:</strong><ul><li><strong>eunits</strong> (<em>int</em>) – # units of encoder</li><li><strong>dunits</strong> (<em>int</em>) – # units of decoder</li><li><strong>att_dim</strong> (<em>int</em>) – attention dimension</li><li><strong>aconv_chans</strong> (<em>int</em>) – # channels of attention convolution</li><li><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</li><li><strong>odim</strong> (<em>int</em>) – output dimension</li></ul></li></ul><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p><div class="custom-h4"><p>forward<span class="small-bracket">(enc_hs_pad, enc_hs_len, dec_z, att_prev, out_prev, scaling=1.0, last_attended_idx=None, backward_window=1, forward_window=3)</span></p></div><p>Calculate AttForwardTA forward propagation.</p><ul><li><strong>Parameters:</strong><ul><li><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B, Tmax, eunits)</li><li><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</li><li><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B, dunits)</li><li><strong>att_prev</strong> (<em>torch.Tensor</em>) – attention weights of previous step</li><li><strong>out_prev</strong> (<em>torch.Tensor</em>) – decoder outputs of previous step (B, odim)</li><li><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</li><li><strong>last_attended_idx</strong> (<em>int</em>) – index of the inputs of the last attended</li><li><strong>backward_window</strong> (<em>int</em>) – backward window size in attention constraint</li><li><strong>forward_window</strong> (<em>int</em>) – forward window size in attetion constraint</li></ul></li><li><strong>Returns:</strong> attention weighted encoder state (B, dunits)</li><li><strong>Return type:</strong> torch.Tensor</li><li><strong>Returns:</strong> previous attention weights (B, Tmax)</li><li><strong>Return type:</strong> torch.Tensor</li></ul><div class="custom-h4"><p>reset()</p></div><div class="custom-h4"><p>training <em>: bool</em></p></div>',13);function i(d,l){return s(),e("div",null,[n(" _espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA "),a])}const m=t(r,[["render",i],["__file","AttForwardTA.html.vue"]]),g=JSON.parse('{"path":"/guide/espnet/nets/AttForwardTA.html","title":"espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.77,"words":232},"filePathRelative":"guide/espnet/nets/AttForwardTA.md","excerpt":"<!-- _espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA -->\\n<h1>espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA<span class=\\"small-bracket\\">(eunits, dunits, att_dim, aconv_chans, aconv_filts, odim)</span></p></div>"}');export{m as comp,g as data};
