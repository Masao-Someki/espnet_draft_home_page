import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,f as n,a as t,o as r}from"./app-KOUU_Wij.js";const s={},i=t('<h1 id="espnet2-gan-svs-vits-generator-visingergenerator" tabindex="-1"><a class="header-anchor" href="#espnet2-gan-svs-vits-generator-visingergenerator"><span>espnet2.gan_svs.vits.generator.VISingerGenerator</span></a></h1><div class="custom-h3"><p><em>class</em> espnet2.gan_svs.vits.generator.VISingerGenerator<span class="small-bracket">(vocabs: int, aux_channels: int = 513, hidden_channels: int = 192, spks: int | None = None, langs: int | None = None, spk_embed_dim: int | None = None, global_channels: int = -1, segment_size: int = 32, text_encoder_attention_heads: int = 2, text_encoder_ffn_expand: int = 4, text_encoder_blocks: int = 6, text_encoder_positionwise_layer_type: str = &#39;conv1d&#39;, text_encoder_positionwise_conv_kernel_size: int = 1, text_encoder_positional_encoding_layer_type: str = &#39;rel_pos&#39;, text_encoder_self_attention_layer_type: str = &#39;rel_selfattn&#39;, text_encoder_activation_type: str = &#39;swish&#39;, text_encoder_normalize_before: bool = True, text_encoder_dropout_rate: float = 0.1, text_encoder_positional_dropout_rate: float = 0.0, text_encoder_attention_dropout_rate: float = 0.0, text_encoder_conformer_kernel_size: int = 7, use_macaron_style_in_text_encoder: bool = True, use_conformer_conv_in_text_encoder: bool = True, decoder_kernel_size: int = 7, decoder_channels: int = 512, decoder_downsample_scales: List[int] = [2, 2, 8, 8], decoder_downsample_kernel_sizes: List[int] = [4, 4, 16, 16], decoder_upsample_scales: List[int] = [8, 8, 2, 2], decoder_upsample_kernel_sizes: List[int] = [16, 16, 4, 4], decoder_resblock_kernel_sizes: List[int] = [3, 7, 11], decoder_resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], use_avocodo=False, projection_filters: List[int] = [0, 1, 1, 1], projection_kernels: List[int] = [0, 5, 7, 11], n_harmonic: int = 64, use_weight_norm_in_decoder: bool = True, posterior_encoder_kernel_size: int = 5, posterior_encoder_layers: int = 16, posterior_encoder_stacks: int = 1, posterior_encoder_base_dilation: int = 1, posterior_encoder_dropout_rate: float = 0.0, use_weight_norm_in_posterior_encoder: bool = True, flow_flows: int = 4, flow_kernel_size: int = 5, flow_base_dilation: int = 1, flow_layers: int = 4, flow_dropout_rate: float = 0.0, use_weight_norm_in_flow: bool = True, use_only_mean_in_flow: bool = True, generator_type: str = &#39;visinger&#39;, vocoder_generator_type: str = &#39;hifigan&#39;, fs: int = 22050, hop_length: int = 256, win_length: int | None = 1024, n_fft: int = 1024, use_phoneme_predictor: bool = False, expand_f0_method: str = &#39;repeat&#39;, hubert_channels: int = 0)</span></p></div><p>Bases: <code>Module</code></p><p>Generator module in VISinger.</p><p>Initialize VITS generator module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>vocabs</strong> (<em>int</em>) – Input vocabulary size.</li><li><strong>aux_channels</strong> (<em>int</em>) – Number of acoustic feature channels.</li><li><strong>hidden_channels</strong> (<em>int</em>) – Number of hidden channels.</li><li><strong>spks</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Number of speakers. If set to &gt; 1, assume that the sids will be provided as the input and use sid embedding layer.</li><li><strong>langs</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Number of languages. If set to &gt; 1, assume that the lids will be provided as the input and use sid embedding layer.</li><li><strong>spk_embed_dim</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Speaker embedding dimension. If set to &gt; 0, assume that spembs will be provided as the input.</li><li><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</li><li><strong>segment_size</strong> (<em>int</em>) – Segment size for decoder.</li><li><strong>text_encoder_attention_heads</strong> (<em>int</em>) – Number of heads in conformer block of text encoder.</li><li><strong>text_encoder_ffn_expand</strong> (<em>int</em>) – Expansion ratio of FFN in conformer block of text encoder.</li><li><strong>text_encoder_blocks</strong> (<em>int</em>) – Number of conformer blocks in text encoder.</li><li><strong>text_encoder_positionwise_layer_type</strong> (<em>str</em>) – Position-wise layer type in conformer block of text encoder.</li><li><strong>text_encoder_positionwise_conv_kernel_size</strong> (<em>int</em>) – Position-wise convolution kernel size in conformer block of text encoder. Only used when the above layer type is conv1d or conv1d-linear.</li><li><strong>text_encoder_positional_encoding_layer_type</strong> (<em>str</em>) – Positional encoding layer type in conformer block of text encoder.</li><li><strong>text_encoder_self_attention_layer_type</strong> (<em>str</em>) – Self-attention layer type in conformer block of text encoder.</li><li><strong>text_encoder_activation_type</strong> (<em>str</em>) – Activation function type in conformer block of text encoder.</li><li><strong>text_encoder_normalize_before</strong> (<em>bool</em>) – Whether to apply layer norm before self-attention in conformer block of text encoder.</li><li><strong>text_encoder_dropout_rate</strong> (<em>float</em>) – Dropout rate in conformer block of text encoder.</li><li><strong>text_encoder_positional_dropout_rate</strong> (<em>float</em>) – Dropout rate for positional encoding in conformer block of text encoder.</li><li><strong>text_encoder_attention_dropout_rate</strong> (<em>float</em>) – Dropout rate for attention in conformer block of text encoder.</li><li><strong>text_encoder_conformer_kernel_size</strong> (<em>int</em>) – Conformer conv kernel size. It will be used when only use_conformer_conv_in_text_encoder = True.</li><li><strong>use_macaron_style_in_text_encoder</strong> (<em>bool</em>) – Whether to use macaron style FFN in conformer block of text encoder.</li><li><strong>use_conformer_conv_in_text_encoder</strong> (<em>bool</em>) – Whether to use covolution in conformer block of text encoder.</li><li><strong>decoder_kernel_size</strong> (<em>int</em>) – Decoder kernel size.</li><li><strong>decoder_channels</strong> (<em>int</em>) – Number of decoder initial channels.</li><li><strong>decoder_downsample_scales</strong> (<em>List</em> *[*<em>int</em> <em>]</em>) – List of downsampling scales in decoder.</li><li><strong>decoder_downsample_kernel_sizes</strong> (<em>List</em> *[*<em>int</em> <em>]</em>) – List of kernel sizes for downsampling layers in decoder.</li><li><strong>decoder_upsample_scales</strong> (<em>List</em> *[*<em>int</em> <em>]</em>) – List of upsampling scales in decoder.</li><li><strong>decoder_upsample_kernel_sizes</strong> (<em>List</em> *[*<em>int</em> <em>]</em>) – List of kernel sizes for upsampling layers in decoder.</li><li><strong>decoder_resblock_kernel_sizes</strong> (<em>List</em> *[*<em>int</em> <em>]</em>) – List of kernel sizes for resblocks in decoder.</li><li><strong>decoder_resblock_dilations</strong> (<em>List</em> *[*<em>List</em> *[*<em>int</em> <em>]</em> <em>]</em>) – List of list of dilations for resblocks in decoder.</li><li><strong>use_avocodo</strong> (<em>bool</em>) – Whether to use Avocodo model in the generator.</li><li><strong>projection_filters</strong> (<em>List</em> *[*<em>int</em> <em>]</em>) – List of projection filter sizes.</li><li><strong>projection_kernels</strong> (<em>List</em> *[*<em>int</em> <em>]</em>) – List of projection kernel sizes.</li><li><strong>n_harmonic</strong> (<em>int</em>) – Number of harmonic components.</li><li><strong>use_weight_norm_in_decoder</strong> (<em>bool</em>) – Whether to apply weight normalization in decoder.</li><li><strong>posterior_encoder_kernel_size</strong> (<em>int</em>) – Posterior encoder kernel size.</li><li><strong>posterior_encoder_layers</strong> (<em>int</em>) – Number of layers of posterior encoder.</li><li><strong>posterior_encoder_stacks</strong> (<em>int</em>) – Number of stacks of posterior encoder.</li><li><strong>posterior_encoder_base_dilation</strong> (<em>int</em>) – Base dilation of posterior encoder.</li><li><strong>posterior_encoder_dropout_rate</strong> (<em>float</em>) – Dropout rate for posterior encoder.</li><li><strong>use_weight_norm_in_posterior_encoder</strong> (<em>bool</em>) – Whether to apply weight normalization in posterior encoder.</li><li><strong>flow_flows</strong> (<em>int</em>) – Number of flows in flow.</li><li><strong>flow_kernel_size</strong> (<em>int</em>) – Kernel size in flow.</li><li><strong>flow_base_dilation</strong> (<em>int</em>) – Base dilation in flow.</li><li><strong>flow_layers</strong> (<em>int</em>) – Number of layers in flow.</li><li><strong>flow_dropout_rate</strong> (<em>float</em>) – Dropout rate in flow</li><li><strong>use_weight_norm_in_flow</strong> (<em>bool</em>) – Whether to apply weight normalization in flow.</li><li><strong>use_only_mean_in_flow</strong> (<em>bool</em>) – Whether to use only mean in flow.</li><li><strong>generator_type</strong> (<em>str</em>) – Type of generator to use for the model.</li><li><strong>vocoder_generator_type</strong> (<em>str</em>) – Type of vocoder generator to use for the model.</li><li><strong>fs</strong> (<em>int</em>) – Sample rate of the audio.</li><li><strong>hop_length</strong> (<em>int</em>) – Number of samples between successive frames in STFT.</li><li><strong>win_length</strong> (<em>int</em>) – Window size of the STFT.</li><li><strong>n_fft</strong> (<em>int</em>) – Length of the FFT window to be used.</li><li><strong>use_phoneme_predictor</strong> (<em>bool</em>) – Whether to use phoneme predictor in the model.</li><li><strong>expand_f0_method</strong> (<em>str</em>) – The method used to expand F0. Use “repeat” or “interpolation”.</li><li><strong>hubert_channels</strong> (<em>int</em>) – Number of channels in the Hubert model. This is used in VISinger2 Plus.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(text: Tensor, text_lengths: Tensor, feats: Tensor, feats_lengths: Tensor, label: Tensor | None = None, label_lengths: Tensor | None = None, melody: Tensor | None = None, gt_dur: Tensor | None = None, score_dur: Tensor | None = None, slur: Tensor | None = None, pitch: Tensor | None = None, ying: Tensor | None = None, sids: Tensor | None = None, spembs: Tensor | None = None, lids: Tensor | None = None)</span></p></div><p>Calculate forward propagation.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>LongTensor</em>) – Batch of padded character ids (B, Tmax).</li><li><strong>text_lengths</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</li><li><strong>feats_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</li><li><strong>label</strong> (<em>LongTensor</em>) – Batch of padded label ids (B, Tmax).</li><li><strong>label_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of padded label ids (B, ).</li><li><strong>melody</strong> (<em>LongTensor</em>) – Batch of padded midi (B, Tmax).</li><li><strong>gt_dur</strong> (<em>LongTensor</em>) – Batch of padded ground truth duration (B, Tmax).</li><li><strong>score_dur</strong> (<em>LongTensor</em>) – Batch of padded score duration (B, Tmax).</li><li><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, Tmax).</li><li><strong>ying</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of padded ying (B, Tmax).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker embeddings (B, spk_embed_dim).</li><li><strong>sids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker IDs (B, 1).</li><li><strong>lids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of language IDs (B, 1).</li></ul></li><li><strong>Returns:</strong> Waveform tensor (B, 1, segment_size * upsample_factor). Tensor: Duration negative log-likelihood (NLL) tensor (B,). Tensor: Monotonic attention weight tensor (B, 1, T_feats, T_text). Tensor: Segments start index tensor (B,). Tensor: Text mask tensor (B, 1, T_text). Tensor: Feature mask tensor (B, 1, T_feats). tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]: <blockquote><ul><li>Tensor: Posterior encoder hidden representation (B, H, T_feats).</li><li>Tensor: Flow hidden representation (B, H, T_feats).</li><li>Tensor: Expanded text encoder projected mean (B, H, T_feats).</li><li>Tensor: Expanded text encoder projected scale (B, H, T_feats).</li><li>Tensor: Posterior encoder projected mean (B, H, T_feats).</li><li>Tensor: Posterior encoder projected scale (B, H, T_feats).</li></ul></blockquote></li><li><strong>Return type:</strong> Tensor</li></ul><div class="custom-h4"><p>inference<span class="small-bracket">(text: Tensor, text_lengths: Tensor, feats: Tensor | None = None, feats_lengths: Tensor | None = None, label: Tensor | None = None, label_lengths: Tensor | None = None, melody: Tensor | None = None, score_dur: Tensor | None = None, slur: Tensor | None = None, gt_dur: Tensor | None = None, pitch: Tensor | None = None, sids: Tensor | None = None, spembs: Tensor | None = None, lids: Tensor | None = None, noise_scale: float = 0.667, noise_scale_dur: float = 0.8, alpha: float = 1.0, max_len: int | None = None, use_teacher_forcing: bool = False)</span></p></div><p>Run inference.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>LongTensor</em>) – Batch of padded character ids (B, Tmax).</li><li><strong>text_lengths</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</li><li><strong>feats_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</li><li><strong>label</strong> (<em>LongTensor</em>) – Batch of padded label ids (B, Tmax).</li><li><strong>label_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of padded label ids (B, ).</li><li><strong>melody</strong> (<em>LongTensor</em>) – Batch of padded midi (B, Tmax).</li><li><strong>gt_dur</strong> (<em>LongTensor</em>) – Batch of padded ground truth duration (B, Tmax).</li><li><strong>score_dur</strong> (<em>LongTensor</em>) – Batch of padded score duration (B, Tmax).</li><li><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, Tmax).</li><li><strong>ying</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of padded ying (B, Tmax).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker embeddings (B, spk_embed_dim).</li><li><strong>sids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker IDs (B, 1).</li><li><strong>lids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of language IDs (B, 1).</li><li><strong>noise_scale</strong> (<em>float</em>) – Noise scale parameter for flow.</li><li><strong>noise_scale_dur</strong> (<em>float</em>) – Noise scale parameter for duration predictor.</li><li><strong>alpha</strong> (<em>float</em>) – Alpha parameter to control the speed of generated speech.</li><li><strong>max_len</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Maximum length of acoustic feature sequence.</li><li><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</li></ul></li><li><strong>Returns:</strong> Generated waveform tensor (B, T_wav).</li><li><strong>Return type:</strong> Tensor</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',13);function l(a,_){return r(),o("div",null,[n(" _espnet2.gan_svs.vits.generator.VISingerGenerator "),i])}const c=e(s,[["render",l],["__file","VISingerGenerator.html.vue"]]),g=JSON.parse(`{"path":"/guide/espnet2/gan_svs/VISingerGenerator.html","title":"espnet2.gan_svs.vits.generator.VISingerGenerator","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":4.88,"words":1464},"filePathRelative":"guide/espnet2/gan_svs/VISingerGenerator.md","excerpt":"<!-- _espnet2.gan_svs.vits.generator.VISingerGenerator -->\\n<h1>espnet2.gan_svs.vits.generator.VISingerGenerator</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.gan_svs.vits.generator.VISingerGenerator<span class=\\"small-bracket\\">(vocabs: int, aux_channels: int = 513, hidden_channels: int = 192, spks: int | None = None, langs: int | None = None, spk_embed_dim: int | None = None, global_channels: int = -1, segment_size: int = 32, text_encoder_attention_heads: int = 2, text_encoder_ffn_expand: int = 4, text_encoder_blocks: int = 6, text_encoder_positionwise_layer_type: str = 'conv1d', text_encoder_positionwise_conv_kernel_size: int = 1, text_encoder_positional_encoding_layer_type: str = 'rel_pos', text_encoder_self_attention_layer_type: str = 'rel_selfattn', text_encoder_activation_type: str = 'swish', text_encoder_normalize_before: bool = True, text_encoder_dropout_rate: float = 0.1, text_encoder_positional_dropout_rate: float = 0.0, text_encoder_attention_dropout_rate: float = 0.0, text_encoder_conformer_kernel_size: int = 7, use_macaron_style_in_text_encoder: bool = True, use_conformer_conv_in_text_encoder: bool = True, decoder_kernel_size: int = 7, decoder_channels: int = 512, decoder_downsample_scales: List[int] = [2, 2, 8, 8], decoder_downsample_kernel_sizes: List[int] = [4, 4, 16, 16], decoder_upsample_scales: List[int] = [8, 8, 2, 2], decoder_upsample_kernel_sizes: List[int] = [16, 16, 4, 4], decoder_resblock_kernel_sizes: List[int] = [3, 7, 11], decoder_resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], use_avocodo=False, projection_filters: List[int] = [0, 1, 1, 1], projection_kernels: List[int] = [0, 5, 7, 11], n_harmonic: int = 64, use_weight_norm_in_decoder: bool = True, posterior_encoder_kernel_size: int = 5, posterior_encoder_layers: int = 16, posterior_encoder_stacks: int = 1, posterior_encoder_base_dilation: int = 1, posterior_encoder_dropout_rate: float = 0.0, use_weight_norm_in_posterior_encoder: bool = True, flow_flows: int = 4, flow_kernel_size: int = 5, flow_base_dilation: int = 1, flow_layers: int = 4, flow_dropout_rate: float = 0.0, use_weight_norm_in_flow: bool = True, use_only_mean_in_flow: bool = True, generator_type: str = 'visinger', vocoder_generator_type: str = 'hifigan', fs: int = 22050, hop_length: int = 256, win_length: int | None = 1024, n_fft: int = 1024, use_phoneme_predictor: bool = False, expand_f0_method: str = 'repeat', hubert_channels: int = 0)</span></p></div>"}`);export{c as comp,g as data};
