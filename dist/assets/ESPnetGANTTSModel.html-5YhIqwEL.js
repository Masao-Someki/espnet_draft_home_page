import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r,c as o,f as a,b as e,d as l,e as i,w as m,a as t,o as g}from"./app-KOUU_Wij.js";const c={},p=t('<h1 id="espnet2-gan-tts-espnet-model-espnetganttsmodel" tabindex="-1"><a class="header-anchor" href="#espnet2-gan-tts-espnet-model-espnetganttsmodel"><span>espnet2.gan_tts.espnet_model.ESPnetGANTTSModel</span></a></h1><div class="custom-h3"><p><em>class</em> espnet2.gan_tts.espnet_model.ESPnetGANTTSModel<span class="small-bracket">(feats_extract: <a href="../tts/AbsFeatsExtract.md#espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract">AbsFeatsExtract</a></span> | None, normalize: <a href="../layers/InversibleInterface.md#espnet2.layers.inversible_interface.InversibleInterface">InversibleInterface</a> | None, pitch_extract: <a href="../tts/AbsFeatsExtract.md#espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract">AbsFeatsExtract</a> | None, pitch_normalize: <a href="../layers/InversibleInterface.md#espnet2.layers.inversible_interface.InversibleInterface">InversibleInterface</a> | None, energy_extract: <a href="../tts/AbsFeatsExtract.md#espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract">AbsFeatsExtract</a> | None, energy_normalize: <a href="../layers/InversibleInterface.md#espnet2.layers.inversible_interface.InversibleInterface">InversibleInterface</a> | None, tts: <a href="AbsGANTTS.md#espnet2.gan_tts.abs_gan_tts.AbsGANTTS">AbsGANTTS</a>)</p></div>',2),d=e("code",null,"AbsGANESPnetModel",-1),_=t('<p>ESPnet model for GAN-based text-to-speech task.</p><p>Initialize ESPnetGANTTSModel module.</p><div class="custom-h4"><p>collect_feats<span class="small-bracket">(text: Tensor, text_lengths: Tensor, speech: Tensor, speech_lengths: Tensor, durations: Tensor | None = None, durations_lengths: Tensor | None = None, pitch: Tensor | None = None, pitch_lengths: Tensor | None = None, energy: Tensor | None = None, energy_lengths: Tensor | None = None, spembs: Tensor | None = None, sids: Tensor | None = None, lids: Tensor | None = None, **kwargs)</span></p></div><p>Calculate features and return them as a dict.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</li><li><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</li><li><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</li><li><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B, 1).</li><li><strong>durations</strong> (<em>Optional</em> *[*<em>Tensor</em>) – Duration tensor.</li><li><strong>durations_lengths</strong> (<em>Optional</em> *[*<em>Tensor</em>) – Duration length tensor (B,).</li><li><strong>pitch</strong> (<em>Optional</em> *[*<em>Tensor</em>) – Pitch tensor.</li><li><strong>pitch_lengths</strong> (<em>Optional</em> *[*<em>Tensor</em>) – Pitch length tensor (B,).</li><li><strong>energy</strong> (<em>Optional</em> *[*<em>Tensor</em>) – Energy tensor.</li><li><strong>energy_lengths</strong> (<em>Optional</em> *[*<em>Tensor</em>) – Energy length tensor (B,).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker embedding tensor (B, D).</li><li><strong>sids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker index tensor (B, 1).</li><li><strong>lids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Language ID tensor (B, 1).</li></ul></li><li><strong>Returns:</strong> Dict of features.</li><li><strong>Return type:</strong> Dict[str, Tensor]</li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(text: Tensor, text_lengths: Tensor, speech: Tensor, speech_lengths: Tensor, durations: Tensor | None = None, durations_lengths: Tensor | None = None, pitch: Tensor | None = None, pitch_lengths: Tensor | None = None, energy: Tensor | None = None, energy_lengths: Tensor | None = None, spembs: Tensor | None = None, sids: Tensor | None = None, lids: Tensor | None = None, forward_generator: bool = True, **kwargs)</span></p></div><p>Return generator or discriminator loss with dict format.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</li><li><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</li><li><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</li><li><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B,).</li><li><strong>duration</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Duration tensor.</li><li><strong>duration_lengths</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Duration length tensor (B,).</li><li><strong>pitch</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Pitch tensor.</li><li><strong>pitch_lengths</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Pitch length tensor (B,).</li><li><strong>energy</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Energy tensor.</li><li><strong>energy_lengths</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Energy length tensor (B,).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker embedding tensor (B, D).</li><li><strong>sids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker ID tensor (B, 1).</li><li><strong>lids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Language ID tensor (B, 1).</li><li><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</li><li><strong>kwargs</strong> – “utt_id” is among the input.</li></ul></li><li><strong>Returns:</strong><ul><li>loss (Tensor): Loss scalar tensor.</li><li>stats (Dict[str, float]): Statistics to be monitored.</li><li>weight (Tensor): Weight tensor to summarize losses.</li><li>optim_idx (int): Optimizer index (0 for G and 1 for D).</li></ul></li><li><strong>Return type:</strong> Dict[str, Any]</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',9);function h(T,f){const s=r("RouteLink");return g(),o("div",null,[a(" _espnet2.gan_tts.espnet_model.ESPnetGANTTSModel "),p,e("p",null,[l("Bases: "),i(s,{to:"/guide/espnet2/train/AbsGANESPnetModel.html#espnet2.train.abs_gan_espnet_model.AbsGANESPnetModel"},{default:m(()=>[d]),_:1})]),_])}const x=n(c,[["render",h],["__file","ESPnetGANTTSModel.html.vue"]]),u=JSON.parse('{"path":"/guide/espnet2/gan_tts/ESPnetGANTTSModel.html","title":"espnet2.gan_tts.espnet_model.ESPnetGANTTSModel","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.63,"words":489},"filePathRelative":"guide/espnet2/gan_tts/ESPnetGANTTSModel.md","excerpt":"<!-- _espnet2.gan_tts.espnet_model.ESPnetGANTTSModel -->\\n<h1>espnet2.gan_tts.espnet_model.ESPnetGANTTSModel</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.gan_tts.espnet_model.ESPnetGANTTSModel<span class=\\"small-bracket\\">(feats_extract: <a href=\\"../tts/AbsFeatsExtract.md#espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract\\">AbsFeatsExtract</a></span> | None, normalize: <a href=\\"../layers/InversibleInterface.md#espnet2.layers.inversible_interface.InversibleInterface\\">InversibleInterface</a> | None, pitch_extract: <a href=\\"../tts/AbsFeatsExtract.md#espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract\\">AbsFeatsExtract</a> | None, pitch_normalize: <a href=\\"../layers/InversibleInterface.md#espnet2.layers.inversible_interface.InversibleInterface\\">InversibleInterface</a> | None, energy_extract: <a href=\\"../tts/AbsFeatsExtract.md#espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract\\">AbsFeatsExtract</a> | None, energy_normalize: <a href=\\"../layers/InversibleInterface.md#espnet2.layers.inversible_interface.InversibleInterface\\">InversibleInterface</a> | None, tts: <a href=\\"AbsGANTTS.md#espnet2.gan_tts.abs_gan_tts.AbsGANTTS\\">AbsGANTTS</a>)</p></div>"}');export{x as comp,u as data};
