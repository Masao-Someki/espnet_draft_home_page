import{_ as r}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as o,c as n,f as a,b as e,d as t,e as i,w as l,a as d,o as c}from"./app-KOUU_Wij.js";const u={},p=e("h1",{id:"espnet2-asr-transducer-decoder-mega-decoder-megadecoder",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-asr-transducer-decoder-mega-decoder-megadecoder"},[e("span",null,"espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder")])],-1),_=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder"),e("span",{class:"small-bracket"},"(vocab_size: int, block_size: int = 512, linear_size: int = 1024, qk_size: int = 128, v_size: int = 1024, num_heads: int = 4, rel_pos_bias_type: str = 'simple', max_positions: int = 2048, truncation_length: int | None = None, normalization_type: str = 'layer_norm', normalization_args: Dict = {}, activation_type: str = 'swish', activation_args: Dict = {}, chunk_size: int = -1, num_blocks: int = 4, dropout_rate: float = 0.0, embed_dropout_rate: float = 0.0, att_dropout_rate: float = 0.0, ema_dropout_rate: float = 0.0, ffn_dropout_rate: float = 0.0, embed_pad: int = 0)")])],-1),g=e("code",null,"AbsDecoder",-1),m=d('<p>MEGA decoder module.</p><p>Based on <a href="https://arxiv.org/pdf/2209.10655.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2209.10655.pdf</a>.</p><ul><li><strong>Parameters:</strong><ul><li><strong>vocab_size</strong> – Vocabulary size.</li><li><strong>block_size</strong> – Input/Output size.</li><li><strong>linear_size</strong> – NormalizedPositionwiseFeedForward hidden size.</li><li><strong>qk_size</strong> – Shared query and key size for attention module.</li><li><strong>v_size</strong> – Value size for attention module.</li><li><strong>num_heads</strong> – Number of EMA heads.</li><li><strong>rel_pos_bias</strong> – Type of relative position bias in attention module.</li><li><strong>max_positions</strong> – Maximum number of position for RelativePositionBias.</li><li><strong>truncation_length</strong> – Maximum length for truncation in EMA module.</li><li><strong>normalization_type</strong> – Normalization layer type.</li><li><strong>normalization_args</strong> – Normalization layer arguments.</li><li><strong>activation_type</strong> – Activation function type.</li><li><strong>activation_args</strong> – Activation function arguments.</li><li><strong>chunk_size</strong> – Chunk size for attention computation (-1 = full context).</li><li><strong>num_blocks</strong> – Number of MEGA blocks.</li><li><strong>dropout_rate</strong> – Dropout rate for MEGA internal modules.</li><li><strong>embed_dropout_rate</strong> – Dropout rate for embedding layer.</li><li><strong>att_dropout_rate</strong> – Dropout rate for the attention module.</li><li><strong>ema_dropout_rate</strong> – Dropout rate for the EMA module.</li><li><strong>ffn_dropout_rate</strong> – Dropout rate for the feed-forward module.</li><li><strong>embed_pad</strong> – Embedding padding symbol ID.</li></ul></li></ul><p>Construct a MEGADecoder object.</p><div class="custom-h4"><p>batch_score<span class="small-bracket">(hyps: List[<a href="Hypothesis.md#espnet2.asr_transducer.beam_search_transducer.Hypothesis">Hypothesis</a></span>])</p></div><p>One-step forward hypotheses.</p><ul><li><strong>Parameters:</strong><strong>hyps</strong> – Hypotheses.</li><li><strong>Returns:</strong> states:</li><li><strong>Return type:</strong> out</li></ul><div class="custom-h4"><p>create_batch_states<span class="small-bracket">(new_states: List[List[Dict[str, Tensor]]])</span></p></div><p>Create batch of decoder hidden states given a list of new states.</p><ul><li><strong>Parameters:</strong><strong>new_states</strong> – Decoder hidden states. [B x [N x Dict]]</li><li><strong>Returns:</strong> Decoder hidden states. [N x Dict]</li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(labels: Tensor)</span></p></div><p>Encode source label sequences.</p><ul><li><strong>Parameters:</strong><strong>labels</strong> – Decoder input sequences. (B, L)</li><li><strong>Returns:</strong> Decoder output sequences. (B, U, D_dec)</li><li><strong>Return type:</strong> out</li></ul><div class="custom-h4"><p>inference<span class="small-bracket">(labels: Tensor, states: List[Dict[str, Tensor]])</span></p></div><p>Encode source label sequences.</p><ul><li><strong>Parameters:</strong><ul><li><strong>labels</strong> – Decoder input sequences. (B, L)</li><li><strong>states</strong> – Decoder hidden states. [B x Dict]</li></ul></li><li><strong>Returns:</strong> Decoder output sequences. (B, U, D_dec) new_states: Decoder hidden states. [B x Dict]</li><li><strong>Return type:</strong> out</li></ul><div class="custom-h4"><p>init_state<span class="small-bracket">(batch_size: int = 0)</span></p></div><p>Initialize MEGADecoder states.</p><ul><li><strong>Parameters:</strong><strong>batch_size</strong> – Batch size.</li><li><strong>Returns:</strong> Decoder hidden states. [N x Dict]</li><li><strong>Return type:</strong> states</li></ul><div class="custom-h4"><p>score<span class="small-bracket">(label_sequence: List[int], states: List[Dict[str, Tensor]])</span></p></div><p>One-step forward hypothesis.</p><ul><li><strong>Parameters:</strong><ul><li><strong>label_sequence</strong> – Current label sequence.</li><li><strong>states</strong> – Decoder hidden states. (??)</li></ul></li><li><strong>Returns:</strong> Decoder output sequence. (D_dec) states: Decoder hidden states. (??)</li></ul><div class="custom-h4"><p>select_state<span class="small-bracket">(states: List[Dict[str, Tensor]], idx: int)</span></p></div><p>Select ID state from batch of decoder hidden states.</p><ul><li><strong>Parameters:</strong><strong>states</strong> – Decoder hidden states. [N x Dict]</li><li><strong>Returns:</strong> Decoder hidden states for given ID. [N x Dict]</li></ul><div class="custom-h4"><p>set_device<span class="small-bracket">(device: device)</span></p></div><p>Set GPU device to use.</p><ul><li><strong>Parameters:</strong><strong>device</strong> – Device ID.</li></ul><div class="custom-h4"><p>stack_qk_states<span class="small-bracket">(state_list: List[Tensor], dim: int)</span></p></div><p>Stack query or key states with different lengths.</p><ul><li><strong>Parameters:</strong><strong>state_list</strong> – List of query or key states.</li><li><strong>Returns:</strong> Query/Key state.</li><li><strong>Return type:</strong> new_state</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',32);function h(f,b){const s=o("RouteLink");return c(),n("div",null,[a(" _espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder "),p,_,e("p",null,[t("Bases: "),i(s,{to:"/guide/espnet2/asr_transducer/AbsDecoder.html#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder"},{default:l(()=>[g]),_:1})]),m])}const y=r(u,[["render",h],["__file","MEGADecoder.html.vue"]]),z=JSON.parse(`{"path":"/guide/espnet2/asr_transducer/MEGADecoder.html","title":"espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.98,"words":593},"filePathRelative":"guide/espnet2/asr_transducer/MEGADecoder.md","excerpt":"<!-- _espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder -->\\n<h1>espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder<span class=\\"small-bracket\\">(vocab_size: int, block_size: int = 512, linear_size: int = 1024, qk_size: int = 128, v_size: int = 1024, num_heads: int = 4, rel_pos_bias_type: str = 'simple', max_positions: int = 2048, truncation_length: int | None = None, normalization_type: str = 'layer_norm', normalization_args: Dict = {}, activation_type: str = 'swish', activation_args: Dict = {}, chunk_size: int = -1, num_blocks: int = 4, dropout_rate: float = 0.0, embed_dropout_rate: float = 0.0, att_dropout_rate: float = 0.0, ema_dropout_rate: float = 0.0, ffn_dropout_rate: float = 0.0, embed_pad: int = 0)</span></p></div>"}`);export{y as comp,z as data};
