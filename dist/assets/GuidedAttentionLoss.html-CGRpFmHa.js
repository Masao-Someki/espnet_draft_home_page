import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,f as s,a as n,o}from"./app-KOUU_Wij.js";const a={},i=n('<h1 id="espnet-nets-pytorch-backend-e2e-tts-tacotron2-guidedattentionloss" tabindex="-1"><a class="header-anchor" href="#espnet-nets-pytorch-backend-e2e-tts-tacotron2-guidedattentionloss"><span>espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss</span></a></h1><div class="custom-h3"><p><em>class</em> espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss<span class="small-bracket">(sigma=0.4, alpha=1.0, reset_always=True)</span></p></div><p>Bases: <code>Module</code></p><p>Guided attention loss function module.</p><p>This module calculates the guided attention loss described in <a href="https://arxiv.org/abs/1710.08969" target="_blank" rel="noopener noreferrer">Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention</a>, which forces the attention to be diagonal.</p><p>Initialize guided attention loss module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>sigma</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Standard deviation to control how close attention to a diagonal.</li><li><strong>alpha</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Scaling coefficient (lambda).</li><li><strong>reset_always</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – Whether to always reset masks.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(att_ws, ilens, olens)</span></p></div><p>Calculate forward propagation.</p><ul><li><strong>Parameters:</strong><ul><li><strong>att_ws</strong> (<em>Tensor</em>) – Batch of attention weights (B, T_max_out, T_max_in).</li><li><strong>ilens</strong> (<em>LongTensor</em>) – Batch of input lengths (B,).</li><li><strong>olens</strong> (<em>LongTensor</em>) – Batch of output lengths (B,).</li></ul></li><li><strong>Returns:</strong> Guided attention loss value.</li><li><strong>Return type:</strong> Tensor</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',11);function l(r,d){return o(),e("div",null,[s(" _espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss "),i])}const m=t(a,[["render",l],["__file","GuidedAttentionLoss.html.vue"]]),u=JSON.parse('{"path":"/guide/espnet/nets/GuidedAttentionLoss.html","title":"espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.54,"words":162},"filePathRelative":"guide/espnet/nets/GuidedAttentionLoss.md","excerpt":"<!-- _espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss -->\\n<h1>espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss<span class=\\"small-bracket\\">(sigma=0.4, alpha=1.0, reset_always=True)</span></p></div>"}');export{m as comp,u as data};
