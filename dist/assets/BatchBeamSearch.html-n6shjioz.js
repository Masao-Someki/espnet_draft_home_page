import{_ as l}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as a,c as i,f as h,b as e,d as s,e as n,w as o,a as r,o as c}from"./app-KOUU_Wij.js";const _={},p=r('<h1 id="espnet-nets-batch-beam-search-batchbeamsearch" tabindex="-1"><a class="header-anchor" href="#espnet-nets-batch-beam-search-batchbeamsearch"><span>espnet.nets.batch_beam_search.BatchBeamSearch</span></a></h1><div class="custom-h3"><p><em>class</em> espnet.nets.batch_beam_search.BatchBeamSearch<span class="small-bracket">(scorers: Dict[str, <a href="ScorerInterface.md#espnet.nets.scorer_interface.ScorerInterface">ScorerInterface</a></span>], weights: Dict[str, float], beam_size: int, vocab_size: int, sos: int, eos: int, token_list: List[str] | None = None, pre_beam_ratio: float = 1.5, pre_beam_score_key: str | None = None, return_hs: bool = False, hyp_primer: List[int] | None = None, normalize_length: bool = False)</p></div>',2),u=e("code",null,"BeamSearch",-1),m=e("p",null,"Batch beam search implementation.",-1),d=e("p",null,"Initialize beam search.",-1),g=e("strong",null,"Parameters:",-1),f=e("strong",null,"scorers",-1),b=e("em",null,"dict",-1),y=e("em",null,"str",-1),B=e("em",null,",",-1),T=e("em",null,"ScorerInterface",-1),k=e("em",null,"]",-1),H=r("<li><strong>weights</strong> (<em>dict</em> *[*<em>str</em> <em>,</em> <em>float</em> <em>]</em>) – Dict of weights for each scorers The scorer will be ignored if its weight is 0</li><li><strong>beam_size</strong> (<em>int</em>) – The number of hypotheses kept during search</li><li><strong>vocab_size</strong> (<em>int</em>) – The number of vocabulary</li><li><strong>sos</strong> (<em>int</em>) – Start of sequence id</li><li><strong>eos</strong> (<em>int</em>) – End of sequence id</li><li><strong>token_list</strong> (<em>list</em> *[*<em>str</em> <em>]</em>) – List of tokens for debug log</li><li><strong>pre_beam_score_key</strong> (<em>str</em>) – key of scores to perform pre-beam search</li><li><strong>pre_beam_ratio</strong> (<em>float</em>) – beam size in the pre-beam search will be int(pre_beam_ratio * beam_size)</li><li><strong>return_hs</strong> (<em>bool</em>) – Whether to return hidden intermediates</li><li><strong>normalize_length</strong> (<em>bool</em>) – If true, select the best ended hypotheses based on length-normalized scores rather than the accumulated scores</li>",10),v=r('<div class="custom-h4"><p>batch_beam<span class="small-bracket">(weighted_scores: Tensor, ids: Tensor)</span></p></div><p>Batch-compute topk full token ids and partial token ids.</p><ul><li><strong>Parameters:</strong><ul><li><strong>weighted_scores</strong> (<em>torch.Tensor</em>) – The weighted sum scores for each tokens. Its shape is (n_beam, self.vocab_size).</li><li><strong>ids</strong> (<em>torch.Tensor</em>) – The partial token ids to compute topk. Its shape is (n_beam, self.pre_beam_size).</li></ul></li><li><strong>Returns:</strong> The topk full (prev_hyp, new_token) ids and partial (prev_hyp, new_token) ids. Their shapes are all (self.beam_size,)</li><li><strong>Return type:</strong> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]</li></ul><div class="custom-h4"><p>batchfy<span class="small-bracket">(hyps: List[Hypothesis])</span></p></div><p>Convert list to batch.</p><div class="custom-h4"><p>init_hyp<span class="small-bracket">(x: Tensor)</span></p></div><p>Get an initial hypothesis data.</p>',7),x=e("li",null,[e("strong",null,"Parameters:"),e("strong",null,"x"),s(" ("),e("em",null,"torch.Tensor"),s(") – The encoder output feature")],-1),S=e("li",null,[e("strong",null,"Returns:"),s(" The initial hypothesis.")],-1),w=e("strong",null,"Return type:",-1),N=r('<div class="custom-h4"><p>merge_states<span class="small-bracket">(states: Any, part_states: Any, part_idx: int)</span></p></div><p>Merge states for new hypothesis.</p><ul><li><strong>Parameters:</strong><ul><li><strong>states</strong> – states of self.full_scorers</li><li><strong>part_states</strong> – states of self.part_scorers</li><li><strong>part_idx</strong> (<em>int</em>) – The new token id for part_scores</li></ul></li><li><strong>Returns:</strong> The new score dict. : Its keys are names of self.full_scorers and self.part_scorers. Its values are states of the scorers.</li><li><strong>Return type:</strong> Dict[str, torch.Tensor]</li></ul><div class="custom-h4"><p>post_process<span class="small-bracket">(i: int, maxlen: int, minlen: int, maxlenratio: float, running_hyps: <a href="BatchHypothesis.md#espnet.nets.batch_beam_search.BatchHypothesis">BatchHypothesis</a></span>, ended_hyps: List[Hypothesis])</p></div><p>Perform post-processing of beam search iterations.</p>',5),R=e("strong",null,"Parameters:",-1),D=r("<li><strong>i</strong> (<em>int</em>) – The length of hypothesis tokens.</li><li><strong>maxlen</strong> (<em>int</em>) – The maximum length of tokens in beam search.</li><li><strong>maxlenratio</strong> (<em>int</em>) – The maximum length ratio in beam search.</li>",3),z=e("strong",null,"running_hyps",-1),I=e("em",null,"BatchHypothesis",-1),L=e("strong",null,"ended_hyps",-1),P=e("em",null,"List",-1),q=e("em",null,"[",-1),A=e("em",null,"Hypothesis",-1),C=e("em",null,"]",-1),E=e("li",null,[e("strong",null,"Returns:"),s(" The new running hypotheses.")],-1),V=e("strong",null,"Return type:",-1),F=e("div",{class:"custom-h4"},[e("p",null,[s("score_full"),e("span",{class:"small-bracket"},[s("(hyp: "),e("a",{href:"BatchHypothesis.md#espnet.nets.batch_beam_search.BatchHypothesis"},"BatchHypothesis")]),s(", x: Tensor, pre_x: Tensor | None = None)")])],-1),M=e("p",null,"Score new hypothesis by self.full_scorers.",-1),G=e("strong",null,"Parameters:",-1),J=e("strong",null,"hyp",-1),O=e("em",null,"Hypothesis",-1),U=e("li",null,[e("strong",null,"x"),s(" ("),e("em",null,"torch.Tensor"),s(") – Corresponding input feature")],-1),W=e("li",null,[e("strong",null,"pre_x"),s(" ("),e("em",null,"torch.Tensor"),s(") – Encoded speech feature for sequential attn (T, D) Sequential attn computes attn first on pre_x then on x, thereby attending to two sources in sequence.")],-1),j=e("li",null,[e("strong",null,"Returns:"),s(" Tuple of : score dict of hyp that has string keys of self.full_scorers and tensor score values of shape: (self.n_vocab,), and state dict that has string keys and state values of self.full_scorers")],-1),K=e("li",null,[e("strong",null,"Return type:"),s(" Tuple[Dict[str, torch.Tensor], Dict[str, Any]]")],-1),Q=e("div",{class:"custom-h4"},[e("p",null,[s("score_partial"),e("span",{class:"small-bracket"},[s("(hyp: "),e("a",{href:"BatchHypothesis.md#espnet.nets.batch_beam_search.BatchHypothesis"},"BatchHypothesis")]),s(", ids: Tensor, x: Tensor, pre_x: Tensor | None = None)")])],-1),X=e("p",null,"Score new hypothesis by self.full_scorers.",-1),Y=e("strong",null,"Parameters:",-1),Z=e("strong",null,"hyp",-1),$=e("em",null,"Hypothesis",-1),ee=r("<li><strong>ids</strong> (<em>torch.Tensor</em>) – 2D tensor of new partial tokens to score</li><li><strong>x</strong> (<em>torch.Tensor</em>) – Corresponding input feature</li><li><strong>pre_x</strong> (<em>torch.Tensor</em>) – Encoded speech feature for sequential attn (T, D) Sequential attn computes attn first on pre_x then on x, thereby attending to two sources in sequence.</li>",3),se=e("li",null,[e("strong",null,"Returns:"),s(" Tuple of : score dict of hyp that has string keys of self.full_scorers and tensor score values of shape: (self.n_vocab,), and state dict that has string keys and state values of self.full_scorers")],-1),te=e("li",null,[e("strong",null,"Return type:"),s(" Tuple[Dict[str, torch.Tensor], Dict[str, Any]]")],-1),ne=e("div",{class:"custom-h4"},[e("p",null,[s("search"),e("span",{class:"small-bracket"},[s("(running_hyps: "),e("a",{href:"BatchHypothesis.md#espnet.nets.batch_beam_search.BatchHypothesis"},"BatchHypothesis")]),s(", x: Tensor, pre_x: Tensor | None = None)")])],-1),oe=e("p",null,"Search new tokens for running hypotheses and encoded speech x.",-1),re=e("strong",null,"Parameters:",-1),le=e("strong",null,"running_hyps",-1),ae=e("em",null,"BatchHypothesis",-1),ie=e("li",null,[e("strong",null,"x"),s(" ("),e("em",null,"torch.Tensor"),s(") – Encoded speech feature (T, D)")],-1),he=e("li",null,[e("strong",null,"pre_x"),s(" ("),e("em",null,"torch.Tensor"),s(") – Encoded speech feature for sequential attention (T, D)")],-1),ce=e("li",null,[e("strong",null,"Returns:"),s(" Best sorted hypotheses")],-1),_e=e("strong",null,"Return type:",-1),pe=e("div",{class:"custom-h4"},[e("p",null,[s("training "),e("em",null,": bool")])],-1),ue=e("div",{class:"custom-h4"},[e("p",null,[s("unbatchfy"),e("span",{class:"small-bracket"},[s("(batch_hyps: "),e("a",{href:"BatchHypothesis.md#espnet.nets.batch_beam_search.BatchHypothesis"},"BatchHypothesis")]),s(")")])],-1),me=e("p",null,"Revert batch to list.",-1);function de(ge,fe){const t=a("RouteLink");return c(),i("div",null,[h(" _espnet.nets.batch_beam_search.BatchBeamSearch "),p,e("p",null,[s("Bases: "),n(t,{to:"/guide/espnet/nets/BeamSearch.html#espnet.nets.beam_search.BeamSearch"},{default:o(()=>[u]),_:1})]),m,d,e("ul",null,[e("li",null,[g,e("ul",null,[e("li",null,[f,s(" ("),b,s(" *[*"),y,s(),B,s(),n(t,{to:"/guide/espnet/nets/ScorerInterface.html#espnet.nets.scorer_interface.ScorerInterface"},{default:o(()=>[T]),_:1}),s(),k,s(") – Dict of decoder modules e.g., Decoder, CTCPrefixScorer, LM The scorer will be ignored if it is None")]),H])])]),v,e("ul",null,[x,S,e("li",null,[w,n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[s("Hypothesis")]),_:1})])]),N,e("ul",null,[e("li",null,[R,e("ul",null,[D,e("li",null,[z,s(" ("),n(t,{to:"/guide/espnet/nets/BatchHypothesis.html#espnet.nets.batch_beam_search.BatchHypothesis"},{default:o(()=>[I]),_:1}),s(") – The running hypotheses in beam search.")]),e("li",null,[L,s(" ("),P,s(),q,n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[A]),_:1}),s(),C,s(") – The ended hypotheses in beam search.")])])]),E,e("li",null,[V,n(t,{to:"/guide/espnet/nets/BatchHypothesis.html#espnet.nets.batch_beam_search.BatchHypothesis"},{default:o(()=>[s("BatchHypothesis")]),_:1})])]),F,M,e("ul",null,[e("li",null,[G,e("ul",null,[e("li",null,[J,s(" ("),n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[O]),_:1}),s(") – Hypothesis with prefix tokens to score")]),U,W])]),j,K]),Q,X,e("ul",null,[e("li",null,[Y,e("ul",null,[e("li",null,[Z,s(" ("),n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[$]),_:1}),s(") – Hypothesis with prefix tokens to score")]),ee])]),se,te]),ne,oe,e("ul",null,[e("li",null,[re,e("ul",null,[e("li",null,[le,s(" ("),n(t,{to:"/guide/espnet/nets/BatchHypothesis.html#espnet.nets.batch_beam_search.BatchHypothesis"},{default:o(()=>[ae]),_:1}),s(") – Running hypotheses on beam")]),ie,he])]),ce,e("li",null,[_e,n(t,{to:"/guide/espnet/nets/BatchHypothesis.html#espnet.nets.batch_beam_search.BatchHypothesis"},{default:o(()=>[s("BatchHypothesis")]),_:1})])]),pe,ue,me])}const Be=l(_,[["render",de],["__file","BatchBeamSearch.html.vue"]]),Te=JSON.parse('{"path":"/guide/espnet/nets/BatchBeamSearch.html","title":"espnet.nets.batch_beam_search.BatchBeamSearch","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":2.84,"words":851},"filePathRelative":"guide/espnet/nets/BatchBeamSearch.md","excerpt":"<!-- _espnet.nets.batch_beam_search.BatchBeamSearch -->\\n<h1>espnet.nets.batch_beam_search.BatchBeamSearch</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.nets.batch_beam_search.BatchBeamSearch<span class=\\"small-bracket\\">(scorers: Dict[str, <a href=\\"ScorerInterface.md#espnet.nets.scorer_interface.ScorerInterface\\">ScorerInterface</a></span>], weights: Dict[str, float], beam_size: int, vocab_size: int, sos: int, eos: int, token_list: List[str] | None = None, pre_beam_ratio: float = 1.5, pre_beam_score_key: str | None = None, return_hs: bool = False, hyp_primer: List[int] | None = None, normalize_length: bool = False)</p></div>"}');export{Be as comp,Te as data};
