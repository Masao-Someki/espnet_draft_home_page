import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as n,c as o,b as e,d as r,e as a,w as i,a as _,o as l}from"./app-KOUU_Wij.js";const m={},c=e("p",null,"<!-- _espnet2.gan_tts.jets.jets.JETS -->",-1),d=e("h1",{id:"espnet2-gan-tts-jets-jets-jets",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-gan-tts-jets-jets-jets"},[e("span",null,"espnet2.gan_tts.jets.jets.JETS")])],-1),p=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),r(" espnet2.gan_tts.jets.jets.JETS"),e("span",{class:"small-bracket"},"(idim: int, odim: int, sampling_rate: int = 22050, generator_type: str = 'jets_generator', generator_params: Dict[str, Any] = {'adim': 256, 'aheads': 2, 'conformer_activation_type': 'swish', 'conformer_dec_kernel_size': 31, 'conformer_enc_kernel_size': 7, 'conformer_pos_enc_layer_type': 'rel_pos', 'conformer_rel_pos_type': 'latest', 'conformer_self_attn_layer_type': 'rel_selfattn', 'decoder_concat_after': False, 'decoder_normalize_before': True, 'decoder_type': 'transformer', 'dlayers': 4, 'dunits': 1024, 'duration_predictor_chans': 384, 'duration_predictor_dropout_rate': 0.1, 'duration_predictor_kernel_size': 3, 'duration_predictor_layers': 2, 'elayers': 4, 'encoder_concat_after': False, 'encoder_normalize_before': True, 'encoder_type': 'transformer', 'energy_embed_dropout': 0.5, 'energy_embed_kernel_size': 1, 'energy_predictor_chans': 384, 'energy_predictor_dropout': 0.5, 'energy_predictor_kernel_size': 3, 'energy_predictor_layers': 2, 'eunits': 1024, 'generator_bias': True, 'generator_channels': 512, 'generator_global_channels': -1, 'generator_kernel_size': 7, 'generator_nonlinear_activation': 'LeakyReLU', 'generator_nonlinear_activation_params': {'negative_slope': 0.1}, 'generator_out_channels': 1, 'generator_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'generator_resblock_kernel_sizes': [3, 7, 11], 'generator_upsample_kernel_sizes': [16, 16, 4, 4], 'generator_upsample_scales': [8, 8, 2, 2], 'generator_use_additional_convs': True, 'generator_use_weight_norm': True, 'gst_conv_chans_list': [32, 32, 64, 64, 128, 128], 'gst_conv_kernel_size': 3, 'gst_conv_layers': 6, 'gst_conv_stride': 2, 'gst_gru_layers': 1, 'gst_gru_units': 128, 'gst_heads': 4, 'gst_tokens': 10, 'init_dec_alpha': 1.0, 'init_enc_alpha': 1.0, 'init_type': 'xavier_uniform', 'langs': -1, 'pitch_embed_dropout': 0.5, 'pitch_embed_kernel_size': 1, 'pitch_predictor_chans': 384, 'pitch_predictor_dropout': 0.5, 'pitch_predictor_kernel_size': 5, 'pitch_predictor_layers': 5, 'positionwise_conv_kernel_size': 1, 'positionwise_layer_type': 'conv1d', 'reduction_factor': 1, 'segment_size': 64, 'spk_embed_dim': None, 'spk_embed_integration_type': 'add', 'spks': -1, 'stop_gradient_from_energy_predictor': False, 'stop_gradient_from_pitch_predictor': True, 'transformer_dec_attn_dropout_rate': 0.1, 'transformer_dec_dropout_rate': 0.1, 'transformer_dec_positional_dropout_rate': 0.1, 'transformer_enc_attn_dropout_rate': 0.1, 'transformer_enc_dropout_rate': 0.1, 'transformer_enc_positional_dropout_rate': 0.1, 'use_batch_norm': True, 'use_cnn_in_conformer': True, 'use_gst': False, 'use_macaron_style_in_conformer': True, 'use_masking': False, 'use_scaled_pos_enc': True, 'use_weighted_masking': False, 'zero_triu': False}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_adv: float = 1.0, lambda_mel: float = 45.0, lambda_feat_match: float = 2.0, lambda_var: float = 1.0, lambda_align: float = 2.0, cache_generator_outputs: bool = True, plot_pred_mos: bool = False, mos_pred_tool: str = 'utmos')")])],-1),g=e("code",null,"AbsGANTTS",-1),u=_('<p>JETS module (generator + discriminator).</p><p>This is a module of JETS described in</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>`</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to Speech’_.</p><p>&lt;!-- : https://arxiv.org/abs/2203.16852 --&gt;</p><p>Initialize JETS module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</li><li><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will be 1 since JETS is the end-to-end text-to-wave model but for the compatibility odim is used to indicate the acoustic feature dimension.</li><li><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will be referred in saving waveform during the inference.</li><li><strong>generator_type</strong> (<em>str</em>) – Generator type.</li><li><strong>generator_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for generator.</li><li><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</li><li><strong>discriminator_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for discriminator.</li><li><strong>generator_adv_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for generator adversarial loss.</li><li><strong>discriminator_adv_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for discriminator adversarial loss.</li><li><strong>feat_match_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for feat match loss.</li><li><strong>mel_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for mel loss.</li><li><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</li><li><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel spectrogram loss.</li><li><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</li><li><strong>lambda_var</strong> (<em>float</em>) – Loss scaling coefficient for variance loss.</li><li><strong>lambda_align</strong> (<em>float</em>) – Loss scaling coefficient for alignment loss.</li><li><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</li><li><strong>plot_pred_mos</strong> (<em>bool</em>) – Whether to plot predicted MOS during the training.</li><li><strong>mos_pred_tool</strong> (<em>str</em>) – MOS prediction tool name.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(text: Tensor, text_lengths: Tensor, feats: Tensor, feats_lengths: Tensor, speech: Tensor, speech_lengths: Tensor, sids: Tensor | None = None, spembs: Tensor | None = None, lids: Tensor | None = None, forward_generator: bool = True, **kwargs)</span></p></div><p>Perform generator forward.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</li><li><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, T_feats, aux_channels).</li><li><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</li><li><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</li><li><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B,).</li><li><strong>sids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker index tensor (B,) or (B, 1).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker embedding tensor (B, spk_embed_dim).</li><li><strong>lids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Language index tensor (B,) or (B, 1).</li><li><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</li></ul></li><li><strong>Returns:</strong><ul><li>loss (Tensor): Loss scalar tensor.</li><li>stats (Dict[str, float]): Statistics to be monitored.</li><li>weight (Tensor): Weight tensor to summarize losses.</li><li>optim_idx (int): Optimizer index (0 for G and 1 for D).</li></ul></li><li><strong>Return type:</strong> Dict[str, Any]</li></ul><div class="custom-h4"><p>inference<span class="small-bracket">(text: Tensor, feats: Tensor | None = None, pitch: Tensor | None = None, energy: Tensor | None = None, use_teacher_forcing: bool = False, **kwargs)</span></p></div><p>Run inference.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (T_feats, aux_channels).</li><li><strong>pitch</strong> (<em>Tensor</em>) – Pitch tensor (T_feats, 1).</li><li><strong>energy</strong> (<em>Tensor</em>) – Energy tensor (T_feats, 1).</li><li><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</li></ul></li><li><strong>Returns:</strong><ul><li>wav (Tensor): Generated waveform tensor (T_wav,).</li><li>duration (Tensor): Predicted duration tensor (T_text,).</li></ul></li><li><strong>Return type:</strong> Dict[str, Tensor]</li></ul><div class="custom-h4"><p><em>property</em> require_raw_speech</p></div><p>Return whether or not speech is required.</p><div class="custom-h4"><p><em>property</em> require_vocoder</p></div><p>Return whether or not vocoder is required.</p><div class="custom-h4"><p>training <em>: bool</em></p></div>',18);function h(f,y){const t=n("RouteLink");return l(),o("div",null,[c,d,p,e("p",null,[r("Bases: "),a(t,{to:"/guide/espnet2/gan_tts/AbsGANTTS.html#espnet2.gan_tts.abs_gan_tts.AbsGANTTS"},{default:i(()=>[g]),_:1})]),u])}const v=s(m,[["render",h],["__file","JETS.html.vue"]]),k=JSON.parse(`{"path":"/guide/espnet2/gan_tts/JETS.html","title":"espnet2.gan_tts.jets.jets.JETS","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":3.04,"words":911},"filePathRelative":"guide/espnet2/gan_tts/JETS.md","excerpt":"<p>&lt;!-- _espnet2.gan_tts.jets.jets.JETS --&gt;</p>\\n<h1>espnet2.gan_tts.jets.jets.JETS</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.gan_tts.jets.jets.JETS<span class=\\"small-bracket\\">(idim: int, odim: int, sampling_rate: int = 22050, generator_type: str = 'jets_generator', generator_params: Dict[str, Any] = {'adim': 256, 'aheads': 2, 'conformer_activation_type': 'swish', 'conformer_dec_kernel_size': 31, 'conformer_enc_kernel_size': 7, 'conformer_pos_enc_layer_type': 'rel_pos', 'conformer_rel_pos_type': 'latest', 'conformer_self_attn_layer_type': 'rel_selfattn', 'decoder_concat_after': False, 'decoder_normalize_before': True, 'decoder_type': 'transformer', 'dlayers': 4, 'dunits': 1024, 'duration_predictor_chans': 384, 'duration_predictor_dropout_rate': 0.1, 'duration_predictor_kernel_size': 3, 'duration_predictor_layers': 2, 'elayers': 4, 'encoder_concat_after': False, 'encoder_normalize_before': True, 'encoder_type': 'transformer', 'energy_embed_dropout': 0.5, 'energy_embed_kernel_size': 1, 'energy_predictor_chans': 384, 'energy_predictor_dropout': 0.5, 'energy_predictor_kernel_size': 3, 'energy_predictor_layers': 2, 'eunits': 1024, 'generator_bias': True, 'generator_channels': 512, 'generator_global_channels': -1, 'generator_kernel_size': 7, 'generator_nonlinear_activation': 'LeakyReLU', 'generator_nonlinear_activation_params': {'negative_slope': 0.1}, 'generator_out_channels': 1, 'generator_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'generator_resblock_kernel_sizes': [3, 7, 11], 'generator_upsample_kernel_sizes': [16, 16, 4, 4], 'generator_upsample_scales': [8, 8, 2, 2], 'generator_use_additional_convs': True, 'generator_use_weight_norm': True, 'gst_conv_chans_list': [32, 32, 64, 64, 128, 128], 'gst_conv_kernel_size': 3, 'gst_conv_layers': 6, 'gst_conv_stride': 2, 'gst_gru_layers': 1, 'gst_gru_units': 128, 'gst_heads': 4, 'gst_tokens': 10, 'init_dec_alpha': 1.0, 'init_enc_alpha': 1.0, 'init_type': 'xavier_uniform', 'langs': -1, 'pitch_embed_dropout': 0.5, 'pitch_embed_kernel_size': 1, 'pitch_predictor_chans': 384, 'pitch_predictor_dropout': 0.5, 'pitch_predictor_kernel_size': 5, 'pitch_predictor_layers': 5, 'positionwise_conv_kernel_size': 1, 'positionwise_layer_type': 'conv1d', 'reduction_factor': 1, 'segment_size': 64, 'spk_embed_dim': None, 'spk_embed_integration_type': 'add', 'spks': -1, 'stop_gradient_from_energy_predictor': False, 'stop_gradient_from_pitch_predictor': True, 'transformer_dec_attn_dropout_rate': 0.1, 'transformer_dec_dropout_rate': 0.1, 'transformer_dec_positional_dropout_rate': 0.1, 'transformer_enc_attn_dropout_rate': 0.1, 'transformer_enc_dropout_rate': 0.1, 'transformer_enc_positional_dropout_rate': 0.1, 'use_batch_norm': True, 'use_cnn_in_conformer': True, 'use_gst': False, 'use_macaron_style_in_conformer': True, 'use_masking': False, 'use_scaled_pos_enc': True, 'use_weighted_masking': False, 'zero_triu': False}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_adv: float = 1.0, lambda_mel: float = 45.0, lambda_feat_match: float = 2.0, lambda_var: float = 1.0, lambda_align: float = 2.0, cache_generator_outputs: bool = True, plot_pred_mos: bool = False, mos_pred_tool: str = 'utmos')</span></p></div>"}`);export{v as comp,k as data};
