import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r,c as n,f as a,b as e,d as s,e as l,w as i,a as m,o as p}from"./app-KOUU_Wij.js";const c={},u=e("h1",{id:"espnet2-enh-separator-dccrn-separator-dccrnseparator",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-enh-separator-dccrn-separator-dccrnseparator"},[e("span",null,"espnet2.enh.separator.dccrn_separator.DCCRNSeparator")])],-1),d=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),s(" espnet2.enh.separator.dccrn_separator.DCCRNSeparator"),e("span",{class:"small-bracket"},"(input_dim: int, num_spk: int = 1, rnn_layer: int = 2, rnn_units: int = 256, masking_mode: str = 'E', use_clstm: bool = True, bidirectional: bool = False, use_cbn: bool = False, kernel_size: int = 5, kernel_num: List[int] = [32, 64, 128, 256, 256, 256], use_builtin_complex: bool = True, use_noise_mask: bool = False)")])],-1),_=e("code",null,"AbsSeparator",-1),h=m('<p>DCCRN separator.</p><ul><li><strong>Parameters:</strong><ul><li><strong>input_dim</strong> (<em>int</em>) – input dimension。</li><li><strong>num_spk</strong> (<em>int</em> <em>,</em> <em>optional</em>) – number of speakers. Defaults to 1.</li><li><strong>rnn_layer</strong> (<em>int</em> <em>,</em> <em>optional</em>) – number of lstm layers in the crn. Defaults to 2.</li><li><strong>rnn_units</strong> (<em>int</em> <em>,</em> <em>optional</em>) – rnn units. Defaults to 128.</li><li><strong>masking_mode</strong> (<em>str</em> <em>,</em> <em>optional</em>) – usage of the estimated mask. Defaults to “E”.</li><li><strong>use_clstm</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – whether use complex LSTM. Defaults to False.</li><li><strong>bidirectional</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – whether use BLSTM. Defaults to False.</li><li><strong>use_cbn</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – whether use complex BN. Defaults to False.</li><li><strong>kernel_size</strong> (<em>int</em> <em>,</em> <em>optional</em>) – convolution kernel size. Defaults to 5.</li><li><strong>kernel_num</strong> (<em>list</em> <em>,</em> <em>optional</em>) – output dimension of each layer of the encoder.</li><li><strong>use_builtin_complex</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – torch.complex if True, else ComplexTensor.</li><li><strong>use_noise_mask</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – whether to estimate the mask of noise.</li></ul></li></ul><div class="custom-h4"><p>apply_masks<span class="small-bracket">(masks: List[Tensor | ComplexTensor], real: Tensor, imag: Tensor)</span></p></div><p>apply masks</p><ul><li><strong>Parameters:</strong><ul><li><strong>masks</strong> – est_masks, [(B, T, F), …]</li><li><strong>real</strong> (<em>torch.Tensor</em>) – real part of the noisy spectrum, (B, F, T)</li><li><strong>imag</strong> (<em>torch.Tensor</em>) – imag part of the noisy spectrum, (B, F, T)</li></ul></li><li><strong>Returns:</strong> [(B, T, F), …]</li><li><strong>Return type:</strong> masked (List[Union(torch.Tensor, ComplexTensor)])</li></ul><div class="custom-h4"><p>create_masks<span class="small-bracket">(mask_tensor: Tensor)</span></p></div><p>create estimated mask for each speaker</p><ul><li><strong>Parameters:</strong><strong>mask_tensor</strong> (<em>torch.Tensor</em>) – output of decoder, shape(B, 2*num_spk, F-1, T)</li></ul><div class="custom-h4"><p>flatten_parameters()</p></div><div class="custom-h4"><p>forward<span class="small-bracket">(input: Tensor | ComplexTensor, ilens: Tensor, additional: Dict | None = None)</span></p></div><p>Forward.</p><ul><li><p><strong>Parameters:</strong></p><ul><li><strong>input</strong> (<em>torch.Tensor</em> <em>or</em> <em>ComplexTensor</em>) – Encoded feature [B, T, F]</li><li><strong>ilens</strong> (<em>torch.Tensor</em>) – input lengths [Batch]</li><li><strong>additional</strong> (<em>Dict</em> <em>or</em> <em>None</em>) – other data included in model NOTE: not used in this model</li></ul></li><li><p><strong>Returns:</strong> [(B, T, F), …] ilens (torch.Tensor): (B,) others predicted data, e.g. masks: OrderedDict[</p><blockquote><p>’mask_spk1’: torch.Tensor(Batch, Frames, Freq), ‘mask_spk2’: torch.Tensor(Batch, Frames, Freq), … ‘mask_spkn’: torch.Tensor(Batch, Frames, Freq),</p></blockquote><p>]</p></li><li><p><strong>Return type:</strong> masked (List[Union(torch.Tensor, ComplexTensor)])</p></li></ul><div class="custom-h4"><p><em>property</em> num_spk</p></div><div class="custom-h4"><p>training <em>: bool</em></p></div>',14);function g(k,T){const t=r("RouteLink");return p(),n("div",null,[a(" _espnet2.enh.separator.dccrn_separator.DCCRNSeparator "),u,d,e("p",null,[s("Bases: "),l(t,{to:"/guide/espnet2/enh/AbsSeparator.html#espnet2.enh.separator.abs_separator.AbsSeparator"},{default:i(()=>[_]),_:1})]),h])}const C=o(c,[["render",g],["__file","DCCRNSeparator.html.vue"]]),D=JSON.parse(`{"path":"/guide/espnet2/enh/DCCRNSeparator.html","title":"espnet2.enh.separator.dccrn_separator.DCCRNSeparator","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.31,"words":393},"filePathRelative":"guide/espnet2/enh/DCCRNSeparator.md","excerpt":"<!-- _espnet2.enh.separator.dccrn_separator.DCCRNSeparator -->\\n<h1>espnet2.enh.separator.dccrn_separator.DCCRNSeparator</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.enh.separator.dccrn_separator.DCCRNSeparator<span class=\\"small-bracket\\">(input_dim: int, num_spk: int = 1, rnn_layer: int = 2, rnn_units: int = 256, masking_mode: str = 'E', use_clstm: bool = True, bidirectional: bool = False, use_cbn: bool = False, kernel_size: int = 5, kernel_num: List[int] = [32, 64, 128, 256, 256, 256], use_builtin_complex: bool = True, use_noise_mask: bool = False)</span></p></div>"}`);export{C as comp,D as data};
