import{_ as l}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as i,c as a,b as e,d as s,e as n,w as o,a as r,o as c}from"./app-KOUU_Wij.js";const h={},u=r('<p>&lt;!-- _espnet.nets.beam_search.BeamSearch --&gt;</p><h1 id="espnet-nets-beam-search-beamsearch" tabindex="-1"><a class="header-anchor" href="#espnet-nets-beam-search-beamsearch"><span>espnet.nets.beam_search.BeamSearch</span></a></h1><div class="custom-h3"><p><em>class</em> espnet.nets.beam_search.BeamSearch<span class="small-bracket">(scorers: Dict[str, <a href="ScorerInterface.md#espnet.nets.scorer_interface.ScorerInterface">ScorerInterface</a></span>], weights: Dict[str, float], beam_size: int, vocab_size: int, sos: int, eos: int, token_list: List[str] | None = None, pre_beam_ratio: float = 1.5, pre_beam_score_key: str | None = None, return_hs: bool = False, hyp_primer: List[int] | None = None, normalize_length: bool = False)</p></div><p>Bases: <code>Module</code></p><p>Beam search implementation.</p><p>Initialize beam search.</p>',6),m=e("strong",null,"Parameters:",-1),p=e("strong",null,"scorers",-1),_=e("em",null,"dict",-1),d=e("em",null,"str",-1),g=e("em",null,",",-1),f=e("em",null,"ScorerInterface",-1),y=e("em",null,"]",-1),b=r("<li><strong>weights</strong> (<em>dict</em> *[*<em>str</em> <em>,</em> <em>float</em> <em>]</em>) – Dict of weights for each scorers The scorer will be ignored if its weight is 0</li><li><strong>beam_size</strong> (<em>int</em>) – The number of hypotheses kept during search</li><li><strong>vocab_size</strong> (<em>int</em>) – The number of vocabulary</li><li><strong>sos</strong> (<em>int</em>) – Start of sequence id</li><li><strong>eos</strong> (<em>int</em>) – End of sequence id</li><li><strong>token_list</strong> (<em>list</em> *[*<em>str</em> <em>]</em>) – List of tokens for debug log</li><li><strong>pre_beam_score_key</strong> (<em>str</em>) – key of scores to perform pre-beam search</li><li><strong>pre_beam_ratio</strong> (<em>float</em>) – beam size in the pre-beam search will be int(pre_beam_ratio * beam_size)</li><li><strong>return_hs</strong> (<em>bool</em>) – Whether to return hidden intermediates</li><li><strong>normalize_length</strong> (<em>bool</em>) – If true, select the best ended hypotheses based on length-normalized scores rather than the accumulated scores</li>",10),T=r('<div class="custom-h4"><p><em>static</em> append_token<span class="small-bracket">(xs: Tensor, x: int)</span></p></div><p>Append new token to prefix tokens.</p><ul><li><strong>Parameters:</strong><ul><li><strong>xs</strong> (<em>torch.Tensor</em>) – The prefix token</li><li><strong>x</strong> (<em>int</em>) – The new token to append</li></ul></li><li><strong>Returns:</strong> New tensor contains: xs + [x] with xs.dtype and xs.device</li><li><strong>Return type:</strong> torch.Tensor</li></ul><div class="custom-h4"><p>beam<span class="small-bracket">(weighted_scores: Tensor, ids: Tensor)</span></p></div><p>Compute topk full token ids and partial token ids.</p><ul><li><strong>Parameters:</strong><ul><li><strong>weighted_scores</strong> (<em>torch.Tensor</em>) – The weighted sum scores for each tokens.</li><li><strong>`</strong> (<em>Its shape is</em>) –</li><li><strong>ids</strong> (<em>torch.Tensor</em>) – The partial token ids to compute topk</li></ul></li><li><strong>Returns:</strong> The topk full token ids and partial token ids. Their shapes are (self.beam_size,)</li><li><strong>Return type:</strong> Tuple[torch.Tensor, torch.Tensor]</li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(x: Tensor, maxlenratio: float = 0.0, minlenratio: float = 0.0, pre_x: Tensor | None = None)</span></p></div><p>Perform beam search.</p>',8),x=r("<li><strong>Parameters:</strong><ul><li><strong>x</strong> (<em>torch.Tensor</em>) – Encoded speech feature (T, D)</li><li><strong>maxlenratio</strong> (<em>float</em>) – Input length ratio to obtain max output length. If maxlenratio=0.0 (default), it uses a end-detect function to automatically find maximum hypothesis lengths If maxlenratio&lt;0.0, its absolute value is interpreted as a constant max output length.</li><li><strong>minlenratio</strong> (<em>float</em>) – Input length ratio to obtain min output length. If minlenratio&lt;0.0, its absolute value is interpreted as a constant min output length.</li><li><strong>pre_x</strong> (<em>torch.Tensor</em>) – Encoded speech feature for sequential attn (T, D) Sequential attn computes attn first on pre_x then on x, thereby attending to two sources in sequence.</li></ul></li><li><strong>Returns:</strong> N-best decoding results</li>",2),k=e("strong",null,"Return type:",-1),v=e("div",{class:"custom-h4"},[e("p",null,[s("init_hyp"),e("span",{class:"small-bracket"},"(x: Tensor)")])],-1),w=e("p",null,"Get an initial hypothesis data.",-1),H=e("li",null,[e("strong",null,"Parameters:"),e("strong",null,"x"),s(" ("),e("em",null,"torch.Tensor"),s(") – The encoder output feature")],-1),R=e("li",null,[e("strong",null,"Returns:"),s(" The initial hypothesis.")],-1),S=e("strong",null,"Return type:",-1),N=r('<div class="custom-h4"><p><em>static</em> merge_scores<span class="small-bracket">(prev_scores: Dict[str, float], next_full_scores: Dict[str, Tensor], full_idx: int, next_part_scores: Dict[str, Tensor], part_idx: int)</span></p></div><p>Merge scores for new hypothesis.</p><ul><li><strong>Parameters:</strong><ul><li><strong>prev_scores</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>float</em> <em>]</em>) – The previous hypothesis scores by self.scorers</li><li><strong>next_full_scores</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>torch.Tensor</em> <em>]</em>) – scores by self.full_scorers</li><li><strong>full_idx</strong> (<em>int</em>) – The next token id for next_full_scores</li><li><strong>next_part_scores</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>torch.Tensor</em> <em>]</em>) – scores of partial tokens by self.part_scorers</li><li><strong>part_idx</strong> (<em>int</em>) – The new token id for next_part_scores</li></ul></li><li><strong>Returns:</strong> The new score dict. : Its keys are names of self.full_scorers and self.part_scorers. Its values are scalar tensors by the scorers.</li><li><strong>Return type:</strong> Dict[str, torch.Tensor]</li></ul><div class="custom-h4"><p>merge_states<span class="small-bracket">(states: Any, part_states: Any, part_idx: int)</span></p></div><p>Merge states for new hypothesis.</p><ul><li><strong>Parameters:</strong><ul><li><strong>states</strong> – states of self.full_scorers</li><li><strong>part_states</strong> – states of self.part_scorers</li><li><strong>part_idx</strong> (<em>int</em>) – The new token id for part_scores</li></ul></li><li><strong>Returns:</strong> The new score dict. : Its keys are names of self.full_scorers and self.part_scorers. Its values are states of the scorers.</li><li><strong>Return type:</strong> Dict[str, torch.Tensor]</li></ul><div class="custom-h4"><p>post_process<span class="small-bracket">(i: int, maxlen: int, minlen: int, maxlenratio: float, running_hyps: List[Hypothesis], ended_hyps: List[Hypothesis])</span></p></div><p>Perform post-processing of beam search iterations.</p>',8),D=e("strong",null,"Parameters:",-1),I=r("<li><strong>i</strong> (<em>int</em>) – The length of hypothesis tokens.</li><li><strong>maxlen</strong> (<em>int</em>) – The maximum length of tokens in beam search.</li><li><strong>maxlenratio</strong> (<em>int</em>) – The maximum length ratio in beam search.</li>",3),B=e("strong",null,"running_hyps",-1),L=e("em",null,"List",-1),P=e("em",null,"[",-1),z=e("em",null,"Hypothesis",-1),A=e("em",null,"]",-1),q=e("strong",null,"ended_hyps",-1),C=e("em",null,"List",-1),E=e("em",null,"[",-1),F=e("em",null,"Hypothesis",-1),M=e("em",null,"]",-1),V=e("li",null,[e("strong",null,"Returns:"),s(" The new running hypotheses.")],-1),O=e("strong",null,"Return type:",-1),U=e("div",{class:"custom-h4"},[e("p",null,[s("score_full"),e("span",{class:"small-bracket"},"(hyp: Hypothesis, x: Tensor, pre_x: Tensor | None = None)")])],-1),W=e("p",null,"Score new hypothesis by self.full_scorers.",-1),G=e("strong",null,"Parameters:",-1),J=e("strong",null,"hyp",-1),j=e("em",null,"Hypothesis",-1),K=e("li",null,[e("strong",null,"x"),s(" ("),e("em",null,"torch.Tensor"),s(") – Corresponding input feature")],-1),Q=e("li",null,[e("strong",null,"pre_x"),s(" ("),e("em",null,"torch.Tensor"),s(") – Encoded speech feature for sequential attn (T, D) Sequential attn computes attn first on pre_x then on x, thereby attending to two sources in sequence.")],-1),X=e("li",null,[e("strong",null,"Returns:"),s(" Tuple of : score dict of hyp that has string keys of self.full_scorers and tensor score values of shape: (self.n_vocab,), and state dict that has string keys and state values of self.full_scorers")],-1),Y=e("li",null,[e("strong",null,"Return type:"),s(" Tuple[Dict[str, torch.Tensor], Dict[str, Any]]")],-1),Z=e("div",{class:"custom-h4"},[e("p",null,[s("score_partial"),e("span",{class:"small-bracket"},"(hyp: Hypothesis, ids: Tensor, x: Tensor)")])],-1),$=e("p",null,"Score new hypothesis by self.part_scorers.",-1),ee=e("strong",null,"Parameters:",-1),se=e("strong",null,"hyp",-1),te=e("em",null,"Hypothesis",-1),ne=e("li",null,[e("strong",null,"ids"),s(" ("),e("em",null,"torch.Tensor"),s(") – 1D tensor of new partial tokens to score")],-1),oe=e("li",null,[e("strong",null,"x"),s(" ("),e("em",null,"torch.Tensor"),s(") – Corresponding input feature")],-1),re=e("li",null,[e("strong",null,"Returns:"),s(" Tuple of : score dict of hyp that has string keys of self.part_scorers and tensor score values of shape: (len(ids),), and state dict that has string keys and state values of self.part_scorers")],-1),le=e("li",null,[e("strong",null,"Return type:"),s(" Tuple[Dict[str, torch.Tensor], Dict[str, Any]]")],-1),ie=e("div",{class:"custom-h4"},[e("p",null,[s("search"),e("span",{class:"small-bracket"},"(running_hyps: List[Hypothesis], x: Tensor, pre_x: Tensor | None = None)")])],-1),ae=e("p",null,"Search new tokens for running hypotheses and encoded speech x.",-1),ce=e("strong",null,"Parameters:",-1),he=e("strong",null,"running_hyps",-1),ue=e("em",null,"List",-1),me=e("em",null,"[",-1),pe=e("em",null,"Hypothesis",-1),_e=e("em",null,"]",-1),de=e("li",null,[e("strong",null,"x"),s(" ("),e("em",null,"torch.Tensor"),s(") – Encoded speech feature (T, D)")],-1),ge=e("li",null,[e("strong",null,"pre_x"),s(" ("),e("em",null,"torch.Tensor"),s(") – Encoded speech feature for sequential attn (T, D) Sequential attn computes attn first on pre_x then on x, thereby attending to two sources in sequence.")],-1),fe=e("li",null,[e("strong",null,"Returns:"),s(" Best sorted hypotheses")],-1),ye=e("li",null,[e("strong",null,"Return type:"),s(" List[Hypotheses]")],-1),be=e("div",{class:"custom-h4"},[e("p",null,[s("set_hyp_primer"),e("span",{class:"small-bracket"},"(hyp_primer: List[int] | None = None)")])],-1),Te=e("p",null,"Set the primer sequence for decoding.",-1),xe=e("p",null,"Used for OpenAI Whisper models.",-1),ke=e("div",{class:"custom-h4"},[e("p",null,[s("training "),e("em",null,": bool")])],-1);function ve(we,He){const t=i("RouteLink");return c(),a("div",null,[u,e("ul",null,[e("li",null,[m,e("ul",null,[e("li",null,[p,s(" ("),_,s(" *[*"),d,s(),g,s(),n(t,{to:"/guide/espnet/nets/ScorerInterface.html#espnet.nets.scorer_interface.ScorerInterface"},{default:o(()=>[f]),_:1}),s(),y,s(") – Dict of decoder modules e.g., Decoder, CTCPrefixScorer, LM The scorer will be ignored if it is None")]),b])])]),T,e("ul",null,[x,e("li",null,[k,s(" list["),n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[s("Hypothesis")]),_:1}),s("]")])]),v,w,e("ul",null,[H,R,e("li",null,[S,n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[s("Hypothesis")]),_:1})])]),N,e("ul",null,[e("li",null,[D,e("ul",null,[I,e("li",null,[B,s(" ("),L,s(),P,n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[z]),_:1}),s(),A,s(") – The running hypotheses in beam search.")]),e("li",null,[q,s(" ("),C,s(),E,n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[F]),_:1}),s(),M,s(") – The ended hypotheses in beam search.")])])]),V,e("li",null,[O,s(" List["),n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[s("Hypothesis")]),_:1}),s("]")])]),U,W,e("ul",null,[e("li",null,[G,e("ul",null,[e("li",null,[J,s(" ("),n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[j]),_:1}),s(") – Hypothesis with prefix tokens to score")]),K,Q])]),X,Y]),Z,$,e("ul",null,[e("li",null,[ee,e("ul",null,[e("li",null,[se,s(" ("),n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[te]),_:1}),s(") – Hypothesis with prefix tokens to score")]),ne,oe])]),re,le]),ie,ae,e("ul",null,[e("li",null,[ce,e("ul",null,[e("li",null,[he,s(" ("),ue,s(),me,n(t,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:o(()=>[pe]),_:1}),s(),_e,s(") – Running hypotheses on beam")]),de,ge])]),fe,ye]),be,Te,xe,ke])}const Ne=l(h,[["render",ve],["__file","BeamSearch.html.vue"]]),De=JSON.parse('{"path":"/guide/espnet/nets/BeamSearch.html","title":"espnet.nets.beam_search.BeamSearch","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":3.63,"words":1088},"filePathRelative":"guide/espnet/nets/BeamSearch.md","excerpt":"<p>&lt;!-- _espnet.nets.beam_search.BeamSearch --&gt;</p>\\n<h1>espnet.nets.beam_search.BeamSearch</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.nets.beam_search.BeamSearch<span class=\\"small-bracket\\">(scorers: Dict[str, <a href=\\"ScorerInterface.md#espnet.nets.scorer_interface.ScorerInterface\\">ScorerInterface</a></span>], weights: Dict[str, float], beam_size: int, vocab_size: int, sos: int, eos: int, token_list: List[str] | None = None, pre_beam_ratio: float = 1.5, pre_beam_score_key: str | None = None, return_hs: bool = False, hyp_primer: List[int] | None = None, normalize_length: bool = False)</p></div>"}');export{Ne as comp,De as data};
