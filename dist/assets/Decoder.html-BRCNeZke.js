import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,f as e,a as t,o as s}from"./app-KOUU_Wij.js";const i={},r=t('<h1 id="espnet2-svs-singing-tacotron-decoder-decoder" tabindex="-1"><a class="header-anchor" href="#espnet2-svs-singing-tacotron-decoder-decoder"><span>espnet2.svs.singing_tacotron.decoder.Decoder</span></a></h1><div class="custom-h3"><p><em>class</em> espnet2.svs.singing_tacotron.decoder.Decoder<span class="small-bracket">(idim, odim, att, dlayers=2, dunits=1024, prenet_layers=2, prenet_units=256, postnet_layers=5, postnet_chans=512, postnet_filts=5, output_activation_fn=None, cumulate_att_w=True, use_batch_norm=True, use_concate=True, dropout_rate=0.5, zoneout_rate=0.1, reduction_factor=1)</span></p></div><p>Bases: <code>Module</code></p><p>Decoder module of Spectrogram prediction network.</p><p>This is a module of decoder of Spectrogram prediction network in Singing Tacotron, which described in</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>`https://arxiv.org/pdf/2202.07907v1.pdf`_</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>. The decoder generates the sequence of features from the sequence of the hidden states.</p>',7),a=t('<p>Filter for End-to-end Singing Voice Synthesis`: : <a href="https://arxiv.org/pdf/2202.07907v1.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2202.07907v1.pdf</a></p><p>Initialize Singing Tacotron decoder module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</li><li><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</li><li><strong>att</strong> (<em>torch.nn.Module</em>) – Instance of attention class.</li><li><strong>dlayers</strong> (<em>int</em> <em>,</em> <em>optional</em>) – The number of decoder lstm layers.</li><li><strong>dunits</strong> (<em>int</em> <em>,</em> <em>optional</em>) – The number of decoder lstm units.</li><li><strong>prenet_layers</strong> (<em>int</em> <em>,</em> <em>optional</em>) – The number of prenet layers.</li><li><strong>prenet_units</strong> (<em>int</em> <em>,</em> <em>optional</em>) – The number of prenet units.</li><li><strong>postnet_layers</strong> (<em>int</em> <em>,</em> <em>optional</em>) – The number of postnet layers.</li><li><strong>postnet_filts</strong> (<em>int</em> <em>,</em> <em>optional</em>) – The number of postnet filter size.</li><li><strong>postnet_chans</strong> (<em>int</em> <em>,</em> <em>optional</em>) – The number of postnet filter channels.</li><li><strong>output_activation_fn</strong> (<em>torch.nn.Module</em> <em>,</em> <em>optional</em>) – Activation function for outputs.</li><li><strong>cumulate_att_w</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – Whether to cumulate previous attention weight.</li><li><strong>use_batch_norm</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – Whether to use batch normalization.</li><li><strong>use_concate</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – Whether to concatenate encoder embedding with decoder lstm outputs.</li><li><strong>dropout_rate</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Dropout rate.</li><li><strong>zoneout_rate</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Zoneout rate.</li><li><strong>reduction_factor</strong> (<em>int</em> <em>,</em> <em>optional</em>) – Reduction factor.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(hs, hlens, trans_token, ys)</span></p></div><p>Calculate forward propagation.</p><ul><li><strong>Parameters:</strong><ul><li><strong>hs</strong> (<em>Tensor</em>) – Batch of the sequences of padded hidden states (B, Tmax, idim).</li><li><strong>hlens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</li><li><strong>trans_token</strong> (<em>Tensor</em>) – Global transition token for duration (B x Tmax x 1)</li><li><strong>ys</strong> (<em>Tensor</em>) – Batch of the sequences of padded target features (B, Lmax, odim).</li></ul></li><li><strong>Returns:</strong> Batch of output tensors after postnet (B, Lmax, odim). Tensor: Batch of output tensors before postnet (B, Lmax, odim). Tensor: Batch of logits of stop prediction (B, Lmax). Tensor: Batch of attention weights (B, Lmax, Tmax).</li><li><strong>Return type:</strong> Tensor</li></ul><h6 id="note" tabindex="-1"><a class="header-anchor" href="#note"><span>NOTE</span></a></h6><p>This computation is performed in teacher-forcing manner.</p><div class="custom-h4"><p>inference<span class="small-bracket">(h, trans_token, threshold=0.5, minlenratio=0.0, maxlenratio=30.0, use_att_constraint=False, use_dynamic_filter=True, backward_window=1, forward_window=3)</span></p></div><p>Generate the sequence of features given the sequences of characters.</p><ul><li><strong>Parameters:</strong><ul><li><p><strong>h</strong> (<em>Tensor</em>) – Input sequence of encoder hidden states (T, C).</p></li><li><p><strong>trans_token</strong> (<em>Tensor</em>) – Global transition token for duration.</p></li><li><p><strong>threshold</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Threshold to stop generation.</p></li><li><p><strong>minlenratio</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Minimum length ratio. If set to 1.0 and the length of input is 10, the minimum length of outputs will be 10 * 1 = 10.</p></li><li><p><strong>minlenratio</strong> – Minimum length ratio. If set to 10 and the length of input is 10, the maximum length of outputs will be 10 * 10 = 100.</p></li><li><p><strong>use_att_constraint</strong> (<em>bool</em>) – Whether to apply attention constraint introduced in <a href="https://arxiv.org/abs/1710.07654" target="_blank" rel="noopener noreferrer">Deep Voice 3</a>.</p></li><li><p><strong>use_dynamic_filter</strong> (<em>bool</em>) – Whether to apply dynamic filter introduced in</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>`Singing Tacotron`_</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>.</p></li><li><p><strong>backward_window</strong> (<em>int</em>) – Backward window size in attention constraint.</p></li><li><p><strong>forward_window</strong> (<em>int</em>) – Forward window size in attention constraint.</p></li></ul></li><li><strong>Returns:</strong> Output sequence of features (L, odim). Tensor: Output sequence of stop probabilities (L,). Tensor: Attention weights (L, T).</li><li><strong>Return type:</strong> Tensor</li></ul><h6 id="note-1" tabindex="-1"><a class="header-anchor" href="#note-1"><span>NOTE</span></a></h6><p>This computation is performed in auto-regressive manner.</p><div class="custom-h4"><p>training <em>: bool</em></p></div>',14);function l(m,d){return s(),o("div",null,[e(" _espnet2.svs.singing_tacotron.decoder.Decoder "),r,e(" _`Singing-Tacotron: Global Duration Control Attention and Dynamic "),a])}const u=n(i,[["render",l],["__file","Decoder.html.vue"]]),g=JSON.parse('{"path":"/guide/espnet2/svs/Decoder.html","title":"espnet2.svs.singing_tacotron.decoder.Decoder","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.93,"words":578},"filePathRelative":"guide/espnet2/svs/Decoder.md","excerpt":"<!-- _espnet2.svs.singing_tacotron.decoder.Decoder -->\\n<h1>espnet2.svs.singing_tacotron.decoder.Decoder</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.svs.singing_tacotron.decoder.Decoder<span class=\\"small-bracket\\">(idim, odim, att, dlayers=2, dunits=1024, prenet_layers=2, prenet_units=256, postnet_layers=5, postnet_chans=512, postnet_filts=5, output_activation_fn=None, cumulate_att_w=True, use_batch_norm=True, use_concate=True, dropout_rate=0.5, zoneout_rate=0.1, reduction_factor=1)</span></p></div>"}');export{u as comp,g as data};
