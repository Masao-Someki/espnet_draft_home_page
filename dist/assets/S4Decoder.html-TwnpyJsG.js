import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as a,c as l,b as e,d as t,e as s,w as r,a as i,o as c}from"./app-KOUU_Wij.js";const d={},p=e("p",null,"<!-- _espnet2.asr.decoder.s4_decoder.S4Decoder -->",-1),u=e("h1",{id:"espnet2-asr-decoder-s4-decoder-s4decoder",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-asr-decoder-s4-decoder-s4decoder"},[e("span",null,"espnet2.asr.decoder.s4_decoder.S4Decoder")])],-1),g=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet2.asr.decoder.s4_decoder.S4Decoder"),e("span",{class:"small-bracket"},"(vocab_size: int, encoder_output_size: int, input_layer: str = 'embed', dropinp: float = 0.0, dropout: float = 0.25, prenorm: bool = True, n_layers: int = 16, transposed: bool = False, tie_dropout: bool = False, n_repeat=1, layer=None, residual=None, norm=None, pool=None, track_norms=True, drop_path: float = 0.0)")])],-1),_=e("code",null,"AbsDecoder",-1),m=e("code",null,"BatchScorerInterface",-1),h=i('<p>S4 decoder module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>vocab_size</strong> – output dim</li><li><strong>encoder_output_size</strong> – dimension of hidden vector</li><li><strong>input_layer</strong> – input layer type</li><li><strong>dropinp</strong> – input dropout</li><li><strong>dropout</strong> – dropout parameter applied on every residual and every layer</li><li><strong>prenorm</strong> – pre-norm vs. post-norm</li><li><strong>n_layers</strong> – number of layers</li><li><strong>transposed</strong> – transpose inputs so each layer receives (batch, dim, length)</li><li><strong>tie_dropout</strong> – tie dropout mask across sequence like nn.Dropout1d/nn.Dropout2d</li><li><strong>n_repeat</strong> – each layer is repeated n times per stage before applying pooling</li><li><strong>layer</strong> – layer config, must be specified</li><li><strong>residual</strong> – residual config</li><li><strong>norm</strong> – normalization config (e.g. layer vs batch)</li><li><strong>pool</strong> – config for pooling layer per stage</li><li><strong>track_norms</strong> – log norms of each layer output</li><li><strong>drop_path</strong> – drop rate for stochastic depth</li></ul></li></ul><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p><div class="custom-h4"><p>batch_score<span class="small-bracket">(ys: Tensor, states: List[Any], xs: Tensor)</span></p></div><p>Score new token batch.</p><ul><li><strong>Parameters:</strong><ul><li><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</li><li><strong>states</strong> (<em>List</em> *[*<em>Any</em> <em>]</em>) – Scorer states for prefix tokens.</li><li><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</li></ul></li><li><strong>Returns:</strong> Tuple of : batchfied scores for next token with shape of (n_batch, n_vocab) and next state list for ys.</li><li><strong>Return type:</strong> tuple[torch.Tensor, List[Any]]</li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(hs_pad: Tensor, hlens: Tensor, ys_in_pad: Tensor, ys_in_lens: Tensor, state=None)</span></p></div><p>Forward decoder.</p><ul><li><p><strong>Parameters:</strong></p><ul><li><strong>hs_pad</strong> – encoded memory, float32 (batch, maxlen_in, feat)</li><li><strong>hlens</strong> – (batch)</li><li><strong>ys_in_pad</strong> – input token ids, int64 (batch, maxlen_out) if input_layer == “embed” input tensor (batch, maxlen_out, #mels) in the other cases</li><li><strong>ys_in_lens</strong> – (batch)</li></ul></li><li><p><strong>Returns:</strong> tuple containing:</p><p>x: decoded token score before softmax (batch, maxlen_out, token) : if use_output_layer is True,</p><p>olens: (batch, )</p></li><li><p><strong>Return type:</strong> (tuple)</p></li></ul><div class="custom-h4"><p>init_state<span class="small-bracket">(x: Tensor)</span></p></div><p>Initialize state.</p><div class="custom-h4"><p>score<span class="small-bracket">(ys, state, x)</span></p></div><p>Score new token (required).</p><ul><li><strong>Parameters:</strong><ul><li><strong>y</strong> (<em>torch.Tensor</em>) – 1D torch.int64 prefix tokens.</li><li><strong>state</strong> – Scorer state for prefix tokens</li><li><strong>x</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys.</li></ul></li><li><strong>Returns:</strong> Tuple of : scores for next token that has a shape of (n_vocab) and next state for ys</li><li><strong>Return type:</strong> tuple[torch.Tensor, Any]</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',15);function f(b,y){const o=a("RouteLink");return c(),l("div",null,[p,u,g,e("p",null,[t("Bases: "),s(o,{to:"/guide/espnet2/asr/AbsDecoder.html#espnet2.asr.decoder.abs_decoder.AbsDecoder"},{default:r(()=>[_]),_:1}),t(", "),s(o,{to:"/guide/espnet/nets/BatchScorerInterface.html#espnet.nets.scorer_interface.BatchScorerInterface"},{default:r(()=>[m]),_:1})]),h])}const k=n(d,[["render",f],["__file","S4Decoder.html.vue"]]),T=JSON.parse(`{"path":"/guide/espnet2/asr/S4Decoder.html","title":"espnet2.asr.decoder.s4_decoder.S4Decoder","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.43,"words":430},"filePathRelative":"guide/espnet2/asr/S4Decoder.md","excerpt":"<p>&lt;!-- _espnet2.asr.decoder.s4_decoder.S4Decoder --&gt;</p>\\n<h1>espnet2.asr.decoder.s4_decoder.S4Decoder</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.asr.decoder.s4_decoder.S4Decoder<span class=\\"small-bracket\\">(vocab_size: int, encoder_output_size: int, input_layer: str = 'embed', dropinp: float = 0.0, dropout: float = 0.25, prenorm: bool = True, n_layers: int = 16, transposed: bool = False, tie_dropout: bool = False, n_repeat=1, layer=None, residual=None, norm=None, pool=None, track_norms=True, drop_path: float = 0.0)</span></p></div>"}`);export{k as comp,T as data};
