import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,o as n,a as s}from"./app-KOUU_Wij.js";const o={},i=s('<p>&lt;!-- _espnet2.enh.layers.uses.ATFBlock --&gt;</p><h1 id="espnet2-enh-layers-uses-atfblock" tabindex="-1"><a class="header-anchor" href="#espnet2-enh-layers-uses-atfblock"><span>espnet2.enh.layers.uses.ATFBlock</span></a></h1><div class="custom-h3"><p><em>class</em> espnet2.enh.layers.uses.ATFBlock<span class="small-bracket">(input_size, rnn_type=&#39;lstm&#39;, hidden_size=128, att_heads=4, dropout=0.0, activation=&#39;relu&#39;, bidirectional=True, norm_type=&#39;cLN&#39;, ch_mode=&#39;att&#39;, ch_att_dim=256, eps=1e-05, with_channel_modeling=True)</span></p></div><p>Bases: <code>Module</code></p><p>Container module for a single Attentive Time-Frequency Block.</p><ul><li><strong>Parameters:</strong><ul><li><strong>input_size</strong> (<em>int</em>) – dimension of the input feature.</li><li><strong>rnn_type</strong> (<em>str</em>) – type of the RNN cell in the improved Transformer layer.</li><li><strong>hidden_size</strong> (<em>int</em>) – hidden dimension of the RNN cell.</li><li><strong>att_heads</strong> (<em>int</em>) – number of attention heads in Transformer.</li><li><strong>dropout</strong> (<em>float</em>) – dropout ratio. Default is 0.</li><li><strong>activation</strong> (<em>str</em>) – non-linear activation function applied in each block.</li><li><strong>bidirectional</strong> (<em>bool</em>) – whether the RNN layers are bidirectional.</li><li><strong>norm_type</strong> (<em>str</em>) – normalization type in the improved Transformer layer.</li><li><strong>ch_mode</strong> (<em>str</em>) – mode of channel modeling. Select from “att” and “tac”.</li><li><strong>ch_att_dim</strong> (<em>int</em>) – dimension of the channel attention.</li><li><strong>eps</strong> (<em>float</em>) – epsilon for layer normalization.</li><li><strong>with_channel_modeling</strong> (<em>bool</em>) – whether to use channel modeling.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(input, ref_channel=None)</span></p></div><p>Forward.</p><ul><li><strong>Parameters:</strong><ul><li><strong>input</strong> (<em>torch.Tensor</em>) – feature sequence (batch, C, N, freq, time)</li><li><strong>ref_channel</strong> (<em>None</em> <em>or</em> <em>int</em>) – index of the reference channel. if None, simply average all channels. if int, take the specified channel instead of averaging.</li></ul></li><li><strong>Returns:</strong> output sequence (batch, C, N, freq, time)</li><li><strong>Return type:</strong> output (torch.Tensor)</li></ul><div class="custom-h4"><p>freq_path_process<span class="small-bracket">(x)</span></p></div><div class="custom-h4"><p>time_path_process<span class="small-bracket">(x)</span></p></div><div class="custom-h4"><p>training <em>: bool</em></p></div>',12),l=[i];function r(a,c){return n(),t("div",null,l)}const h=e(o,[["render",r],["__file","ATFBlock.html.vue"]]),d=JSON.parse(`{"path":"/guide/espnet2/enh/ATFBlock.html","title":"espnet2.enh.layers.uses.ATFBlock","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.86,"words":259},"filePathRelative":"guide/espnet2/enh/ATFBlock.md","excerpt":"<p>&lt;!-- _espnet2.enh.layers.uses.ATFBlock --&gt;</p>\\n<h1>espnet2.enh.layers.uses.ATFBlock</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.enh.layers.uses.ATFBlock<span class=\\"small-bracket\\">(input_size, rnn_type='lstm', hidden_size=128, att_heads=4, dropout=0.0, activation='relu', bidirectional=True, norm_type='cLN', ch_mode='att', ch_att_dim=256, eps=1e-05, with_channel_modeling=True)</span></p></div>"}`);export{h as comp,d as data};
