import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,f as e,a as i,o as a}from"./app-KOUU_Wij.js";const s={},o=i('<h1 id="espnet-nets-pytorch-backend-rnn-attentions-initial-att" tabindex="-1"><a class="header-anchor" href="#espnet-nets-pytorch-backend-rnn-attentions-initial-att"><span>espnet.nets.pytorch_backend.rnn.attentions.initial_att</span></a></h1><div class="custom-h3"><p>espnet.nets.pytorch_backend.rnn.attentions.initial_att<span class="small-bracket">(atype, eprojs, dunits, aheads, adim, awin, aconv_chans, aconv_filts, han_mode=False)</span></p></div><p>Instantiates a single attention module</p><ul><li><strong>Parameters:</strong><ul><li><strong>atype</strong> (<em>str</em>) – attention type</li><li><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</li><li><strong>dunits</strong> (<em>int</em>) – # units of decoder</li><li><strong>aheads</strong> (<em>int</em>) – # heads of multi head attention</li><li><strong>adim</strong> (<em>int</em>) – attention dimension</li><li><strong>awin</strong> (<em>int</em>) – attention window size</li><li><strong>aconv_chans</strong> (<em>int</em>) – # channels of attention convolution</li><li><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</li><li><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention</li></ul></li><li><strong>Returns:</strong> The attention module</li></ul>',4);function r(l,c){return a(),n("div",null,[e(" _espnet.nets.pytorch_backend.rnn.attentions.initial_att "),o])}const p=t(s,[["render",r],["__file","initial_att.html.vue"]]),_=JSON.parse('{"path":"/guide/espnet/nets/initial_att.html","title":"espnet.nets.pytorch_backend.rnn.attentions.initial_att","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.3,"words":89},"filePathRelative":"guide/espnet/nets/initial_att.md","excerpt":"<!-- _espnet.nets.pytorch_backend.rnn.attentions.initial_att -->\\n<h1>espnet.nets.pytorch_backend.rnn.attentions.initial_att</h1>\\n<div class=\\"custom-h3\\"><p>espnet.nets.pytorch_backend.rnn.attentions.initial_att<span class=\\"small-bracket\\">(atype, eprojs, dunits, aheads, adim, awin, aconv_chans, aconv_filts, han_mode=False)</span></p></div>"}');export{p as comp,_ as data};
