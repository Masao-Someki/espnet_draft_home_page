import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r,c as i,f as h,b as e,d as t,e as a,w as n,a as l,o as c}from"./app-KOUU_Wij.js";const m={},p=e("h1",{id:"espnet-nets-beam-search-partially-ar-partiallyarbeamsearch",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet-nets-beam-search-partially-ar-partiallyarbeamsearch"},[e("span",null,"espnet.nets.beam_search_partially_AR.PartiallyARBeamSearch")])],-1),_=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet.nets.beam_search_partially_AR.PartiallyARBeamSearch"),e("span",{class:"small-bracket"},"(*args, **kwargs)")])],-1),u=e("code",null,"BatchBeamSearch",-1),d=e("p",null,"Partially autoregressive beam search implementation. Partially autoregressive hypothesis is a set of BatchHypothesis.",-1),y=e("p",null,"We need to use add_mask function to add a hypothesis for a mask. Before search and beam search method, each partially autoregressive hypothesis is extracted to BatchHypothesis, and applied the same process as the batched_beam_search.",-1),g=e("p",null,"Initialize beam search.",-1),f=e("strong",null,"Parameters:",-1),b=e("strong",null,"scorers",-1),R=e("em",null,"dict",-1),B=e("em",null,"str",-1),A=e("em",null,",",-1),T=e("em",null,"ScorerInterface",-1),k=e("em",null,"]",-1),H=l("<li><strong>weights</strong> (<em>dict</em> *[*<em>str</em> <em>,</em> <em>float</em> <em>]</em>) – Dict of weights for each scorers The scorer will be ignored if its weight is 0</li><li><strong>beam_size</strong> (<em>int</em>) – The number of hypotheses kept during search</li><li><strong>vocab_size</strong> (<em>int</em>) – The number of vocabulary</li><li><strong>sos</strong> (<em>int</em>) – Start of sequence id</li><li><strong>eos</strong> (<em>int</em>) – End of sequence id</li><li><strong>token_list</strong> (<em>list</em> *[*<em>str</em> <em>]</em>) – List of tokens for debug log</li><li><strong>pre_beam_score_key</strong> (<em>str</em>) – key of scores to perform pre-beam search</li><li><strong>pre_beam_ratio</strong> (<em>float</em>) – beam size in the pre-beam search will be int(pre_beam_ratio * beam_size)</li><li><strong>return_hs</strong> (<em>bool</em>) – Whether to return hidden intermediates</li><li><strong>normalize_length</strong> (<em>bool</em>) – If true, select the best ended hypotheses based on length-normalized scores rather than the accumulated scores</li>",10),P=l('<div class="custom-h4"><p>add_mask<span class="small-bracket">(primer: List[int], eos: int)</span></p></div><p>Add a mask to a batch of hypotheses.</p><ul><li><strong>Parameters:</strong><strong>primer</strong> (<em>torch.Tensor</em>) – Primer yseq.</li></ul><div class="custom-h4"><p>batch_beam<span class="small-bracket">(weighted_scores: Tensor)</span></p></div><p>Batch-compute topk full token ids and partial token ids.</p><ul><li><strong>Parameters:</strong><strong>weighted_scores</strong> (<em>torch.Tensor</em>) – The weighted sum scores for each tokens. Its shape is (n_beam, self.vocab_size).</li><li><strong>Returns:</strong> The topk full (prev_hyp, new_token) ids and partial (prev_hyp, new_token) ids. Their shapes are all (self.beam_size,)</li><li><strong>Return type:</strong> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]</li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(x: Tensor, max_seq_len: int | None = None)</span></p></div><p>Perform beam search.</p>',8),v=l("<li><strong>Parameters:</strong><ul><li><strong>x</strong> (<em>torch.Tensor</em>) – Encoded speech feature (T, D)</li><li><strong>maxlenratio</strong> (<em>float</em>) – Input length ratio to obtain max output length. If maxlenratio=0.0 (default), it uses a end-detect function to automatically find maximum hypothesis lengths If maxlenratio&lt;0.0, its absolute value is interpreted as a constant max output length.</li><li><strong>minlenratio</strong> (<em>float</em>) – Input length ratio to obtain min output length.</li></ul></li><li><strong>Returns:</strong> N-best decoding results</li>",2),x=e("strong",null,"Return type:",-1),S=e("div",{class:"custom-h4"},[e("p",null,[t("init_hyp"),e("span",{class:"small-bracket"},"(x: Tensor)")])],-1),w=e("p",null,"Get an initial hypothesis data for each mask.",-1),I=e("li",null,[e("strong",null,"Parameters:"),e("strong",null,"x"),t(" ("),e("em",null,"torch.Tensor"),t(") – The encoder output feature")],-1),N=e("li",null,[e("strong",null,"Returns:"),t(" The initial hypothesis.")],-1),z=e("strong",null,"Return type:",-1),L=l('<div class="custom-h4"><p>init_masks()</p></div><div class="custom-h4"><p>post_process<span class="small-bracket">(i: int, maxlen: int, running_hyps: <a href="PartiallyARHypothesis.md#espnet.nets.beam_search_partially_AR.PartiallyARHypothesis">PartiallyARHypothesis</a></span>, ended_hyps: List[List[<a href="Hypothesis.md#espnet.nets.beam_search_partially_AR.Hypothesis">Hypothesis</a>]])</p></div><p>Perform post-processing of beam search iterations. Extract BatchHypothesis for each mask, and perform post-process. Then merge BatchHypothesis.</p>',3),D=e("strong",null,"Parameters:",-1),C=l("<li><strong>i</strong> (<em>int</em>) – The length of hypothesis tokens.</li><li><strong>maxlen</strong> (<em>int</em>) – The maximum length of tokens in beam search.</li><li><strong>maxlenratio</strong> (<em>int</em>) – The maximum length ratio in beam search.</li>",3),E=e("strong",null,"running_hyps",-1),V=e("em",null,"BatchHypothesis",-1),q=e("strong",null,"ended_hyps",-1),W=e("em",null,"List",-1),F=e("em",null,"[",-1),G=e("em",null,"Hypothesis",-1),J=e("em",null,"]",-1),M=e("li",null,[e("strong",null,"Returns:"),t(" The new running hypotheses.")],-1),O=e("strong",null,"Return type:",-1),U=e("div",{class:"custom-h4"},[e("p",null,[t("score_full"),e("span",{class:"small-bracket"},[t("(hyp: "),e("a",{href:"PartiallyARHypothesis.md#espnet.nets.beam_search_partially_AR.PartiallyARHypothesis"},"PartiallyARHypothesis")]),t(", x: Tensor, is_first: bool = False)")])],-1),j=e("p",null,"Score new hypothesis by self.full_scorers.",-1),K=e("strong",null,"Parameters:",-1),Q=e("strong",null,"hyp",-1),X=e("em",null,"PartiallyARHypothesis",-1),Y=e("li",null,[e("strong",null,"x"),t(" ("),e("em",null,"torch.Tensor"),t(") – Corresponding input feature")],-1),Z=e("li",null,[e("strong",null,"Returns:"),t(" Tuple of : score dict of hyp that has string keys of self.full_scorers and tensor score values of shape: (self.n_vocab,), and state dict that has string keys and state values of self.full_scorers")],-1),$=e("li",null,[e("strong",null,"Return type:"),t(" Tuple[Dict[str, torch.Tensor], Dict[str, Any]]")],-1),ee=e("div",{class:"custom-h4"},[e("p",null,[t("search"),e("span",{class:"small-bracket"},[t("(running_hyps: "),e("a",{href:"PartiallyARHypothesis.md#espnet.nets.beam_search_partially_AR.PartiallyARHypothesis"},"PartiallyARHypothesis")]),t(", x: Tensor)")])],-1),te=e("p",null,"Search new tokens for running hypotheses and encoded speech x.",-1),se=e("strong",null,"Parameters:",-1),ae=e("strong",null,"running_hyps",-1),ne=e("em",null,"BatchHypothesis",-1),le=e("li",null,[e("strong",null,"x"),t(" ("),e("em",null,"torch.Tensor"),t(") – Encoded speech feature (T, D)")],-1),oe=e("li",null,[e("strong",null,"Returns:"),t(" Best sorted hypotheses")],-1),re=e("strong",null,"Return type:",-1),ie=e("div",{class:"custom-h4"},[e("p",null,[t("training "),e("em",null,": bool")])],-1);function he(ce,me){const s=r("RouteLink");return c(),i("div",null,[h(" _espnet.nets.beam_search_partially_AR.PartiallyARBeamSearch "),p,_,e("p",null,[t("Bases: "),a(s,{to:"/guide/espnet/nets/BatchBeamSearch.html#espnet.nets.batch_beam_search.BatchBeamSearch"},{default:n(()=>[u]),_:1})]),d,y,g,e("ul",null,[e("li",null,[f,e("ul",null,[e("li",null,[b,t(" ("),R,t(" *[*"),B,t(),A,t(),a(s,{to:"/guide/espnet/nets/ScorerInterface.html#espnet.nets.scorer_interface.ScorerInterface"},{default:n(()=>[T]),_:1}),t(),k,t(") – Dict of decoder modules e.g., Decoder, CTCPrefixScorer, LM The scorer will be ignored if it is None")]),H])])]),P,e("ul",null,[v,e("li",null,[x,t(" list["),a(s,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:n(()=>[t("Hypothesis")]),_:1}),t("]")])]),S,w,e("ul",null,[I,N,e("li",null,[z,a(s,{to:"/guide/espnet/nets/PartiallyARHypothesis.html#espnet.nets.beam_search_partially_AR.PartiallyARHypothesis"},{default:n(()=>[t("PartiallyARHypothesis")]),_:1})])]),L,e("ul",null,[e("li",null,[D,e("ul",null,[C,e("li",null,[E,t(" ("),a(s,{to:"/guide/espnet/nets/BatchHypothesis.html#espnet.nets.batch_beam_search.BatchHypothesis"},{default:n(()=>[V]),_:1}),t(") – The running hypotheses in beam search.")]),e("li",null,[q,t(" ("),W,t(),F,a(s,{to:"/guide/espnet/nets/Hypothesis.html#espnet.nets.beam_search_partially_AR.Hypothesis"},{default:n(()=>[G]),_:1}),t(),J,t(") – The ended hypotheses in beam search.")])])]),M,e("li",null,[O,a(s,{to:"/guide/espnet/nets/BatchHypothesis.html#espnet.nets.batch_beam_search.BatchHypothesis"},{default:n(()=>[t("BatchHypothesis")]),_:1})])]),U,j,e("ul",null,[e("li",null,[K,e("ul",null,[e("li",null,[Q,t(" ("),a(s,{to:"/guide/espnet/nets/PartiallyARHypothesis.html#espnet.nets.beam_search_partially_AR.PartiallyARHypothesis"},{default:n(()=>[X]),_:1}),t(") – Hypothesis with prefix tokens to score")]),Y])]),Z,$]),ee,te,e("ul",null,[e("li",null,[se,e("ul",null,[e("li",null,[ae,t(" ("),a(s,{to:"/guide/espnet/nets/BatchHypothesis.html#espnet.nets.batch_beam_search.BatchHypothesis"},{default:n(()=>[ne]),_:1}),t(") – Running hypotheses on beam")]),le])]),oe,e("li",null,[re,a(s,{to:"/guide/espnet/nets/BatchHypothesis.html#espnet.nets.batch_beam_search.BatchHypothesis"},{default:n(()=>[t("BatchHypothesis")]),_:1})])]),ie])}const ue=o(m,[["render",he],["__file","PartiallyARBeamSearch.html.vue"]]),de=JSON.parse('{"path":"/guide/espnet/nets/PartiallyARBeamSearch.html","title":"espnet.nets.beam_search_partially_AR.PartiallyARBeamSearch","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":2.35,"words":704},"filePathRelative":"guide/espnet/nets/PartiallyARBeamSearch.md","excerpt":"<!-- _espnet.nets.beam_search_partially_AR.PartiallyARBeamSearch -->\\n<h1>espnet.nets.beam_search_partially_AR.PartiallyARBeamSearch</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.nets.beam_search_partially_AR.PartiallyARBeamSearch<span class=\\"small-bracket\\">(*args, **kwargs)</span></p></div>\\n<p>Bases: <a href=\\"/guide/espnet/nets/BatchBeamSearch.html#espnet.nets.batch_beam_search.BatchBeamSearch\\" target=\\"_blank\\"><code>BatchBeamSearch</code></a></p>"}');export{ue as comp,de as data};
