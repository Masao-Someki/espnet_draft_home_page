import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,f as r,a as s,o as t}from"./app-KOUU_Wij.js";const o={},c=s('<h1 id="espnet2-asr-transducer-encoder-encoder-encoder" tabindex="-1"><a class="header-anchor" href="#espnet2-asr-transducer-encoder-encoder-encoder"><span>espnet2.asr_transducer.encoder.encoder.Encoder</span></a></h1><div class="custom-h3"><p><em>class</em> espnet2.asr_transducer.encoder.encoder.Encoder<span class="small-bracket">(input_size: int, body_conf: List[Dict[str, Any]], input_conf: Dict[str, Any] = {}, main_conf: Dict[str, Any] = {})</span></p></div><p>Bases: <code>Module</code></p><p>Encoder module definition.</p><ul><li><strong>Parameters:</strong><ul><li><strong>input_size</strong> – Input size.</li><li><strong>body_conf</strong> – Encoder body configuration.</li><li><strong>input_conf</strong> – Encoder input configuration.</li><li><strong>main_conf</strong> – Encoder main configuration.</li></ul></li></ul><p>Construct an Encoder object.</p><div class="custom-h4"><p>chunk_forward<span class="small-bracket">(x: Tensor, x_len: Tensor, processed_frames: tensor, left_context: int = 32)</span></p></div><p>Encode input sequences as chunks.</p><ul><li><strong>Parameters:</strong><ul><li><strong>x</strong> – Encoder input features. (1, T_in, F)</li><li><strong>x_len</strong> – Encoder input features lengths. (1,)</li><li><strong>processed_frames</strong> – Number of frames already seen.</li><li><strong>left_context</strong> – Number of previous frames (AFTER subsampling) the attention module can see in current chunk.</li></ul></li><li><strong>Returns:</strong> Encoder outputs. (B, T_out, D_enc)</li><li><strong>Return type:</strong> x</li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(x: Tensor, x_len: Tensor)</span></p></div><p>Encode input sequences.</p><ul><li><strong>Parameters:</strong><ul><li><strong>x</strong> – Encoder input features. (B, T_in, F)</li><li><strong>x_len</strong> – Encoder input features lengths. (B,)</li></ul></li><li><strong>Returns:</strong> Encoder outputs. (B, T_out, D_enc) x_len: Encoder outputs lenghts. (B,)</li><li><strong>Return type:</strong> x</li></ul><div class="custom-h4"><p>reset_cache<span class="small-bracket">(left_context: int, device: device)</span></p></div><p>Initialize/Reset encoder cache for streaming.</p><ul><li><strong>Parameters:</strong><ul><li><strong>left_context</strong> – Number of previous frames (AFTER subsampling) the attention module can see in current chunk.</li><li><strong>device</strong> – Device ID.</li></ul></li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',16);function i(a,l){return t(),n("div",null,[r(" _espnet2.asr_transducer.encoder.encoder.Encoder "),c])}const p=e(o,[["render",i],["__file","Encoder.html.vue"]]),m=JSON.parse('{"path":"/guide/espnet2/asr_transducer/Encoder.html","title":"espnet2.asr_transducer.encoder.encoder.Encoder","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.76,"words":229},"filePathRelative":"guide/espnet2/asr_transducer/Encoder.md","excerpt":"<!-- _espnet2.asr_transducer.encoder.encoder.Encoder -->\\n<h1>espnet2.asr_transducer.encoder.encoder.Encoder</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.asr_transducer.encoder.encoder.Encoder<span class=\\"small-bracket\\">(input_size: int, body_conf: List[Dict[str, Any]], input_conf: Dict[str, Any] = {}, main_conf: Dict[str, Any] = {})</span></p></div>"}');export{p as comp,m as data};
