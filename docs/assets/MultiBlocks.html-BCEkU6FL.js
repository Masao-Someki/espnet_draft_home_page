import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as s,f as t,a as o,o as l}from"./app-KOUU_Wij.js";const n={},r=o('<h1 id="espnet2-asr-transducer-encoder-modules-multi-blocks-multiblocks" tabindex="-1"><a class="header-anchor" href="#espnet2-asr-transducer-encoder-modules-multi-blocks-multiblocks"><span>espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks</span></a></h1><div class="custom-h3"><p><em>class</em> espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks<span class="small-bracket">(block_list: ~typing.List[~torch.nn.modules.module.Module], output_size: int, norm_class: ~torch.nn.modules.module.Module = &lt;class &#39;torch.nn.modules.normalization.LayerNorm&#39;&gt;, norm_args: ~typing.Dict | None = None, blockdrop_rate: int = 0.0)</span></p></div><p>Bases: <code>Module</code></p><p>MultiBlocks definition.</p><ul><li><strong>Parameters:</strong><ul><li><strong>block_list</strong> – Individual blocks of the encoder architecture.</li><li><strong>output_size</strong> – Architecture output size.</li><li><strong>norm_class</strong> – Normalization module class.</li><li><strong>norm_args</strong> – Normalization module arguments.</li><li><strong>blockdrop_rate</strong> – Probability threshold of dropping out each block.</li></ul></li></ul><p>Construct a MultiBlocks object.</p><div class="custom-h4"><p>chunk_forward<span class="small-bracket">(x: Tensor, pos_enc: Tensor, mask: Tensor, left_context: int = 0)</span></p></div><p>Forward each block of the encoder architecture.</p><ul><li><strong>Parameters:</strong><ul><li><strong>x</strong> – MultiBlocks input sequences. (B, T, D_block_1)</li><li><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_att)</li><li><strong>mask</strong> – Source mask. (B, T_2)</li><li><strong>left_context</strong> – Number of previous frames the attention module can see in current chunk (used by Conformer and Branchformer block).</li></ul></li><li><strong>Returns:</strong> MultiBlocks output sequences. (B, T, D_block_N)</li><li><strong>Return type:</strong> x</li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(x: Tensor, pos_enc: Tensor, mask: Tensor, chunk_mask: Tensor | None = None)</span></p></div><p>Forward each block of the encoder architecture.</p><ul><li><strong>Parameters:</strong><ul><li><strong>x</strong> – MultiBlocks input sequences. (B, T, D_block_1)</li><li><strong>pos_enc</strong> – Positional embedding sequences.</li><li><strong>mask</strong> – Source mask. (B, T)</li><li><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</li></ul></li><li><strong>Returns:</strong> Output sequences. (B, T, D_block_N)</li><li><strong>Return type:</strong> x</li></ul><div class="custom-h4"><p>reset_streaming_cache<span class="small-bracket">(left_context: int, device: device)</span></p></div><p>Initialize/Reset encoder streaming cache.</p><ul><li><strong>Parameters:</strong><ul><li><strong>left_context</strong> – Number of previous frames the attention module can see in current chunk (used by Conformer and Branchformer block).</li><li><strong>device</strong> – Device to use for cache tensor.</li></ul></li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',16);function c(i,a){return l(),s("div",null,[t(" _espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks "),r])}const m=e(n,[["render",c],["__file","MultiBlocks.html.vue"]]),p=JSON.parse(`{"path":"/guide/espnet2/asr_transducer/MultiBlocks.html","title":"espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.91,"words":274},"filePathRelative":"guide/espnet2/asr_transducer/MultiBlocks.md","excerpt":"<!-- _espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks -->\\n<h1>espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks<span class=\\"small-bracket\\">(block_list: ~typing.List[~torch.nn.modules.module.Module], output_size: int, norm_class: ~torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;, norm_args: ~typing.Dict | None = None, blockdrop_rate: int = 0.0)</span></p></div>"}`);export{m as comp,p as data};
