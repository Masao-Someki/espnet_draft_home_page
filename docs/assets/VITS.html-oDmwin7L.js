import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r,c as n,b as e,d as t,e as a,w as i,a as _,o as l}from"./app-KOUU_Wij.js";const m={},c=e("p",null,"<!-- _espnet2.gan_tts.vits.vits.VITS -->",-1),d=e("h1",{id:"espnet2-gan-tts-vits-vits-vits",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-gan-tts-vits-vits-vits"},[e("span",null,"espnet2.gan_tts.vits.vits.VITS")])],-1),p=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet2.gan_tts.vits.vits.VITS"),e("span",{class:"small-bracket"},"(idim: int, odim: int, sampling_rate: int = 22050, generator_type: str = 'vits_generator', generator_params: Dict[str, Any] = {'decoder_channels': 512, 'decoder_kernel_size': 7, 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_upsample_scales': [8, 8, 2, 2], 'flow_base_dilation': 1, 'flow_dropout_rate': 0.0, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_layers': 4, 'global_channels': -1, 'hidden_channels': 192, 'langs': None, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'segment_size': 32, 'spk_embed_dim': None, 'spks': None, 'stochastic_duration_predictor_dds_conv_layers': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_kernel_size': 3, 'text_encoder_activation_type': 'swish', 'text_encoder_attention_dropout_rate': 0.0, 'text_encoder_attention_heads': 2, 'text_encoder_blocks': 6, 'text_encoder_conformer_kernel_size': 7, 'text_encoder_dropout_rate': 0.1, 'text_encoder_ffn_expand': 4, 'text_encoder_normalize_before': True, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_positionwise_conv_kernel_size': 1, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'use_conformer_conv_in_text_encoder': True, 'use_macaron_style_in_text_encoder': True, 'use_only_mean_in_flow': True, 'use_weight_norm_in_decoder': True, 'use_weight_norm_in_flow': True, 'use_weight_norm_in_posterior_encoder': True}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_adv: float = 1.0, lambda_mel: float = 45.0, lambda_feat_match: float = 2.0, lambda_dur: float = 1.0, lambda_kl: float = 1.0, cache_generator_outputs: bool = True, plot_pred_mos: bool = False, mos_pred_tool: str = 'utmos')")])],-1),g=e("code",null,"AbsGANTTS",-1),u=_('<p>VITS module (generator + discriminator).</p><p>This is a module of VITS described in <a href="https://arxiv.org/abs/2006.04558" target="_blank" rel="noopener noreferrer">Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</a>.</p><p>Initialize VITS module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</li><li><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will be 1 since VITS is the end-to-end text-to-wave model but for the compatibility odim is used to indicate the acoustic feature dimension.</li><li><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will be referred in saving waveform during the inference.</li><li><strong>generator_type</strong> (<em>str</em>) – Generator type.</li><li><strong>generator_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for generator.</li><li><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</li><li><strong>discriminator_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for discriminator.</li><li><strong>generator_adv_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for generator adversarial loss.</li><li><strong>discriminator_adv_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for discriminator adversarial loss.</li><li><strong>feat_match_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for feat match loss.</li><li><strong>mel_loss_params</strong> (<em>Dict</em> *[*<em>str</em> <em>,</em> <em>Any</em> <em>]</em>) – Parameter dict for mel loss.</li><li><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</li><li><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel spectrogram loss.</li><li><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</li><li><strong>lambda_dur</strong> (<em>float</em>) – Loss scaling coefficient for duration loss.</li><li><strong>lambda_kl</strong> (<em>float</em>) – Loss scaling coefficient for KL divergence loss.</li><li><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</li><li><strong>plot_pred_mos</strong> (<em>bool</em>) – Whether to plot predicted MOS during the training.</li><li><strong>mos_pred_tool</strong> (<em>str</em>) – MOS prediction tool name.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(text: Tensor, text_lengths: Tensor, feats: Tensor, feats_lengths: Tensor, speech: Tensor, speech_lengths: Tensor, sids: Tensor | None = None, spembs: Tensor | None = None, lids: Tensor | None = None, forward_generator: bool = True)</span></p></div><p>Perform generator forward.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</li><li><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, T_feats, aux_channels).</li><li><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</li><li><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</li><li><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B,).</li><li><strong>sids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker index tensor (B,) or (B, 1).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker embedding tensor (B, spk_embed_dim).</li><li><strong>lids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Language index tensor (B,) or (B, 1).</li><li><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</li></ul></li><li><strong>Returns:</strong><ul><li>loss (Tensor): Loss scalar tensor.</li><li>stats (Dict[str, float]): Statistics to be monitored.</li><li>weight (Tensor): Weight tensor to summarize losses.</li><li>optim_idx (int): Optimizer index (0 for G and 1 for D).</li></ul></li><li><strong>Return type:</strong> Dict[str, Any]</li></ul><div class="custom-h4"><p>inference<span class="small-bracket">(text: Tensor, feats: Tensor | None = None, sids: Tensor | None = None, spembs: Tensor | None = None, lids: Tensor | None = None, durations: Tensor | None = None, noise_scale: float = 0.667, noise_scale_dur: float = 0.8, alpha: float = 1.0, max_len: int | None = None, use_teacher_forcing: bool = False)</span></p></div><p>Run inference.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (T_feats, aux_channels).</li><li><strong>sids</strong> (<em>Tensor</em>) – Speaker index tensor (1,).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Speaker embedding tensor (spk_embed_dim,).</li><li><strong>lids</strong> (<em>Tensor</em>) – Language index tensor (1,).</li><li><strong>durations</strong> (<em>Tensor</em>) – Ground-truth duration tensor (T_text,).</li><li><strong>noise_scale</strong> (<em>float</em>) – Noise scale value for flow.</li><li><strong>noise_scale_dur</strong> (<em>float</em>) – Noise scale value for duration predictor.</li><li><strong>alpha</strong> (<em>float</em>) – Alpha parameter to control the speed of generated speech.</li><li><strong>max_len</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Maximum length.</li><li><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</li></ul></li><li><strong>Returns:</strong><ul><li>wav (Tensor): Generated waveform tensor (T_wav,).</li><li>att_w (Tensor): Monotonic attention weight tensor (T_feats, T_text).</li><li>duration (Tensor): Predicted duration tensor (T_text,).</li></ul></li><li><strong>Return type:</strong> Dict[str, Tensor]</li></ul><div class="custom-h4"><p><em>property</em> require_raw_speech</p></div><p>Return whether or not speech is required.</p><div class="custom-h4"><p><em>property</em> require_vocoder</p></div><p>Return whether or not vocoder is required.</p><div class="custom-h4"><p>training <em>: bool</em></p></div>',15);function f(h,T){const s=r("RouteLink");return l(),n("div",null,[c,d,p,e("p",null,[t("Bases: "),a(s,{to:"/guide/espnet2/gan_tts/AbsGANTTS.html#espnet2.gan_tts.abs_gan_tts.AbsGANTTS"},{default:i(()=>[g]),_:1})]),u])}const w=o(m,[["render",f],["__file","VITS.html.vue"]]),x=JSON.parse(`{"path":"/guide/espnet2/gan_tts/VITS.html","title":"espnet2.gan_tts.vits.vits.VITS","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":3.01,"words":904},"filePathRelative":"guide/espnet2/gan_tts/VITS.md","excerpt":"<p>&lt;!-- _espnet2.gan_tts.vits.vits.VITS --&gt;</p>\\n<h1>espnet2.gan_tts.vits.vits.VITS</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.gan_tts.vits.vits.VITS<span class=\\"small-bracket\\">(idim: int, odim: int, sampling_rate: int = 22050, generator_type: str = 'vits_generator', generator_params: Dict[str, Any] = {'decoder_channels': 512, 'decoder_kernel_size': 7, 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_upsample_scales': [8, 8, 2, 2], 'flow_base_dilation': 1, 'flow_dropout_rate': 0.0, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_layers': 4, 'global_channels': -1, 'hidden_channels': 192, 'langs': None, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'segment_size': 32, 'spk_embed_dim': None, 'spks': None, 'stochastic_duration_predictor_dds_conv_layers': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_kernel_size': 3, 'text_encoder_activation_type': 'swish', 'text_encoder_attention_dropout_rate': 0.0, 'text_encoder_attention_heads': 2, 'text_encoder_blocks': 6, 'text_encoder_conformer_kernel_size': 7, 'text_encoder_dropout_rate': 0.1, 'text_encoder_ffn_expand': 4, 'text_encoder_normalize_before': True, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_positionwise_conv_kernel_size': 1, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'use_conformer_conv_in_text_encoder': True, 'use_macaron_style_in_text_encoder': True, 'use_only_mean_in_flow': True, 'use_weight_norm_in_decoder': True, 'use_weight_norm_in_flow': True, 'use_weight_norm_in_posterior_encoder': True}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_adv: float = 1.0, lambda_mel: float = 45.0, lambda_feat_match: float = 2.0, lambda_dur: float = 1.0, lambda_kl: float = 1.0, cache_generator_outputs: bool = True, plot_pred_mos: bool = False, mos_pred_tool: str = 'utmos')</span></p></div>"}`);export{w as comp,x as data};
