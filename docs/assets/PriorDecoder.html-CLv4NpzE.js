import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,f as t,a as n,o as r}from"./app-KOUU_Wij.js";const s={},i=n('<h1 id="espnet2-gan-svs-vits-prior-decoder-priordecoder" tabindex="-1"><a class="header-anchor" href="#espnet2-gan-svs-vits-prior-decoder-priordecoder"><span>espnet2.gan_svs.vits.prior_decoder.PriorDecoder</span></a></h1><div class="custom-h3"><p><em>class</em> espnet2.gan_svs.vits.prior_decoder.PriorDecoder<span class="small-bracket">(out_channels: int = 384, attention_dim: int = 192, attention_heads: int = 2, linear_units: int = 768, blocks: int = 6, positionwise_layer_type: str = &#39;conv1d&#39;, positionwise_conv_kernel_size: int = 3, positional_encoding_layer_type: str = &#39;rel_pos&#39;, self_attention_layer_type: str = &#39;rel_selfattn&#39;, activation_type: str = &#39;swish&#39;, normalize_before: bool = True, use_macaron_style: bool = False, use_conformer_conv: bool = False, conformer_kernel_size: int = 7, dropout_rate: float = 0.1, positional_dropout_rate: float = 0.0, attention_dropout_rate: float = 0.0, global_channels: int = 0)</span></p></div><p>Bases: <code>Module</code></p><p>Initialize prior decoder module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>out_channels</strong> (<em>int</em>) – Output channels of the prior decoder. Defaults to 384.</li><li><strong>attention_dim</strong> (<em>int</em>) – Dimension of the attention mechanism. Defaults to 192.</li><li><strong>attention_heads</strong> (<em>int</em>) – Number of attention heads. Defaults to 2.</li><li><strong>linear_units</strong> (<em>int</em>) – Number of units in the linear layer. Defaults to 768.</li><li><strong>blocks</strong> (<em>int</em>) – Number of blocks in the encoder. Defaults to 6.</li><li><strong>positionwise_layer_type</strong> (<em>str</em>) – Type of the positionwise layer. Defaults to “conv1d”.</li><li><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – Kernel size of the positionwise convolutional layer. Defaults to 3.</li><li><strong>positional_encoding_layer_type</strong> (<em>str</em>) – Type of positional encoding layer. Defaults to “rel_pos”.</li><li><strong>self_attention_layer_type</strong> (<em>str</em>) – Type of self-attention layer. Defaults to “rel_selfattn”.</li><li><strong>activation_type</strong> (<em>str</em>) – Type of activation. Defaults to “swish”.</li><li><strong>normalize_before</strong> (<em>bool</em>) – Flag for normalization. Defaults to True.</li><li><strong>use_macaron_style</strong> (<em>bool</em>) – Flag for macaron style. Defaults to False.</li><li><strong>use_conformer_conv</strong> (<em>bool</em>) – Flag for using conformer convolution. Defaults to False.</li><li><strong>conformer_kernel_size</strong> (<em>int</em>) – Kernel size for conformer convolution. Defaults to 7.</li><li><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate. Defaults to 0.1.</li><li><strong>positional_dropout_rate</strong> (<em>float</em>) – Dropout rate for positional encoding. Defaults to 0.0.</li><li><strong>attention_dropout_rate</strong> (<em>float</em>) – Dropout rate for attention. Defaults to 0.0.</li><li><strong>global_channels</strong> (<em>int</em>) – Number of global channels. Defaults to 0.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(x, x_lengths, g=None)</span></p></div><p>Forward pass of the PriorDecoder module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, attention_dim + 2, T).</li><li><strong>x_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</li><li><strong>g</strong> (<em>Tensor</em>) – Tensor for multi-singer. (B, global_channels, 1)</li></ul></li><li><strong>Returns:</strong> Output tensor (B, out_channels, T). Tensor: Output mask tensor (B, 1, T).</li><li><strong>Return type:</strong> Tensor</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',9);function l(a,_){return r(),o("div",null,[t(" _espnet2.gan_svs.vits.prior_decoder.PriorDecoder "),i])}const m=e(s,[["render",l],["__file","PriorDecoder.html.vue"]]),d=JSON.parse(`{"path":"/guide/espnet2/gan_svs/PriorDecoder.html","title":"espnet2.gan_svs.vits.prior_decoder.PriorDecoder","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.12,"words":335},"filePathRelative":"guide/espnet2/gan_svs/PriorDecoder.md","excerpt":"<!-- _espnet2.gan_svs.vits.prior_decoder.PriorDecoder -->\\n<h1>espnet2.gan_svs.vits.prior_decoder.PriorDecoder</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.gan_svs.vits.prior_decoder.PriorDecoder<span class=\\"small-bracket\\">(out_channels: int = 384, attention_dim: int = 192, attention_heads: int = 2, linear_units: int = 768, blocks: int = 6, positionwise_layer_type: str = 'conv1d', positionwise_conv_kernel_size: int = 3, positional_encoding_layer_type: str = 'rel_pos', self_attention_layer_type: str = 'rel_selfattn', activation_type: str = 'swish', normalize_before: bool = True, use_macaron_style: bool = False, use_conformer_conv: bool = False, conformer_kernel_size: int = 7, dropout_rate: float = 0.1, positional_dropout_rate: float = 0.0, attention_dropout_rate: float = 0.0, global_channels: int = 0)</span></p></div>"}`);export{m as comp,d as data};
