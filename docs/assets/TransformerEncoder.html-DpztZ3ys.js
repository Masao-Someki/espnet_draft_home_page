import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as i,c as a,f as l,b as e,d as n,e as o,w as r,a as d,o as c}from"./app-KOUU_Wij.js";const _={},p=e("h1",{id:"espnet2-asr-encoder-transformer-encoder-transformerencoder",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-asr-encoder-transformer-encoder-transformerencoder"},[e("span",null,"espnet2.asr.encoder.transformer_encoder.TransformerEncoder")])],-1),u=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),n(" espnet2.asr.encoder.transformer_encoder.TransformerEncoder"),e("span",{class:"small-bracket"},"(input_size: int, output_size: int = 256, attention_heads: int = 4, linear_units: int = 2048, num_blocks: int = 6, dropout_rate: float = 0.1, positional_dropout_rate: float = 0.1, attention_dropout_rate: float = 0.0, input_layer: str | None = 'conv2d', pos_enc_class=<class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'>, normalize_before: bool = True, concat_after: bool = False, positionwise_layer_type: str = 'linear', positionwise_conv_kernel_size: int = 1, padding_idx: int = -1, interctc_layer_idx: ~typing.List[int] = [], interctc_use_conditioning: bool = False, layer_drop_rate: float = 0.0)")])],-1),m=e("code",null,"AbsEncoder",-1),f=d('<p>Transformer encoder module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>input_size</strong> – input dim</li><li><strong>output_size</strong> – dimension of attention</li><li><strong>attention_heads</strong> – the number of heads of multi head attention</li><li><strong>linear_units</strong> – the number of units of position-wise feed forward</li><li><strong>num_blocks</strong> – the number of decoder blocks</li><li><strong>dropout_rate</strong> – dropout rate</li><li><strong>attention_dropout_rate</strong> – dropout rate in attention</li><li><strong>positional_dropout_rate</strong> – dropout rate after adding positional encoding</li><li><strong>input_layer</strong> – input layer type</li><li><strong>pos_enc_class</strong> – PositionalEncoding or ScaledPositionalEncoding</li><li><strong>normalize_before</strong> – whether to use layer_norm before the first block</li><li><strong>concat_after</strong> – whether to concat attention layer’s input and output if True, additional linear will be applied. i.e. x -&gt; x + linear(concat(x, att(x))) if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</li><li><strong>positionwise_layer_type</strong> – linear of conv1d</li><li><strong>positionwise_conv_kernel_size</strong> – kernel size of positionwise conv1d layer</li><li><strong>padding_idx</strong> – padding_idx for input_layer=embed</li></ul></li></ul><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p><div class="custom-h4"><p>forward<span class="small-bracket">(xs_pad: Tensor, ilens: Tensor, prev_states: Tensor | None = None, ctc: <a href="CTC.md#espnet2.asr.ctc.CTC">CTC</a></span> | None = None, return_all_hs: bool = False)</p></div><p>Embed positions in tensor.</p>',5),g=e("strong",null,"Parameters:",-1),h=e("li",null,[e("strong",null,"xs_pad"),n(" – input tensor (B, L, D)")],-1),b=e("li",null,[e("strong",null,"ilens"),n(" – input length (B)")],-1),T=e("li",null,[e("strong",null,"prev_states"),n(" – Not to be used now.")],-1),y=e("strong",null,"ctc",-1),x=e("em",null,"CTC",-1),k=e("li",null,[e("strong",null,"return_all_hs"),n(" ("),e("em",null,"bool"),n(") – whether to return all hidden states")],-1),v=e("li",null,[e("strong",null,"Returns:"),n(" position embedded tensor and mask")],-1),E=e("div",{class:"custom-h4"},[e("p",null,"output_size()")],-1),w=e("div",{class:"custom-h4"},[e("p",null,[n("training "),e("em",null,": bool")])],-1);function C(z,N){const t=i("RouteLink");return c(),a("div",null,[l(" _espnet2.asr.encoder.transformer_encoder.TransformerEncoder "),p,u,e("p",null,[n("Bases: "),o(t,{to:"/guide/espnet2/asr/AbsEncoder.html#espnet2.asr.encoder.abs_encoder.AbsEncoder"},{default:r(()=>[m]),_:1})]),f,e("ul",null,[e("li",null,[g,e("ul",null,[h,b,T,e("li",null,[y,n(" ("),o(t,{to:"/guide/espnet/nets/CTC.html#espnet.nets.chainer_backend.transformer.ctc.CTC"},{default:r(()=>[x]),_:1}),n(") – ctc module for intermediate CTC loss")]),k])]),v]),E,w])}const F=s(_,[["render",C],["__file","TransformerEncoder.html.vue"]]),L=JSON.parse(`{"path":"/guide/espnet2/asr/TransformerEncoder.html","title":"espnet2.asr.encoder.transformer_encoder.TransformerEncoder","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.02,"words":307},"filePathRelative":"guide/espnet2/asr/TransformerEncoder.md","excerpt":"<!-- _espnet2.asr.encoder.transformer_encoder.TransformerEncoder -->\\n<h1>espnet2.asr.encoder.transformer_encoder.TransformerEncoder</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.asr.encoder.transformer_encoder.TransformerEncoder<span class=\\"small-bracket\\">(input_size: int, output_size: int = 256, attention_heads: int = 4, linear_units: int = 2048, num_blocks: int = 6, dropout_rate: float = 0.1, positional_dropout_rate: float = 0.1, attention_dropout_rate: float = 0.0, input_layer: str | None = 'conv2d', pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;, normalize_before: bool = True, concat_after: bool = False, positionwise_layer_type: str = 'linear', positionwise_conv_kernel_size: int = 1, padding_idx: int = -1, interctc_layer_idx: ~typing.List[int] = [], interctc_use_conditioning: bool = False, layer_drop_rate: float = 0.0)</span></p></div>"}`);export{F as comp,L as data};
