import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as s,c as o,f as a,b as e,d as t,e as i,w as l,a as p,o as d}from"./app-KOUU_Wij.js";const m={},c=e("h1",{id:"espnet2-enh-separator-dprnn-separator-dprnnseparator",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-enh-separator-dprnn-separator-dprnnseparator"},[e("span",null,"espnet2.enh.separator.dprnn_separator.DPRNNSeparator")])],-1),u=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet2.enh.separator.dprnn_separator.DPRNNSeparator"),e("span",{class:"small-bracket"},"(input_dim: int, rnn_type: str = 'lstm', bidirectional: bool = True, num_spk: int = 2, predict_noise: bool = False, nonlinear: str = 'relu', layer: int = 3, unit: int = 512, segment_size: int = 20, dropout: float = 0.0)")])],-1),h=e("code",null,"AbsSeparator",-1),_=p('<p>Dual-Path RNN (DPRNN) Separator</p><ul><li><strong>Parameters:</strong><ul><li><strong>input_dim</strong> – input feature dimension</li><li><strong>rnn_type</strong> – string, select from ‘RNN’, ‘LSTM’ and ‘GRU’.</li><li><strong>bidirectional</strong> – bool, whether the inter-chunk RNN layers are bidirectional.</li><li><strong>num_spk</strong> – number of speakers</li><li><strong>predict_noise</strong> – whether to output the estimated noise signal</li><li><strong>nonlinear</strong> – the nonlinear function for mask estimation, select from ‘relu’, ‘tanh’, ‘sigmoid’</li><li><strong>layer</strong> – int, number of stacked RNN layers. Default is 3.</li><li><strong>unit</strong> – int, dimension of the hidden state.</li><li><strong>segment_size</strong> – dual-path segment size</li><li><strong>dropout</strong> – float, dropout ratio. Default is 0.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(input: Tensor | ComplexTensor, ilens: Tensor, additional: Dict | None = None)</span></p></div><p>Forward.</p><ul><li><p><strong>Parameters:</strong></p><ul><li><strong>input</strong> (<em>torch.Tensor</em> <em>or</em> <em>ComplexTensor</em>) – Encoded feature [B, T, N]</li><li><strong>ilens</strong> (<em>torch.Tensor</em>) – input lengths [Batch]</li><li><strong>additional</strong> (<em>Dict</em> <em>or</em> <em>None</em>) – other data included in model NOTE: not used in this model</li></ul></li><li><p><strong>Returns:</strong> [(B, T, N), …] ilens (torch.Tensor): (B,) others predicted data, e.g. masks: OrderedDict[</p><blockquote><p>’mask_spk1’: torch.Tensor(Batch, Frames, Freq), ‘mask_spk2’: torch.Tensor(Batch, Frames, Freq), … ‘mask_spkn’: torch.Tensor(Batch, Frames, Freq),</p></blockquote><p>]</p></li><li><p><strong>Return type:</strong> masked (List[Union(torch.Tensor, ComplexTensor)])</p></li></ul><div class="custom-h4"><p><em>property</em> num_spk</p></div><div class="custom-h4"><p>training <em>: bool</em></p></div>',7);function g(N,f){const r=s("RouteLink");return d(),o("div",null,[a(" _espnet2.enh.separator.dprnn_separator.DPRNNSeparator "),c,u,e("p",null,[t("Bases: "),i(r,{to:"/guide/espnet2/enh/AbsSeparator.html#espnet2.enh.separator.abs_separator.AbsSeparator"},{default:l(()=>[h]),_:1})]),_])}const R=n(m,[["render",g],["__file","DPRNNSeparator.html.vue"]]),T=JSON.parse(`{"path":"/guide/espnet2/enh/DPRNNSeparator.html","title":"espnet2.enh.separator.dprnn_separator.DPRNNSeparator","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.81,"words":243},"filePathRelative":"guide/espnet2/enh/DPRNNSeparator.md","excerpt":"<!-- _espnet2.enh.separator.dprnn_separator.DPRNNSeparator -->\\n<h1>espnet2.enh.separator.dprnn_separator.DPRNNSeparator</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.enh.separator.dprnn_separator.DPRNNSeparator<span class=\\"small-bracket\\">(input_dim: int, rnn_type: str = 'lstm', bidirectional: bool = True, num_spk: int = 2, predict_noise: bool = False, nonlinear: str = 'relu', layer: int = 3, unit: int = 512, segment_size: int = 20, dropout: float = 0.0)</span></p></div>"}`);export{R as comp,T as data};
