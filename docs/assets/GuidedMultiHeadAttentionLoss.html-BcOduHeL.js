import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as o,c as a,f as i,b as e,d as t,e as l,w as r,a as d,o as m}from"./app-KOUU_Wij.js";const c={},u=e("h1",{id:"espnet-nets-pytorch-backend-e2e-tts-transformer-guidedmultiheadattentionloss",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet-nets-pytorch-backend-e2e-tts-transformer-guidedmultiheadattentionloss"},[e("span",null,"espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss")])],-1),p=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss"),e("span",{class:"small-bracket"},"(sigma=0.4, alpha=1.0, reset_always=True)")])],-1),_=e("code",null,"GuidedAttentionLoss",-1),g=d('<p>Guided attention loss function module for multi head attention.</p><ul><li><strong>Parameters:</strong><ul><li><strong>sigma</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Standard deviation to control</li><li><strong>diagonal.</strong> (<em>how close attention to a</em>) –</li><li><strong>alpha</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Scaling coefficient (lambda).</li><li><strong>reset_always</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – Whether to always reset masks.</li></ul></li></ul><p>Initialize guided attention loss module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>sigma</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Standard deviation to control how close attention to a diagonal.</li><li><strong>alpha</strong> (<em>float</em> <em>,</em> <em>optional</em>) – Scaling coefficient (lambda).</li><li><strong>reset_always</strong> (<em>bool</em> <em>,</em> <em>optional</em>) – Whether to always reset masks.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(att_ws, ilens, olens)</span></p></div><p>Calculate forward propagation.</p><ul><li><strong>Parameters:</strong><ul><li><strong>att_ws</strong> (<em>Tensor</em>) – Batch of multi head attention weights (B, H, T_max_out, T_max_in).</li><li><strong>ilens</strong> (<em>LongTensor</em>) – Batch of input lengths (B,).</li><li><strong>olens</strong> (<em>LongTensor</em>) – Batch of output lengths (B,).</li></ul></li><li><strong>Returns:</strong> Guided attention loss value.</li><li><strong>Return type:</strong> Tensor</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',8);function h(f,b){const s=o("RouteLink");return m(),a("div",null,[i(" _espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss "),u,p,e("p",null,[t("Bases: "),l(s,{to:"/guide/espnet/nets/GuidedAttentionLoss.html#espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss"},{default:r(()=>[_]),_:1})]),g])}const y=n(c,[["render",h],["__file","GuidedMultiHeadAttentionLoss.html.vue"]]),w=JSON.parse('{"path":"/guide/espnet/nets/GuidedMultiHeadAttentionLoss.html","title":"espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.56,"words":168},"filePathRelative":"guide/espnet/nets/GuidedMultiHeadAttentionLoss.md","excerpt":"<!-- _espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss -->\\n<h1>espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss<span class=\\"small-bracket\\">(sigma=0.4, alpha=1.0, reset_always=True)</span></p></div>"}');export{y as comp,w as data};
