import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,o as n,a as s}from"./app-KOUU_Wij.js";const d={},o=s('<p>&lt;!-- _espnet.nets.e2e_asr_common.end_detect --&gt;</p><h1 id="espnet-nets-e2e-asr-common-end-detect" tabindex="-1"><a class="header-anchor" href="#espnet-nets-e2e-asr-common-end-detect"><span>espnet.nets.e2e_asr_common.end_detect</span></a></h1><div class="custom-h3"><p>espnet.nets.e2e_asr_common.end_detect<span class="small-bracket">(ended_hyps, i, M=3, D_end=-10.0)</span></p></div><p>End detection.</p><p>described in Eq. (50) of S. Watanabe et al “Hybrid CTC/Attention Architecture for End-to-End Speech Recognition”</p><ul><li><strong>Parameters:</strong><ul><li><strong>ended_hyps</strong> –</li><li><strong>i</strong> –</li><li><strong>M</strong> –</li><li><strong>D_end</strong> –</li></ul></li><li><strong>Returns:</strong></li></ul>',6),c=[o];function r(a,i){return n(),t("div",null,c)}const l=e(d,[["render",r],["__file","end_detect.html.vue"]]),m=JSON.parse('{"path":"/guide/espnet/nets/end_detect.html","title":"espnet.nets.e2e_asr_common.end_detect","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.16,"words":49},"filePathRelative":"guide/espnet/nets/end_detect.md","excerpt":"<p>&lt;!-- _espnet.nets.e2e_asr_common.end_detect --&gt;</p>\\n<h1>espnet.nets.e2e_asr_common.end_detect</h1>\\n<div class=\\"custom-h3\\"><p>espnet.nets.e2e_asr_common.end_detect<span class=\\"small-bracket\\">(ended_hyps, i, M=3, D_end=-10.0)</span></p></div>\\n<p>End detection.</p>\\n<p>described in Eq. (50) of S. Watanabe et al\\n“Hybrid CTC/Attention Architecture for End-to-End Speech Recognition”</p>"}');export{l as comp,m as data};
