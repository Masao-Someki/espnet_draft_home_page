import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,f as o,a as n,o as r}from"./app-KOUU_Wij.js";const a={},s=n('<h1 id="espnet-nets-pytorch-backend-conformer-contextual-block-encoder-layer-contextualblockencoderlayer" tabindex="-1"><a class="header-anchor" href="#espnet-nets-pytorch-backend-conformer-contextual-block-encoder-layer-contextualblockencoderlayer"><span>espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer</span></a></h1><div class="custom-h3"><p><em>class</em> espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer<span class="small-bracket">(size, self_attn, feed_forward, feed_forward_macaron, conv_module, dropout_rate, total_layer_num, normalize_before=True, concat_after=False)</span></p></div><p>Bases: <code>Module</code></p><p>Contexutal Block Encoder layer module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>size</strong> (<em>int</em>) – Input dimension.</li><li><strong>self_attn</strong> (<em>torch.nn.Module</em>) – Self-attention module instance. MultiHeadedAttention or RelPositionMultiHeadedAttention instance can be used as the argument.</li><li><strong>feed_forward</strong> (<em>torch.nn.Module</em>) – Feed-forward module instance. PositionwiseFeedForward, MultiLayeredConv1d, or Conv1dLinear instance can be used as the argument.</li><li><strong>feed_forward_macaron</strong> (<em>torch.nn.Module</em>) – Additional feed-forward module instance. PositionwiseFeedForward, MultiLayeredConv1d, or Conv1dLinear instance can be used as the argument.</li><li><strong>conv_module</strong> (<em>torch.nn.Module</em>) – Convolution module instance. ConvlutionModule instance can be used as the argument.</li><li><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</li><li><strong>total_layer_num</strong> (<em>int</em>) – Total number of layers</li><li><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</li><li><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output. if True, additional linear will be applied. i.e. x -&gt; x + linear(concat(x, att(x))) if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</li></ul></li></ul><p>Construct an EncoderLayer object.</p><div class="custom-h4"><p>forward<span class="small-bracket">(x, mask, infer_mode=False, past_ctx=None, next_ctx=None, is_short_segment=False, layer_idx=0, cache=None)</span></p></div><p>Calculate forward propagation.</p><div class="custom-h4"><p>forward_infer<span class="small-bracket">(x, mask, past_ctx=None, next_ctx=None, is_short_segment=False, layer_idx=0, cache=None)</span></p></div><p>Compute encoded features.</p><ul><li><strong>Parameters:</strong><ul><li><strong>x_input</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, size).</li><li><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor for the input (#batch, 1, time).</li><li><strong>past_ctx</strong> (<em>torch.Tensor</em>) – Previous contexutal vector</li><li><strong>next_ctx</strong> (<em>torch.Tensor</em>) – Next contexutal vector</li><li><strong>cache</strong> (<em>torch.Tensor</em>) – Cache tensor of the input (#batch, time - 1, size).</li></ul></li><li><strong>Returns:</strong> Output tensor (#batch, time, size). torch.Tensor: Mask tensor (#batch, 1, time). cur_ctx (torch.Tensor): Current contexutal vector next_ctx (torch.Tensor): Next contexutal vector layer_idx (int): layer index number</li><li><strong>Return type:</strong> torch.Tensor</li></ul><div class="custom-h4"><p>forward_train<span class="small-bracket">(x, mask, past_ctx=None, next_ctx=None, layer_idx=0, cache=None)</span></p></div><p>Compute encoded features.</p><ul><li><strong>Parameters:</strong><ul><li><strong>x_input</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, size).</li><li><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor for the input (#batch, time).</li><li><strong>past_ctx</strong> (<em>torch.Tensor</em>) – Previous contexutal vector</li><li><strong>next_ctx</strong> (<em>torch.Tensor</em>) – Next contexutal vector</li><li><strong>cache</strong> (<em>torch.Tensor</em>) – Cache tensor of the input (#batch, time - 1, size).</li></ul></li><li><strong>Returns:</strong> Output tensor (#batch, time, size). torch.Tensor: Mask tensor (#batch, time). cur_ctx (torch.Tensor): Current contexutal vector next_ctx (torch.Tensor): Next contexutal vector layer_idx (int): layer index number</li><li><strong>Return type:</strong> torch.Tensor</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',15);function c(l,i){return r(),t("div",null,[o(" _espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer "),s])}const m=e(a,[["render",c],["__file","ContextualBlockEncoderLayer.html.vue"]]),_=JSON.parse('{"path":"/guide/espnet/nets/ContextualBlockEncoderLayer.html","title":"espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.36,"words":409},"filePathRelative":"guide/espnet/nets/ContextualBlockEncoderLayer.md","excerpt":"<!-- _espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer -->\\n<h1>espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer<span class=\\"small-bracket\\">(size, self_attn, feed_forward, feed_forward_macaron, conv_module, dropout_rate, total_layer_num, normalize_before=True, concat_after=False)</span></p></div>"}');export{m as comp,_ as data};
