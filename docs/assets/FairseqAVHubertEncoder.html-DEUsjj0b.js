import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as a,c as n,f as s,b as e,d as t,e as i,w as d,a as l,o as u}from"./app-KOUU_Wij.js";const _={},c=e("h1",{id:"espnet2-asr-encoder-avhubert-encoder-fairseqavhubertencoder",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-asr-encoder-avhubert-encoder-fairseqavhubertencoder"},[e("span",null,"espnet2.asr.encoder.avhubert_encoder.FairseqAVHubertEncoder")])],-1),p=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet2.asr.encoder.avhubert_encoder.FairseqAVHubertEncoder"),e("span",{class:"small-bracket"},"(input_size: int = 1, avhubert_url: str = './', avhubert_dir_path: str = './', freeze_finetune_updates: int = 0, encoder_embed_dim: int = 1024, encoder_layerdrop: float = 0.05, dropout_input: float = 0.1, dropout_features: float = 0.1, dropout: float = 0.1, attention_dropout: float = 0.1, feature_grad_mult: float = 0.1, activation_dropout: float = 0.0, wav_input: bool = False, layer_norm_first: bool = True, audio_feat_dim: int = 104, encoder_layers: int = 24, encoder_ffn_embed_dim: int = 4096, encoder_attention_heads: int = 16, extracted: bool = False, pretrain: bool = True, modality_dropout: float = 0.0, audio_dropout: float = 0.0, noise_augmentation: bool = False, noise_path: str = './data/babble_noise.pt', max_noise_weight: float = 0.5, audio_only: bool = False)")])],-1),b=e("code",null,"AbsEncoder",-1),m=l('<p>FairSeq AVHubert pretrained encoder module</p><ul><li><strong>Parameters:</strong><ul><li><strong>input_size</strong> – input dim</li><li><strong>avhubert_url</strong> – download link for pre-trained avhubert model</li><li><strong>avhubert_dir_path</strong> – dir_path for downloading pre-trained avhubert model</li></ul></li></ul><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p><div class="custom-h4"><p>forward<span class="small-bracket">(xs_pad: Dict[str, Tensor], ilens: Tensor, prev_states: Tensor | None = None)</span></p></div><p>Forward AVHubert Encoder.</p><ul><li><strong>Parameters:</strong><ul><li><strong>xs_pad</strong>**[<strong><strong>video</strong></strong>]** – input tensor (B, 1, L, H, W)</li><li><strong>xs_pad</strong>**[<strong><strong>audio</strong></strong>]** – input tensor (B, D, L)</li><li><strong>ilens</strong> – input length (B)</li><li><strong>prev_states</strong> – Not to be used now.</li></ul></li><li><strong>Returns:</strong> position embedded tensor and mask</li></ul><div class="custom-h4"><p>forward_fusion<span class="small-bracket">(xs_pad: Dict[str, Tensor])</span></p></div><div class="custom-h4"><p>output_size()</p></div><div class="custom-h4"><p>reload_pretrained_parameters()</p></div><div class="custom-h4"><p>training <em>: bool</em></p></div>',10);function h(f,g){const r=a("RouteLink");return u(),n("div",null,[s(" _espnet2.asr.encoder.avhubert_encoder.FairseqAVHubertEncoder "),c,p,e("p",null,[t("Bases: "),i(r,{to:"/guide/espnet2/asr/AbsEncoder.html#espnet2.asr.encoder.abs_encoder.AbsEncoder"},{default:d(()=>[b]),_:1})]),m])}const V=o(_,[["render",h],["__file","FairseqAVHubertEncoder.html.vue"]]),A=JSON.parse(`{"path":"/guide/espnet2/asr/FairseqAVHubertEncoder.html","title":"espnet2.asr.encoder.avhubert_encoder.FairseqAVHubertEncoder","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.79,"words":238},"filePathRelative":"guide/espnet2/asr/FairseqAVHubertEncoder.md","excerpt":"<!-- _espnet2.asr.encoder.avhubert_encoder.FairseqAVHubertEncoder -->\\n<h1>espnet2.asr.encoder.avhubert_encoder.FairseqAVHubertEncoder</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.asr.encoder.avhubert_encoder.FairseqAVHubertEncoder<span class=\\"small-bracket\\">(input_size: int = 1, avhubert_url: str = './', avhubert_dir_path: str = './', freeze_finetune_updates: int = 0, encoder_embed_dim: int = 1024, encoder_layerdrop: float = 0.05, dropout_input: float = 0.1, dropout_features: float = 0.1, dropout: float = 0.1, attention_dropout: float = 0.1, feature_grad_mult: float = 0.1, activation_dropout: float = 0.0, wav_input: bool = False, layer_norm_first: bool = True, audio_feat_dim: int = 104, encoder_layers: int = 24, encoder_ffn_embed_dim: int = 4096, encoder_attention_heads: int = 16, extracted: bool = False, pretrain: bool = True, modality_dropout: float = 0.0, audio_dropout: float = 0.0, noise_augmentation: bool = False, noise_path: str = './data/babble_noise.pt', max_noise_weight: float = 0.5, audio_only: bool = False)</span></p></div>"}`);export{V as comp,A as data};
