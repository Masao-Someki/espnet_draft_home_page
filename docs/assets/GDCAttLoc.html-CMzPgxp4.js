import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,f as e,a as o,o as a}from"./app-KOUU_Wij.js";const s={},r=o('<h1 id="espnet-nets-pytorch-backend-rnn-attentions-gdcattloc" tabindex="-1"><a class="header-anchor" href="#espnet-nets-pytorch-backend-rnn-attentions-gdcattloc"><span>espnet.nets.pytorch_backend.rnn.attentions.GDCAttLoc</span></a></h1><div class="custom-h3"><p><em>class</em> espnet.nets.pytorch_backend.rnn.attentions.GDCAttLoc<span class="small-bracket">(eprojs, dunits, att_dim, aconv_chans, aconv_filts, han_mode=False)</span></p></div><p>Bases: <code>Module</code></p><p>Global duration control attention module. Reference: Singing-Tacotron: Global Duration Control Attention and Dynamic Filter for End-to-end Singing Voice Synthesis (<a href="https://arxiv.org/abs/2202.07907" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2202.07907</a>) :param int eprojs: # projection-units of encoder :param int dunits: # units of decoder :param int att_dim: attention dimension :param int aconv_chans: # channels of attention convolution :param int aconv_filts: filter size of attention convolution :param bool han_mode: flag to swith on mode of hierarchical attention</p><blockquote><p>and not store pre_compute_enc_h</p></blockquote><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p><div class="custom-h4"><p>forward<span class="small-bracket">(enc_hs_pad, enc_hs_len, trans_token, dec_z, att_prev, scaling=1.0, last_attended_idx=None, backward_window=1, forward_window=3)</span></p></div><p>Calcualte AttLoc forward propagation. :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc) :param list enc_hs_len: padded encoder hidden state length (B) :param torch.Tensor trans_token: Global transition token</p><blockquote><p>for duration (B x T_max x 1)</p></blockquote><ul><li><strong>Parameters:</strong><ul><li><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</li><li><strong>att_prev</strong> (<em>torch.Tensor</em>) – previous attention weight (B x T_max)</li><li><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</li><li><strong>forward_window</strong> (<em>int</em>) – forward window size when constraining attention</li><li><strong>last_attended_idx</strong> (<em>int</em>) – index of the inputs of the last attended</li><li><strong>backward_window</strong> (<em>int</em>) – backward window size in attention constraint</li><li><strong>forward_window</strong> – forward window size in attetion constraint</li></ul></li><li><strong>Returns:</strong> attention weighted encoder state (B, D_enc)</li><li><strong>Return type:</strong> torch.Tensor</li><li><strong>Returns:</strong> previous attention weights (B x T_max)</li><li><strong>Return type:</strong> torch.Tensor</li></ul><div class="custom-h4"><p>reset()</p></div><p>reset states</p><div class="custom-h4"><p>training <em>: bool</em></p></div>',13);function i(c,d){return a(),n("div",null,[e(" _espnet.nets.pytorch_backend.rnn.attentions.GDCAttLoc "),r])}const m=t(s,[["render",i],["__file","GDCAttLoc.html.vue"]]),_=JSON.parse('{"path":"/guide/espnet/nets/GDCAttLoc.html","title":"espnet.nets.pytorch_backend.rnn.attentions.GDCAttLoc","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.91,"words":273},"filePathRelative":"guide/espnet/nets/GDCAttLoc.md","excerpt":"<!-- _espnet.nets.pytorch_backend.rnn.attentions.GDCAttLoc -->\\n<h1>espnet.nets.pytorch_backend.rnn.attentions.GDCAttLoc</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet.nets.pytorch_backend.rnn.attentions.GDCAttLoc<span class=\\"small-bracket\\">(eprojs, dunits, att_dim, aconv_chans, aconv_filts, han_mode=False)</span></p></div>"}');export{m as comp,_ as data};
