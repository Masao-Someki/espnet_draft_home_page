import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as a,c as l,f as c,b as e,d as t,e as r,w as o,a as _,o as i}from"./app-KOUU_Wij.js";const d={},p=e("h1",{id:"espnet2-asr-encoder-e-branchformer-encoder-ebranchformerencoder",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-asr-encoder-e-branchformer-encoder-ebranchformerencoder"},[e("span",null,"espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder")])],-1),u=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder"),e("span",{class:"small-bracket"},"(input_size: int, output_size: int = 256, attention_heads: int = 4, attention_layer_type: str = 'rel_selfattn', pos_enc_layer_type: str = 'rel_pos', rel_pos_type: str = 'latest', cgmlp_linear_units: int = 2048, cgmlp_conv_kernel: int = 31, use_linear_after_conv: bool = False, gate_activation: str = 'identity', num_blocks: int = 12, dropout_rate: float = 0.1, positional_dropout_rate: float = 0.1, attention_dropout_rate: float = 0.0, input_layer: str | None = 'conv2d', zero_triu: bool = False, padding_idx: int = -1, layer_drop_rate: float = 0.0, max_pos_emb_len: int = 5000, use_ffn: bool = False, macaron_ffn: bool = False, ffn_activation_type: str = 'swish', linear_units: int = 2048, positionwise_layer_type: str = 'linear', merge_conv_kernel: int = 3, interctc_layer_idx=None, interctc_use_conditioning: bool = False)")])],-1),m=e("code",null,"AbsEncoder",-1),h=e("p",null,"E-Branchformer encoder module.",-1),f=e("p",null,"Initializes internal Module state, shared by both nn.Module and ScriptModule.",-1),b=e("div",{class:"custom-h4"},[e("p",null,[t("forward"),e("span",{class:"small-bracket"},[t("(xs_pad: Tensor, ilens: Tensor, prev_states: Tensor | None = None, ctc: "),e("a",{href:"CTC.md#espnet2.asr.ctc.CTC"},"CTC")]),t(" | None = None, max_layer: int | None = None)")])],-1),g=e("p",null,"Calculate forward propagation.",-1),y=e("strong",null,"Parameters:",-1),E=_("<li><strong>xs_pad</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, L, input_size).</li><li><strong>ilens</strong> (<em>torch.Tensor</em>) – Input length (#batch).</li><li><strong>prev_states</strong> (<em>torch.Tensor</em>) – Not to be used now.</li>",3),v=e("strong",null,"ctc",-1),T=e("em",null,"CTC",-1),C=e("li",null,[e("strong",null,"max_layer"),t(" ("),e("em",null,"int"),t(") – Layer depth below which InterCTC is applied.")],-1),N=e("li",null,[e("strong",null,"Returns:"),t(" Output tensor (#batch, L, output_size). torch.Tensor: Output length (#batch). torch.Tensor: Not to be used now.")],-1),x=e("li",null,[e("strong",null,"Return type:"),t(" torch.Tensor")],-1),B=e("div",{class:"custom-h4"},[e("p",null,"output_size()")],-1),k=e("div",{class:"custom-h4"},[e("p",null,[t("training "),e("em",null,": bool")])],-1);function w(z,F){const n=a("RouteLink");return i(),l("div",null,[c(" _espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder "),p,u,e("p",null,[t("Bases: "),r(n,{to:"/guide/espnet2/asr/AbsEncoder.html#espnet2.asr.encoder.abs_encoder.AbsEncoder"},{default:o(()=>[m]),_:1})]),h,f,b,g,e("ul",null,[e("li",null,[y,e("ul",null,[E,e("li",null,[v,t(" ("),r(n,{to:"/guide/espnet/nets/CTC.html#espnet.nets.chainer_backend.transformer.ctc.CTC"},{default:o(()=>[T]),_:1}),t(") – Intermediate CTC module.")]),C])]),N,x]),B,k])}const R=s(d,[["render",w],["__file","EBranchformerEncoder.html.vue"]]),V=JSON.parse(`{"path":"/guide/espnet2/asr/EBranchformerEncoder.html","title":"espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.77,"words":231},"filePathRelative":"guide/espnet2/asr/EBranchformerEncoder.md","excerpt":"<!-- _espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder -->\\n<h1>espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder<span class=\\"small-bracket\\">(input_size: int, output_size: int = 256, attention_heads: int = 4, attention_layer_type: str = 'rel_selfattn', pos_enc_layer_type: str = 'rel_pos', rel_pos_type: str = 'latest', cgmlp_linear_units: int = 2048, cgmlp_conv_kernel: int = 31, use_linear_after_conv: bool = False, gate_activation: str = 'identity', num_blocks: int = 12, dropout_rate: float = 0.1, positional_dropout_rate: float = 0.1, attention_dropout_rate: float = 0.0, input_layer: str | None = 'conv2d', zero_triu: bool = False, padding_idx: int = -1, layer_drop_rate: float = 0.0, max_pos_emb_len: int = 5000, use_ffn: bool = False, macaron_ffn: bool = False, ffn_activation_type: str = 'swish', linear_units: int = 2048, positionwise_layer_type: str = 'linear', merge_conv_kernel: int = 3, interctc_layer_idx=None, interctc_use_conditioning: bool = False)</span></p></div>"}`);export{R as comp,V as data};
