import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as t,c as s,f as n,b as e,d as r,e as l,w as i,a as m,o as p}from"./app-KOUU_Wij.js";const u={},_=e("h1",{id:"espnet2-enh-separator-neural-beamformer-neuralbeamformer",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-enh-separator-neural-beamformer-neuralbeamformer"},[e("span",null,"espnet2.enh.separator.neural_beamformer.NeuralBeamformer")])],-1),d=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),r(" espnet2.enh.separator.neural_beamformer.NeuralBeamformer"),e("span",{class:"small-bracket"},"(input_dim: int, num_spk: int = 1, loss_type: str = 'mask_mse', use_wpe: bool = False, wnet_type: str = 'blstmp', wlayers: int = 3, wunits: int = 300, wprojs: int = 320, wdropout_rate: float = 0.0, taps: int = 5, delay: int = 3, use_dnn_mask_for_wpe: bool = True, wnonlinear: str = 'crelu', multi_source_wpe: bool = True, wnormalization: bool = False, use_beamformer: bool = True, bnet_type: str = 'blstmp', blayers: int = 3, bunits: int = 300, bprojs: int = 320, badim: int = 320, ref_channel: int = -1, use_noise_mask: bool = True, bnonlinear: str = 'sigmoid', beamformer_type: str = 'mvdr_souden', rtf_iterations: int = 2, bdropout_rate: float = 0.0, shared_power: bool = True, use_torchaudio_api: bool = False, diagonal_loading: bool = True, diag_eps_wpe: float = 1e-07, diag_eps_bf: float = 1e-07, mask_flooring: bool = False, flooring_thres_wpe: float = 1e-06, flooring_thres_bf: float = 1e-06, use_torch_solver: bool = True)")])],-1),c=e("code",null,"AbsSeparator",-1),h=m('<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p><div class="custom-h4"><p>forward<span class="small-bracket">(input: Tensor | ComplexTensor, ilens: Tensor, additional: Dict | None = None)</span></p></div><p>Forward.</p><ul><li><p><strong>Parameters:</strong></p><ul><li><strong>input</strong> (<em>torch.complex64/ComplexTensor</em>) – mixed speech [Batch, Frames, Channel, Freq]</li><li><strong>ilens</strong> (<em>torch.Tensor</em>) – input lengths [Batch]</li><li><strong>additional</strong> (<em>Dict</em> <em>or</em> <em>None</em>) – other data included in model NOTE: not used in this model</li></ul></li><li><p><strong>Returns:</strong> List[torch.complex64/ComplexTensor] output lengths other predcited data: OrderedDict[</p><blockquote><p>’dereverb1’: ComplexTensor(Batch, Frames, Channel, Freq), ‘mask_dereverb1’: torch.Tensor(Batch, Frames, Channel, Freq), ‘mask_noise1’: torch.Tensor(Batch, Frames, Channel, Freq), ‘mask_spk1’: torch.Tensor(Batch, Frames, Channel, Freq), ‘mask_spk2’: torch.Tensor(Batch, Frames, Channel, Freq), … ‘mask_spkn’: torch.Tensor(Batch, Frames, Channel, Freq),</p></blockquote><p>]</p></li><li><p><strong>Return type:</strong> enhanced speech (single-channel)</p></li></ul><div class="custom-h4"><p><em>property</em> num_spk</p></div><div class="custom-h4"><p>training <em>: bool</em></p></div>',6);function b(f,g){const o=t("RouteLink");return p(),s("div",null,[n(" _espnet2.enh.separator.neural_beamformer.NeuralBeamformer "),_,d,e("p",null,[r("Bases: "),l(o,{to:"/guide/espnet2/enh/AbsSeparator.html#espnet2.enh.separator.abs_separator.AbsSeparator"},{default:i(()=>[c]),_:1})]),h])}const k=a(u,[["render",b],["__file","NeuralBeamformer.html.vue"]]),B=JSON.parse(`{"path":"/guide/espnet2/enh/NeuralBeamformer.html","title":"espnet2.enh.separator.neural_beamformer.NeuralBeamformer","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.89,"words":268},"filePathRelative":"guide/espnet2/enh/NeuralBeamformer.md","excerpt":"<!-- _espnet2.enh.separator.neural_beamformer.NeuralBeamformer -->\\n<h1>espnet2.enh.separator.neural_beamformer.NeuralBeamformer</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.enh.separator.neural_beamformer.NeuralBeamformer<span class=\\"small-bracket\\">(input_dim: int, num_spk: int = 1, loss_type: str = 'mask_mse', use_wpe: bool = False, wnet_type: str = 'blstmp', wlayers: int = 3, wunits: int = 300, wprojs: int = 320, wdropout_rate: float = 0.0, taps: int = 5, delay: int = 3, use_dnn_mask_for_wpe: bool = True, wnonlinear: str = 'crelu', multi_source_wpe: bool = True, wnormalization: bool = False, use_beamformer: bool = True, bnet_type: str = 'blstmp', blayers: int = 3, bunits: int = 300, bprojs: int = 320, badim: int = 320, ref_channel: int = -1, use_noise_mask: bool = True, bnonlinear: str = 'sigmoid', beamformer_type: str = 'mvdr_souden', rtf_iterations: int = 2, bdropout_rate: float = 0.0, shared_power: bool = True, use_torchaudio_api: bool = False, diagonal_loading: bool = True, diag_eps_wpe: float = 1e-07, diag_eps_bf: float = 1e-07, mask_flooring: bool = False, flooring_thres_wpe: float = 1e-06, flooring_thres_bf: float = 1e-06, use_torch_solver: bool = True)</span></p></div>"}`);export{k as comp,B as data};
