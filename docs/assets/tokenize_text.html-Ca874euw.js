import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,o as s,a}from"./app-KOUU_Wij.js";const i={},p=a(`<p>&lt;!-- _tokenize_text.py --&gt;</p><h1 id="tokenize-text-py" tabindex="-1"><a class="header-anchor" href="#tokenize-text-py"><span>tokenize_text.py</span></a></h1><p>Tokenize texts</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" data-title="text" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>usage: tokenize_text.py [-h]</span></span>
<span class="line"><span>                        [--log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}]</span></span>
<span class="line"><span>                        --input INPUT --output OUTPUT</span></span>
<span class="line"><span>                        [--field FIELD]</span></span>
<span class="line"><span>                        [--token_type {char,bpe,word,phn}]</span></span>
<span class="line"><span>                        [--delimiter DELIMITER]</span></span>
<span class="line"><span>                        [--space_symbol SPACE_SYMBOL]</span></span>
<span class="line"><span>                        [--bpemodel BPEMODEL]</span></span>
<span class="line"><span>                        [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]</span></span>
<span class="line"><span>                        [--remove_non_linguistic_symbols REMOVE_NON_LINGUISTIC_SYMBOLS]</span></span>
<span class="line"><span>                        [--cleaner {None,tacotron,jaconv,vietnamese,korean_cleaner,whisper_en,whisper_basic}]</span></span>
<span class="line"><span>                        [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2p_phone,pypinyin_g2p_phone_without_prosody,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_english_us_vits,espeak_ng_hindi,espeak_ng_italian,espeak_ng_ukrainian,espeak_ng_polish,g2pk,g2pk_no_space,g2pk_explicit_space,korean_jaso,korean_jaso_no_space,g2p_is}]</span></span>
<span class="line"><span>                        [--write_vocabulary WRITE_VOCABULARY]</span></span>
<span class="line"><span>                        [--vocabulary_size VOCABULARY_SIZE]</span></span>
<span class="line"><span>                        [--cutoff CUTOFF] [--add_symbol ADD_SYMBOL]</span></span>
<span class="line"><span>                        [--add_nonsplit_symbol ADD_NONSPLIT_SYMBOL]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="named-arguments" tabindex="-1"><a class="header-anchor" href="#named-arguments"><span>Named Arguments</span></a></h2><h2 id="write-vocabulary-mode-related" tabindex="-1"><a class="header-anchor" href="#write-vocabulary-mode-related"><span>write_vocabulary mode related</span></a></h2>`,6),l=[p];function t(_,r){return s(),e("div",null,l)}const o=n(i,[["render",t],["__file","tokenize_text.html.vue"]]),u=JSON.parse('{"path":"/tools/espnet2_bin/tokenize_text.html","title":"tokenize_text.py","lang":"en-US","frontmatter":{},"headers":[{"level":2,"title":"Named Arguments","slug":"named-arguments","link":"#named-arguments","children":[]},{"level":2,"title":"write_vocabulary mode related","slug":"write-vocabulary-mode-related","link":"#write-vocabulary-mode-related","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.31,"words":93},"filePathRelative":"tools/espnet2_bin/tokenize_text.md","excerpt":"<p>&lt;!-- _tokenize_text.py --&gt;</p>\\n<h1>tokenize_text.py</h1>\\n<p>Tokenize texts</p>\\n<div class=\\"language-text line-numbers-mode\\" data-highlighter=\\"shiki\\" data-ext=\\"text\\" data-title=\\"text\\" style=\\"--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34\\"><pre class=\\"shiki shiki-themes github-light one-dark-pro vp-code\\"><code><span class=\\"line\\"><span>usage: tokenize_text.py [-h]</span></span>\\n<span class=\\"line\\"><span>                        [--log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}]</span></span>\\n<span class=\\"line\\"><span>                        --input INPUT --output OUTPUT</span></span>\\n<span class=\\"line\\"><span>                        [--field FIELD]</span></span>\\n<span class=\\"line\\"><span>                        [--token_type {char,bpe,word,phn}]</span></span>\\n<span class=\\"line\\"><span>                        [--delimiter DELIMITER]</span></span>\\n<span class=\\"line\\"><span>                        [--space_symbol SPACE_SYMBOL]</span></span>\\n<span class=\\"line\\"><span>                        [--bpemodel BPEMODEL]</span></span>\\n<span class=\\"line\\"><span>                        [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]</span></span>\\n<span class=\\"line\\"><span>                        [--remove_non_linguistic_symbols REMOVE_NON_LINGUISTIC_SYMBOLS]</span></span>\\n<span class=\\"line\\"><span>                        [--cleaner {None,tacotron,jaconv,vietnamese,korean_cleaner,whisper_en,whisper_basic}]</span></span>\\n<span class=\\"line\\"><span>                        [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2p_phone,pypinyin_g2p_phone_without_prosody,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_english_us_vits,espeak_ng_hindi,espeak_ng_italian,espeak_ng_ukrainian,espeak_ng_polish,g2pk,g2pk_no_space,g2pk_explicit_space,korean_jaso,korean_jaso_no_space,g2p_is}]</span></span>\\n<span class=\\"line\\"><span>                        [--write_vocabulary WRITE_VOCABULARY]</span></span>\\n<span class=\\"line\\"><span>                        [--vocabulary_size VOCABULARY_SIZE]</span></span>\\n<span class=\\"line\\"><span>                        [--cutoff CUTOFF] [--add_symbol ADD_SYMBOL]</span></span>\\n<span class=\\"line\\"><span>                        [--add_nonsplit_symbol ADD_NONSPLIT_SYMBOL]</span></span></code></pre>\\n<div class=\\"line-numbers\\" aria-hidden=\\"true\\" style=\\"counter-reset:line-number 0\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>"}');export{o as comp,u as data};
