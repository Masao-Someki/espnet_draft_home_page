import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as i,c as s,f as r,b as e,d as t,e as a,w as l,a as m,o as d}from"./app-KOUU_Wij.js";const g={},p=e("h1",{id:"espnet2-svs-naive-rnn-naive-rnn-dp-naivernndp",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-svs-naive-rnn-naive-rnn-dp-naivernndp"},[e("span",null,"espnet2.svs.naive_rnn.naive_rnn_dp.NaiveRNNDP")])],-1),c=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet2.svs.naive_rnn.naive_rnn_dp.NaiveRNNDP"),e("span",{class:"small-bracket"},"(idim: int, odim: int, midi_dim: int = 129, embed_dim: int = 512, duration_dim: int = 500, eprenet_conv_layers: int = 3, eprenet_conv_chans: int = 256, eprenet_conv_filts: int = 5, elayers: int = 3, eunits: int = 1024, ebidirectional: bool = True, midi_embed_integration_type: str = 'add', dlayers: int = 3, dunits: int = 1024, dbidirectional: bool = True, postnet_layers: int = 5, postnet_chans: int = 256, postnet_filts: int = 5, use_batch_norm: bool = True, duration_predictor_layers: int = 2, duration_predictor_chans: int = 384, duration_predictor_kernel_size: int = 3, duration_predictor_dropout_rate: float = 0.1, reduction_factor: int = 1, spks: int | None = None, langs: int | None = None, spk_embed_dim: int | None = None, spk_embed_integration_type: str = 'add', eprenet_dropout_rate: float = 0.5, edropout_rate: float = 0.1, ddropout_rate: float = 0.1, postnet_dropout_rate: float = 0.5, init_type: str = 'xavier_uniform', use_masking: bool = False, use_weighted_masking: bool = False)")])],-1),_=e("code",null,"AbsSVS",-1),u=m('<p>NaiveRNNDP-SVS module.</p><p>This is an implementation of naive RNN with duration prediction for singing voice synthesis The features are processed directly over time-domain from music score and predict the singing voice features</p><p>Initialize NaiveRNNDP module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>idim</strong> (<em>int</em>) – Dimension of the label inputs.</li><li><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</li><li><strong>midi_dim</strong> (<em>int</em>) – Dimension of the midi inputs.</li><li><strong>embed_dim</strong> (<em>int</em>) – Dimension of the token embedding.</li><li><strong>eprenet_conv_layers</strong> (<em>int</em>) – Number of prenet conv layers.</li><li><strong>eprenet_conv_filts</strong> (<em>int</em>) – Number of prenet conv filter size.</li><li><strong>eprenet_conv_chans</strong> (<em>int</em>) – Number of prenet conv filter channels.</li><li><strong>elayers</strong> (<em>int</em>) – Number of encoder layers.</li><li><strong>eunits</strong> (<em>int</em>) – Number of encoder hidden units.</li><li><strong>ebidirectional</strong> (<em>bool</em>) – If bidirectional in encoder.</li><li><strong>midi_embed_integration_type</strong> (<em>str</em>) – how to integrate midi information, (“add” or “cat”).</li><li><strong>dlayers</strong> (<em>int</em>) – Number of decoder lstm layers.</li><li><strong>dunits</strong> (<em>int</em>) – Number of decoder lstm units.</li><li><strong>dbidirectional</strong> (<em>bool</em>) – if bidirectional in decoder.</li><li><strong>postnet_layers</strong> (<em>int</em>) – Number of postnet layers.</li><li><strong>postnet_filts</strong> (<em>int</em>) – Number of postnet filter size.</li><li><strong>postnet_chans</strong> (<em>int</em>) – Number of postnet filter channels.</li><li><strong>use_batch_norm</strong> (<em>bool</em>) – Whether to use batch normalization.</li><li><strong>reduction_factor</strong> (<em>int</em>) – Reduction factor.</li><li><strong>duration_predictor_layers</strong> (<em>int</em>) – Number of duration predictor layers.</li><li><strong>duration_predictor_chans</strong> (<em>int</em>) – Number of duration predictor channels.</li><li><strong>duration_predictor_kernel_size</strong> (<em>int</em>) – Kernel size of duration predictor.</li><li><strong>duration_predictor_dropout_rate</strong> (<em>float</em>) – Dropout rate in duration predictor.</li><li><strong>related</strong> ( <em># extra embedding</em>) –</li><li><strong>spks</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Number of speakers. If set to &gt; 1, assume that the sids will be provided as the input and use sid embedding layer.</li><li><strong>langs</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Number of languages. If set to &gt; 1, assume that the lids will be provided as the input and use sid embedding layer.</li><li><strong>spk_embed_dim</strong> (<em>Optional</em> *[*<em>int</em> <em>]</em>) – Speaker embedding dimension. If set to &gt; 0, assume that spembs will be provided as the input.</li><li><strong>spk_embed_integration_type</strong> (<em>str</em>) – How to integrate speaker embedding.</li><li><strong>eprenet_dropout_rate</strong> (<em>float</em>) – Prenet dropout rate.</li><li><strong>edropout_rate</strong> (<em>float</em>) – Encoder dropout rate.</li><li><strong>ddropout_rate</strong> (<em>float</em>) – Decoder dropout rate.</li><li><strong>postnet_dropout_rate</strong> (<em>float</em>) – Postnet dropout_rate.</li><li><strong>init_type</strong> (<em>str</em>) – How to initialize transformer parameters.</li><li><strong>use_masking</strong> (<em>bool</em>) – Whether to mask padded part in loss calculation.</li><li><strong>use_weighted_masking</strong> (<em>bool</em>) – Whether to apply weighted masking in loss calculation.</li></ul></li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(text: Tensor, text_lengths: Tensor, feats: Tensor, feats_lengths: Tensor, label: Dict[str, Tensor] | None = None, label_lengths: Dict[str, Tensor] | None = None, melody: Dict[str, Tensor] | None = None, melody_lengths: Dict[str, Tensor] | None = None, pitch: Tensor | None = None, pitch_lengths: Tensor | None = None, duration: Dict[str, Tensor] | None = None, duration_lengths: Dict[str, Tensor] | None = None, slur: LongTensor | None = None, slur_lengths: Tensor | None = None, spembs: Tensor | None = None, sids: Tensor | None = None, lids: Tensor | None = None, joint_training: bool = False, flag_IsValid=False)</span></p></div><p>Calculate forward propagation.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>LongTensor</em>) – Batch of padded character ids (B, Tmax).</li><li><strong>text_lengths</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</li><li><strong>feats</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</li><li><strong>feats_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</li><li><strong>label</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded label ids (B, Tmax).</li><li><strong>label_lengths</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of the lengths of padded label ids (B, ).</li><li><strong>melody</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded melody (B, Tmax).</li><li><strong>melody_lengths</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of the lengths of padded melody (B, ).</li><li><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (B, Tmax).</li><li><strong>pitch_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of padded f0 (B, ).</li><li><strong>duration</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab”, “score_phn” or “score_syb”; value (LongTensor): Batch of padded duration (B, Tmax).</li><li><strong>duration_length</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab”, “score_phn” or “score_syb”; value (LongTensor): Batch of the lengths of padded duration (B, ).</li><li><strong>slur</strong> (<em>LongTensor</em>) – Batch of padded slur (B, Tmax).</li><li><strong>slur_lengths</strong> (<em>LongTensor</em>) – Batch of the lengths of padded slur (B, ).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker embeddings (B, spk_embed_dim).</li><li><strong>sids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker IDs (B, 1).</li><li><strong>lids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of language IDs (B, 1).</li><li><strong>joint_training</strong> (<em>bool</em>) – Whether to perform joint training with vocoder.</li></ul></li></ul><p>GS Fix: : arguements from forward func. V.S. &lt;br/&gt;</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>**</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>&lt;br/&gt; batch from espnet_model.py label == durations | phone sequence melody -&gt; pitch sequence</p><ul><li><strong>Returns:</strong> Loss scalar value. Dict: Statistics to be monitored. Tensor: Weight value if not joint training else model outputs.</li><li><strong>Return type:</strong> Tensor</li></ul><div class="custom-h4"><p>inference<span class="small-bracket">(text: Tensor, feats: Tensor | None = None, label: Dict[str, Tensor] | None = None, melody: Dict[str, Tensor] | None = None, pitch: Tensor | None = None, duration: Dict[str, Tensor] | None = None, slur: Dict[str, Tensor] | None = None, spembs: Tensor | None = None, sids: Tensor | None = None, lids: Tensor | None = None, joint_training: bool = False, use_teacher_forcing: Tensor = False)</span></p></div><p>Calculate forward propagation.</p><ul><li><strong>Parameters:</strong><ul><li><strong>text</strong> (<em>LongTensor</em>) – Batch of padded character ids (Tmax).</li><li><strong>feats</strong> (<em>Tensor</em>) – Batch of padded target features (Lmax, odim).</li><li><strong>label</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded label ids (Tmax).</li><li><strong>melody</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab” or “score”; value (LongTensor): Batch of padded melody (Tmax).</li><li><strong>pitch</strong> (<em>FloatTensor</em>) – Batch of padded f0 (Tmax).</li><li><strong>duration</strong> (<em>Optional</em> *[*<em>Dict</em> <em>]</em>) – key is “lab”, “score_phn” or “score_syb”; value (LongTensor): Batch of padded duration (Tmax).</li><li><strong>slur</strong> (<em>LongTensor</em>) – Batch of padded slur (B, Tmax).</li><li><strong>spembs</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker embeddings (spk_embed_dim).</li><li><strong>sids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of speaker IDs (1).</li><li><strong>lids</strong> (<em>Optional</em> *[*<em>Tensor</em> <em>]</em>) – Batch of language IDs (1).</li></ul></li><li><strong>Returns:</strong> Output dict including the following items: : * feat_gen (Tensor): Output sequence of features (T_feats, odim).</li><li><strong>Return type:</strong> Dict[str, Tensor]</li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',15);function h(f,b){const n=i("RouteLink");return d(),s("div",null,[r(" _espnet2.svs.naive_rnn.naive_rnn_dp.NaiveRNNDP "),p,c,e("p",null,[t("Bases: "),a(n,{to:"/guide/espnet2/svs/AbsSVS.html#espnet2.svs.abs_svs.AbsSVS"},{default:l(()=>[_]),_:1})]),u])}const T=o(g,[["render",h],["__file","NaiveRNNDP.html.vue"]]),y=JSON.parse(`{"path":"/guide/espnet2/svs/NaiveRNNDP.html","title":"espnet2.svs.naive_rnn.naive_rnn_dp.NaiveRNNDP","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":3.46,"words":1037},"filePathRelative":"guide/espnet2/svs/NaiveRNNDP.md","excerpt":"<!-- _espnet2.svs.naive_rnn.naive_rnn_dp.NaiveRNNDP -->\\n<h1>espnet2.svs.naive_rnn.naive_rnn_dp.NaiveRNNDP</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.svs.naive_rnn.naive_rnn_dp.NaiveRNNDP<span class=\\"small-bracket\\">(idim: int, odim: int, midi_dim: int = 129, embed_dim: int = 512, duration_dim: int = 500, eprenet_conv_layers: int = 3, eprenet_conv_chans: int = 256, eprenet_conv_filts: int = 5, elayers: int = 3, eunits: int = 1024, ebidirectional: bool = True, midi_embed_integration_type: str = 'add', dlayers: int = 3, dunits: int = 1024, dbidirectional: bool = True, postnet_layers: int = 5, postnet_chans: int = 256, postnet_filts: int = 5, use_batch_norm: bool = True, duration_predictor_layers: int = 2, duration_predictor_chans: int = 384, duration_predictor_kernel_size: int = 3, duration_predictor_dropout_rate: float = 0.1, reduction_factor: int = 1, spks: int | None = None, langs: int | None = None, spk_embed_dim: int | None = None, spk_embed_integration_type: str = 'add', eprenet_dropout_rate: float = 0.5, edropout_rate: float = 0.1, ddropout_rate: float = 0.1, postnet_dropout_rate: float = 0.5, init_type: str = 'xavier_uniform', use_masking: bool = False, use_weighted_masking: bool = False)</span></p></div>"}`);export{T as comp,y as data};
