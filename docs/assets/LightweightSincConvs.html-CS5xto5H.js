import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as o,c as s,f as r,b as e,d as t,e as a,w as l,a as c,o as p}from"./app-KOUU_Wij.js";const h={},u=e("h1",{id:"espnet2-asr-preencoder-sinc-lightweightsincconvs",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-asr-preencoder-sinc-lightweightsincconvs"},[e("span",null,"espnet2.asr.preencoder.sinc.LightweightSincConvs")])],-1),d=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),t(" espnet2.asr.preencoder.sinc.LightweightSincConvs"),e("span",{class:"small-bracket"},"(fs: int | str | float = 16000, in_channels: int = 1, out_channels: int = 256, activation_type: str = 'leakyrelu', dropout_type: str = 'dropout', windowing_type: str = 'hamming', scale_type: str = 'mel')")])],-1),g=e("code",null,"AbsPreEncoder",-1),_=c('<p>Lightweight Sinc Convolutions.</p><p>Instead of using precomputed features, end-to-end speech recognition can also be done directly from raw audio using sinc convolutions, as described in “Lightweight End-to-End Speech Recognition from Raw Audio Data Using Sinc-Convolutions” by Kürzinger et al. <a href="https://arxiv.org/abs/2010.07597" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2010.07597</a></p><p>To use Sinc convolutions in your model instead of the default f-bank frontend, set this module as your pre-encoder with preencoder: sinc and use the input of the sliding window frontend with frontend: sliding_window in your yaml configuration file. So that the process flow is:</p><p>Frontend (SlidingWindow) -&gt; SpecAug -&gt; Normalization -&gt; Pre-encoder (LightweightSincConvs) -&gt; Encoder -&gt; Decoder</p><p>Note that this method also performs data augmentation in time domain (vs. in spectral domain in the default frontend). Use plot_sinc_filters.py to visualize the learned Sinc filters.</p><p>Initialize the module.</p><ul><li><strong>Parameters:</strong><ul><li><strong>fs</strong> – Sample rate.</li><li><strong>in_channels</strong> – Number of input channels.</li><li><strong>out_channels</strong> – Number of output channels (for each input channel).</li><li><strong>activation_type</strong> – Choice of activation function.</li><li><strong>dropout_type</strong> – Choice of dropout function.</li><li><strong>windowing_type</strong> – Choice of windowing function.</li><li><strong>scale_type</strong> – Choice of filter-bank initialization scale.</li></ul></li></ul><div class="custom-h4"><p>espnet_initialization_fn()</p></div><p>Initialize sinc filters with filterbank values.</p><div class="custom-h4"><p>forward<span class="small-bracket">(input: Tensor, input_lengths: Tensor)</span></p></div><p>Apply Lightweight Sinc Convolutions.</p><p>The input shall be formatted as (B, T, C_in, D_in) with B as batch size, T as time dimension, C_in as channels, and D_in as feature dimension.</p><p>The output will then be (B, T, C_out*D_out) with C_out and D_out as output dimensions.</p><p>The current module structure only handles D_in=400, so that D_out=1. Remark for the multichannel case: C_out is the number of out_channels given at initialization multiplied with C_in.</p><div class="custom-h4"><p>gen_lsc_block<span class="small-bracket">(in_channels: int, out_channels: int, depthwise_kernel_size: int = 9, depthwise_stride: int = 1, depthwise_groups=None, pointwise_groups=0, dropout_probability: float = 0.15, avgpool=False)</span></p></div><p>Generate a convolutional block for Lightweight Sinc convolutions.</p><p>Each block consists of either a depthwise or a depthwise-separable convolutions together with dropout, (batch-)normalization layer, and an optional average-pooling layer.</p><ul><li><strong>Parameters:</strong><ul><li><strong>in_channels</strong> – Number of input channels.</li><li><strong>out_channels</strong> – Number of output channels.</li><li><strong>depthwise_kernel_size</strong> – Kernel size of the depthwise convolution.</li><li><strong>depthwise_stride</strong> – Stride of the depthwise convolution.</li><li><strong>depthwise_groups</strong> – Number of groups of the depthwise convolution.</li><li><strong>pointwise_groups</strong> – Number of groups of the pointwise convolution.</li><li><strong>dropout_probability</strong> – Dropout probability in the block.</li><li><strong>avgpool</strong> – If True, an AvgPool layer is inserted.</li></ul></li><li><strong>Returns:</strong> Neural network building block.</li><li><strong>Return type:</strong> torch.nn.Sequential</li></ul><div class="custom-h4"><p>output_size()</p></div><p>Get the output size.</p><div class="custom-h4"><p>training <em>: bool</em></p></div>',21);function m(f,w){const n=o("RouteLink");return p(),s("div",null,[r(" _espnet2.asr.preencoder.sinc.LightweightSincConvs "),u,d,e("p",null,[t("Bases: "),a(n,{to:"/guide/espnet2/asr/AbsPreEncoder.html#espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder"},{default:l(()=>[g]),_:1})]),_])}const y=i(h,[["render",m],["__file","LightweightSincConvs.html.vue"]]),C=JSON.parse(`{"path":"/guide/espnet2/asr/LightweightSincConvs.html","title":"espnet2.asr.preencoder.sinc.LightweightSincConvs","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.59,"words":477},"filePathRelative":"guide/espnet2/asr/LightweightSincConvs.md","excerpt":"<!-- _espnet2.asr.preencoder.sinc.LightweightSincConvs -->\\n<h1>espnet2.asr.preencoder.sinc.LightweightSincConvs</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.asr.preencoder.sinc.LightweightSincConvs<span class=\\"small-bracket\\">(fs: int | str | float = 16000, in_channels: int = 1, out_channels: int = 256, activation_type: str = 'leakyrelu', dropout_type: str = 'dropout', windowing_type: str = 'hamming', scale_type: str = 'mel')</span></p></div>"}`);export{y as comp,C as data};
