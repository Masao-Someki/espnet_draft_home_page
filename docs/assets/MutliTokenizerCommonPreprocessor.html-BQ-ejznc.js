import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r,c as n,f as a,b as e,d as o,e as i,w as p,o as l}from"./app-KOUU_Wij.js";const c={},_=e("h1",{id:"espnet2-train-preprocessor-mutlitokenizercommonpreprocessor",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2-train-preprocessor-mutlitokenizercommonpreprocessor"},[e("span",null,"espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor")])],-1),m=e("div",{class:"custom-h3"},[e("p",null,[e("em",null,"class"),o(" espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor"),e("span",{class:"small-bracket"},"(train: bool, token_type: List[str] = [None], token_list: List[Path | str | Iterable[str]] = [None], bpemodel: List[Path | str | Iterable[str]] = [None], text_cleaner: Collection[str] | None = None, g2p_type: List[str] | str | None = None, unk_symbol: str = '<unk>', space_symbol: str = '<space>', non_linguistic_symbols: Path | str | Iterable[str] | None = None, delimiter: str | None = None, rir_scp: str | None = None, rir_apply_prob: float = 1.0, noise_scp: str | None = None, noise_apply_prob: float = 1.0, noise_db_range: str = '3_10', short_noise_thres: float = 0.5, speech_volume_normalize: float | None = None, speech_name: str = 'speech', text_name: List[str] = ['text'], tokenizer_encode_conf: List[Dict] = [{}, {}], fs: int = 0, data_aug_effects: List | None = None, data_aug_num: List[int] = [1, 1], data_aug_prob: float = 0.0, whisper_language: List[str] | None = None, whisper_task: str | None = None)")])],-1),u=e("code",null,"CommonPreprocessor",-1);function N(d,h){const t=r("RouteLink");return l(),n("div",null,[a(" _espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor "),_,m,e("p",null,[o("Bases: "),i(t,{to:"/guide/espnet2/train/CommonPreprocessor.html#espnet2.train.preprocessor.CommonPreprocessor"},{default:p(()=>[u]),_:1})])])}const b=s(c,[["render",N],["__file","MutliTokenizerCommonPreprocessor.html.vue"]]),g=JSON.parse(`{"path":"/guide/espnet2/train/MutliTokenizerCommonPreprocessor.html","title":"espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":0.44,"words":132},"filePathRelative":"guide/espnet2/train/MutliTokenizerCommonPreprocessor.md","excerpt":"<!-- _espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor -->\\n<h1>espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.train.preprocessor.MutliTokenizerCommonPreprocessor<span class=\\"small-bracket\\">(train: bool, token_type: List[str] = [None], token_list: List[Path | str | Iterable[str]] = [None], bpemodel: List[Path | str | Iterable[str]] = [None], text_cleaner: Collection[str] | None = None, g2p_type: List[str] | str | None = None, unk_symbol: str = '&lt;unk&gt;', space_symbol: str = '&lt;space&gt;', non_linguistic_symbols: Path | str | Iterable[str] | None = None, delimiter: str | None = None, rir_scp: str | None = None, rir_apply_prob: float = 1.0, noise_scp: str | None = None, noise_apply_prob: float = 1.0, noise_db_range: str = '3_10', short_noise_thres: float = 0.5, speech_volume_normalize: float | None = None, speech_name: str = 'speech', text_name: List[str] = ['text'], tokenizer_encode_conf: List[Dict] = [{}, {}], fs: int = 0, data_aug_effects: List | None = None, data_aug_num: List[int] = [1, 1], data_aug_prob: float = 0.0, whisper_language: List[str] | None = None, whisper_task: str | None = None)</span></p></div>"}`);export{b as comp,g as data};
