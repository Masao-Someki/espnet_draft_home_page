import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,f as s,a as t,o}from"./app-KOUU_Wij.js";const r={},i=t('<h1 id="espnet2-asr-transducer-encoder-blocks-conv1d-conv1d" tabindex="-1"><a class="header-anchor" href="#espnet2-asr-transducer-encoder-blocks-conv1d-conv1d"><span>espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d</span></a></h1><div class="custom-h3"><p><em>class</em> espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d<span class="small-bracket">(input_size: int, output_size: int, kernel_size: int | Tuple, stride: int | Tuple = 1, dilation: int | Tuple = 1, groups: int | Tuple = 1, bias: bool = True, batch_norm: bool = False, relu: bool = True, causal: bool = False, dropout_rate: float = 0.0)</span></p></div><p>Bases: <code>Module</code></p><p>Conv1d module definition.</p><ul><li><strong>Parameters:</strong><ul><li><strong>input_size</strong> – Input dimension.</li><li><strong>output_size</strong> – Output dimension.</li><li><strong>kernel_size</strong> – Size of the convolving kernel.</li><li><strong>stride</strong> – Stride of the convolution.</li><li><strong>dilation</strong> – Spacing between the kernel points.</li><li><strong>groups</strong> – Number of blocked connections from input channels to output channels.</li><li><strong>bias</strong> – Whether to add a learnable bias to the output.</li><li><strong>batch_norm</strong> – Whether to use batch normalization after convolution.</li><li><strong>relu</strong> – Whether to use a ReLU activation after convolution.</li><li><strong>causal</strong> – Whether to use causal convolution (set to True if streaming).</li><li><strong>dropout_rate</strong> – Dropout rate.</li></ul></li></ul><p>Construct a Conv1d object.</p><div class="custom-h4"><p>chunk_forward<span class="small-bracket">(x: Tensor, pos_enc: Tensor, mask: Tensor, left_context: int = 0)</span></p></div><p>Encode chunk of input sequence.</p><ul><li><strong>Parameters:</strong><ul><li><strong>x</strong> – Conv1d input sequences. (B, T, D_in)</li><li><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_in)</li><li><strong>mask</strong> – Source mask. (B, T)</li><li><strong>left_context</strong> – Number of previous frames the attention module can see in current chunk (not used here).</li></ul></li><li><strong>Returns:</strong> Conv1d output sequences. (B, T, D_out) pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_out)</li><li><strong>Return type:</strong> x</li></ul><div class="custom-h4"><p>create_new_mask<span class="small-bracket">(mask: Tensor)</span></p></div><p>Create new mask for output sequences.</p><ul><li><strong>Parameters:</strong><strong>mask</strong> – Mask of input sequences. (B, T)</li><li><strong>Returns:</strong> Mask of output sequences. (B, sub(T))</li><li><strong>Return type:</strong> mask</li></ul><div class="custom-h4"><p>create_new_pos_enc<span class="small-bracket">(pos_enc: Tensor)</span></p></div><p>Create new positional embedding vector.</p><ul><li><strong>Parameters:</strong><strong>pos_enc</strong> – Input sequences positional embedding. (B, 2 * (T - 1), D_in)</li><li><strong>Returns:</strong> Output sequences positional embedding. : (B, 2 * (sub(T) - 1), D_in)</li><li><strong>Return type:</strong> pos_enc</li></ul><div class="custom-h4"><p>forward<span class="small-bracket">(x: Tensor, pos_enc: Tensor, mask: Tensor | None = None, chunk_mask: Tensor | None = None)</span></p></div><p>Encode input sequences.</p><ul><li><strong>Parameters:</strong><ul><li><strong>x</strong> – Conv1d input sequences. (B, T, D_in)</li><li><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_in)</li><li><strong>mask</strong> – Source mask. (B, T)</li><li><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</li></ul></li><li><strong>Returns:</strong> Conv1d output sequences. (B, sub(T), D_out) mask: Source mask. (B, T) or (B, sub(T)) pos_enc: Positional embedding sequences. <blockquote><p>(B, 2 * (T - 1), D_att) or (B, 2 * (sub(T) - 1), D_out)</p></blockquote></li><li><strong>Return type:</strong> x</li></ul><div class="custom-h4"><p>reset_streaming_cache<span class="small-bracket">(left_context: int, device: device)</span></p></div><p>Initialize/Reset Conv1d cache for streaming.</p><ul><li><strong>Parameters:</strong><ul><li><strong>left_context</strong> – Number of previous frames the attention module can see in current chunk (not used here).</li><li><strong>device</strong> – Device to use for cache tensor.</li></ul></li></ul><div class="custom-h4"><p>training <em>: bool</em></p></div>',22);function l(a,c){return o(),n("div",null,[s(" _espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d "),i])}const p=e(r,[["render",l],["__file","Conv1d.html.vue"]]),g=JSON.parse('{"path":"/guide/espnet2/asr_transducer/Conv1d.html","title":"espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d","lang":"en-US","frontmatter":{},"headers":[],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.52,"words":457},"filePathRelative":"guide/espnet2/asr_transducer/Conv1d.md","excerpt":"<!-- _espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d -->\\n<h1>espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d</h1>\\n<div class=\\"custom-h3\\"><p><em>class</em> espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d<span class=\\"small-bracket\\">(input_size: int, output_size: int, kernel_size: int | Tuple, stride: int | Tuple = 1, dilation: int | Tuple = 1, groups: int | Tuple = 1, bias: bool = True, batch_norm: bool = False, relu: bool = True, causal: bool = False, dropout_rate: float = 0.0)</span></p></div>"}');export{p as comp,g as data};
